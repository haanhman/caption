{"27":{"dur":5,"text":"Wow! Okay, that was great. That's never happened\nbefore. (Laughing) can you do me a favor and"},"33":{"dur":5,"text":"bring me the water. I left that with you.\nAll right, this is called county queenses"},"38":{"dur":5,"text":"of an insightful algorithm. The talk is for\nempathetic coding. We're going to delve into"},"43":{"dur":8,"text":"specific examples and and in that spirit I\nwant to start with raccoon tent warning, I'm"},"51":{"dur":7,"text":"going to deal with a number of examples that\nare sensitive top Inc.s Greek PTSD, fertility,"},"59":{"dur":5,"text":"racial profiling, con receivation camps sexual\nhistory concept and assault. While these are"},"64":{"dur":4,"text":"not the major point of the talk, in about\nten minutes we'll get into examples so you"},"69":{"dur":7,"text":"have a bit of time to decide if it's not right\nmoment for you. Algorithms impose consequences"},"77":{"dur":7,"text":"on people all the time. We're able to extract\nremarkably precise insights about an individual,"},"85":{"dur":5,"text":"but do we have a right to know what they didn't\nconsent to share? Even when they're willingly"},"90":{"dur":6,"text":"sharing the data that leads us there. How\ndo we even mitigate against unintended consequences"},"96":{"dur":6,"text":"like these? Let's start by just thinking about\nwhat is an algorithm, defined step\u2011by\u2011step"},"103":{"dur":8,"text":"set of operations predictably arriving at\nan outcome. Predictivefully is pivotal here."},"112":{"dur":5,"text":"We're talking ability algorithm of computer\nscience, patterns of instructions that are"},"118":{"dur":9,"text":"articulate in the code or in formulas. But\nyou could also think of algorithms as being"},"127":{"dur":4,"text":"something in just ordinary every day life,\npatterns of instructions that can be articulate"},"131":{"dur":13,"text":"in the all sorts of ways such as a map or\na recipe or even C\u00a0\u2011\u2011 you can Lasly define"},"145":{"dur":7,"text":"it as Al governorrisms as fast trainable artificial\ngnarl networks. A technology been around for"},"152":{"dur":6,"text":"a while since '80s in theirretcal scale and\nconfined to academia. In the past few year"},"158":{"dur":7,"text":"this is' been big advance in a variety of\nways that make deep learning for extracting"},"166":{"dur":7,"text":"insights out of Big Data out of construction\ndeployment. Opening up a lot offed possibilities."},"174":{"dur":3,"text":"In particular it's an approach to building\nand training article official neural networks"},"177":{"dur":5,"text":"you can think of them as decision making black\nboxes. What does that mean, essentially we"},"183":{"dur":6,"text":"have some inputs, is this an array might be\nrepresenting words concepts, Octobers, any"},"189":{"dur":5,"text":"number of things, execution running a series\nof functions repeatedly and layers that get"},"195":{"dur":5,"text":"more and more recease in their analysis, output\nour predictions of properties that might be"},"201":{"dur":4,"text":"useful for drawing intuition about future\ndata set as long as they're similar to the"},"206":{"dur":5,"text":"original training data set. That allows the\nus to do some incredible things behavioral"},"211":{"dur":6,"text":"prediction, the facial identification, sentiment\nanalysis, and things as extreme as self driving"},"217":{"dur":5,"text":"cars which Google is already using this stuff\nfor a number of other companies are as well."},"222":{"dur":4,"text":"So there's a lot of practical applications\nif that's already intriguing you you can check"},"226":{"dur":11,"text":"out C Convnetjs, it's a great opportunity\nto explore and experiment. So deep learning"},"238":{"dur":7,"text":"relies on and ANN's automated discovery. And\nit applies those discoveries to intuitions"},"245":{"dur":7,"text":"about future inputs. There's aquavit, every\nflaw or assumption in that training data set"},"252":{"dur":5,"text":"or original functions is going to have unrecognized\ninfluence on the Gordon and Maureen and the"},"258":{"dur":4,"text":"outcomes they generate. We're going to take\na closer look at that in a minute, I want"},"262":{"dur":8,"text":"to give you a neat example of what an ANN\nis like. This is Mario. It's an ANN that teaches"},"271":{"dur":6,"text":"itself how to play super Mario world. It start\nwas no clue whatsoever, all it does is manipulate"},"277":{"dur":7,"text":"numbers and notice that sometimes things happen.\nOver 24 hour period it learns movement and"},"285":{"dur":6,"text":"play via a purely self training session in\nwhich it engages in those hours of experimentation"},"291":{"dur":4,"text":"each time learn ago little bit more about\nthe patterns and identifiable them and using"},"295":{"dur":7,"text":"them to make predictions for next layer. And\nspeaking of games, let's play one. It looks"},"303":{"dur":7,"text":"a little bit like Bingo, it's called data\nmining fail. Insightful algorithms are full"},"311":{"dur":4,"text":"of pitfalls by looking at case studies it's\nan opportunity to explore some of the pitfalls"},"316":{"dur":4,"text":"on this particular board. So are you ready?\nYeah."},"320":{"dur":6,"text":"All right, here we go. In the retail sector\nthe second trimester of pregnancy is known"},"327":{"dur":6,"text":"as the holy grail. The reason is that it is\none of the few times in life where consumers"},"333":{"dur":6,"text":"spending habits product loyalties, brand loyalties\nare all kind of thrown up in the air, everything"},"339":{"dur":4,"text":"is subject for an opportunity to change. And\nfor retailers this is an incredible moment,"},"343":{"dur":7,"text":"an opportunity to capture a consumer for potentially\nthe rest of their lives and family. Target"},"351":{"dur":3,"text":"managed to come up several years ago with\na predictive algorithm that was good at identifying"},"355":{"dur":7,"text":"customers that were in the second trimester.\nThey started sending out add seculars to the"},"362":{"dur":8,"text":"targeted people full of stuff related pregnancy,\nbabies, a funny thing happened one day a man"},"371":{"dur":6,"text":"came into the store and he was really angry.\nHe's yelling at the manager, how dare you"},"377":{"dur":6,"text":"send this to my teenage daughter are you trying\nto tell her to have sex. Manager, you know,"},"384":{"dur":3,"text":"like he's not in charge of this, this is a\nhuge national change, he apologizes, the guy"},"388":{"dur":5,"text":"goes home he comes back the following day\nand says, I you an apology, I talked to my"},"393":{"dur":7,"text":"daughter it turns out there were things I\ndid not know and she is in fact pregnant."},"401":{"dur":8,"text":"So, target was right. But they were also wrong.\nWhat they found were that a lot of women were"},"410":{"dur":5,"text":"not okay with having their privacy violate\nin the this way. And the way they describe"},"415":{"dur":8,"text":"od it is, some women React badly. Which is\nan interesting moral judgment on that. So,"},"423":{"dur":8,"text":"they came up with a change in plan. The new\none was, now adds still go out to the same"},"432":{"dur":5,"text":"people, same adds except they're couched among\nother adds that seem completely unrelated"},"437":{"dur":4,"text":"so that their perception is that you know\nit's completely random bunch of adds that"},"441":{"dur":3,"text":"they just happen to get that have some things\nthat are relevant to their life. And the reason"},"445":{"dur":5,"text":"they do this. This is a quote \"as long as\na pregnant women thinks she hasn't been spied"},"451":{"dur":9,"text":"on, as long as we don't spook her, it works.\".\n(Laughing) so algorithms aren't just about"},"460":{"dur":5,"text":"the outputs, it's about how we use them and\nhow we abuse them. This is one of the examples"},"465":{"dur":8,"text":"of ways that we can have all the math right\nand still be wrong. Shutterfully likewise"},"474":{"dur":5,"text":"was trying to predict things related pregnancy,\nin this case what they were predicting was"},"479":{"dur":5,"text":"recent childbirth. Congratulations on your\nnew bundle of joy, time to write thank you"},"485":{"dur":6,"text":"cards to all the people that came to your\nlovely party. Some of the people who got these"},"491":{"dur":5,"text":"said, well, I haven't really been pregnant\nseeing as how I'm male. (Laughing) and others"},"497":{"dur":5,"text":"had different responses. Thanks, shutterfly\nfor the congratulations on my new bundle of"},"502":{"dur":9,"text":"joy, I'm horribly infertile, but hey, I'm\naadopting a kitten, so ... I lost a baby in"},"512":{"dur":7,"text":"November, who would have been due this week,\nit was like hitting a wall all over again."},"519":{"dur":5,"text":"Shutterfly's response was the intent of the\ne\u2011mail was to target customers who recently"},"525":{"dur":7,"text":"had a baby. Well, yes, that's true. That's\nnot an apology. That is a statement that that"},"532":{"dur":10,"text":"was what they wanted to do. They failed at\nit. False positives can be very meaningful."},"543":{"dur":6,"text":"Few months ago mark Zuckerberg excitedly announced\nhe's going to be a father soon. He wrote on"},"549":{"dur":6,"text":"Facebook about a series of miscarriages that\nhe and his wife had felt with as a couple."},"556":{"dur":4,"text":"This is part of what he had to say. He said,\nyou feel so hopeful when you learn you're"},"560":{"dur":5,"text":"going to have a child. You start imagining\nwho they'll become, and dreaming of hopes"},"566":{"dur":11,"text":"for their future. You start making plans.\nAnd then they're gone. It's a lonely experience."},"577":{"dur":5,"text":"Facebook in review has\u00a0\u2011\u2011 Facebook year\nin review has been around for a while. This"},"583":{"dur":4,"text":"past year what they did was much more automated\nputting the post from the past year that they"},"588":{"dur":4,"text":"felt were particularly big and important and\nmemorable for you and throwing them back to"},"593":{"dur":3,"text":"you at the end of the year to enjoy all over\nagain. What they failed to take into account"},"597":{"dur":7,"text":"is our lives oconstantly changing in the course\nof a year many of us have job changes, relationship"},"604":{"dur":4,"text":"change, our life circumstances. All sorts\nof things and some of those mean that not"},"609":{"dur":7,"text":"every memory stays the joyous one that it\nonce was.Er reck Meyer coined the term inadvertent"},"616":{"dur":6,"text":"algorithmic cruelty. The result of code that\nworks in the overwhelming majority of cases"},"622":{"dur":7,"text":"but doesn't take other use cases into account.\nSo why does he get to name it? Well because"},"630":{"dur":7,"text":"he's one of the people it happened to. This\nis a picture ofmy daughter who is dead. Who"},"637":{"dur":6,"text":"died this year. The year in review add keeps\ncoming up in my feed, rotating through different"},"644":{"dur":6,"text":"fun and fabulous backgrounds as if celebrating\nher death. And there's no obvious way to stop"},"650":{"dur":8,"text":"it. Eric calls on us to increase awareness\nof and consideration of the failure modes,"},"659":{"dur":5,"text":"the educations, the worst case scenarios,\nand I hope that we can do some of that today"},"664":{"dur":4,"text":"and that you're going to carry it forward\nto others W that in mind hear's my first recommendation"},"669":{"dur":9,"text":"for all of us to think about. Be humble. We\ncannot actually Intuit inner state, emotions,"},"679":{"dur":13,"text":"private subjectivity. Not yet. Any way. (Scenario)\nwhen fitbit started out, it had a sex tracker."},"693":{"dur":4,"text":"You know, quantified self, let's quantified\neverything, it counts as exercise. Right."},"698":{"dur":16,"text":"There was a wrinkle, the wrinkle was that\nit defaulted to public. (Laughing) you all"},"714":{"dur":8,"text":"want a fitbit now don't you?! All right, so\nfirst of all I appreciate the vigorous effort."},"723":{"dur":6,"text":"(Laughing) secondly, I also am a certified\nsex educator and I'm look oing at the four"},"730":{"dur":12,"text":"hours and I just tonight know whether to congratulate\nor be concerned. (Laughing) fitbit users were"},"742":{"dur":4,"text":"unwitting libraries sharing details of their\nsex lives with the whole world, it was on"},"747":{"dur":6,"text":"Google. That's because it was set public by\ndefault. And this is one of the things that"},"753":{"dur":5,"text":"we have to be thinking about an algorithm\nis not just about crunching numbers our patterns,"},"759":{"dur":6,"text":"prepredictable reproducible actions, this\nwas really unthinking decision to not evaluate"},"766":{"dur":5,"text":"how different data sets might be differently\ntreated, differently considered. Different"},"771":{"dur":3,"text":"amounts of privacy in our lives just because\nyou want to share with all your friends your"},"775":{"dur":5,"text":"competition over how many steps you've taken\nor how many runs you've done doesn't mean"},"780":{"dur":2,"text":"that everything in your life is meant to be\na public DOM petition as well. This was\u00a0\u2011\u2011"},"782":{"dur":14,"text":"public competition as this was a algorithm\nfor UX it was really a fail here. Most of"},"796":{"dur":8,"text":"us use internal opt tools, it's mandatory\nright. Performance tuning, business metrics,"},"804":{"dur":5,"text":"a lot of something, Uber is called God view.\nIf you're a gamer you're already suspecting"},"810":{"dur":6,"text":"what this implies. Uber did not limit access\nto admins and not restrict it to operational"},"817":{"dur":5,"text":"use alone, workers could freely identify had\nany passenger and monitor the person's movements"},"823":{"dur":8,"text":"even drivers were welcome to Bruce through\nUbers customer trip records. Meanwhile managers"},"831":{"dur":6,"text":"felt free to abuse God view for non\u2011operational\npurposes such as stocking celebrity ride in"},"837":{"dur":6,"text":"real\u2011time showing it as party entertainment.\nTo is show you how horrifying God view is,"},"844":{"dur":12,"text":"here's code expert. This is so nobly inappropriate.\nmean, seriously. Auto play true? Okay. And"},"856":{"dur":4,"text":"then of course there's the other choice. Background\nimage, that's pretty telling as well as to"},"861":{"dur":6,"text":"what their intent was for this. The research\ngroup at dating site okay cupid used to Blog"},"867":{"dur":6,"text":"all the time things they were learning about\naggregating their data and Blog showing insights"},"874":{"dur":6,"text":"into simple ways that okay cupid users could\nuse that data site well to date better. Uber"},"880":{"dur":5,"text":"used to Blog about its day to too. There's\na critical difference in that Uber's approach"},"886":{"dur":7,"text":"to it was not about improving customers' experience\nof a ride service, it was about invading people's"},"893":{"dur":6,"text":"privacy for the sake of judging and shaming\nand stalking them. These are not predictable"},"899":{"dur":8,"text":"consequences of signing up for an account\nto take a ride. Galling add words is an interesting"},"908":{"dur":6,"text":"study done at Harvard a few years ago, what\nthey did was took two sets of names, one that"},"915":{"dur":4,"text":"is strongly correlated with black people and\none that's correlated with white people. So"},"920":{"dur":4,"text":"for instance first name like Latonya would\nbe something that's highly correlated lated"},"924":{"dur":6,"text":"with black women and something like Jill would\nbe highly correlated with a white woman. And"},"931":{"dur":3,"text":"then what they did was they matched up the\nfirst names a with the real last names of"},"934":{"dur":6,"text":"professors and did some searches on add words\nfor those names. And what they found is that"},"941":{"dur":6,"text":"a black identifying name was 25\u00a0percent more\nlikely to result in the an add that implied"},"948":{"dur":10,"text":"that that person had an arrest record. So\nfor example adds like these. And I think it's"},"958":{"dur":5,"text":"important to note here, Ad word algorithm\nis focused on predicting what we'll click"},"964":{"dur":7,"text":"on. That's it. It's not interested in whether\nanyone was arrested. That's not it's point,"},"971":{"dur":5,"text":"the real world isn't important. It's whole\njob is to figure out what motivates us to"},"976":{"dur":5,"text":"click. Which Ad template we're going to respond\nto. Based on what it knows about us individually"},"982":{"dur":5,"text":"and collectively what it knows about other\nusers before us, what we're see inning these"},"988":{"dur":7,"text":"Ads is our collective bias at work and being\nreflected back to us and then being reinforced"},"995":{"dur":6,"text":"every time it's presented again and we click\non it again. This is a feedback loop. Data"},"1002":{"dur":6,"text":"is generated by people. It's not objective.\nIt's constrained by our tunnel vision it replicates"},"1008":{"dur":14,"text":"our flaws, it echos our preconceptions. Image\nrecognition is hard. And you remember it wasn't"},"1023":{"dur":9,"text":"so long ago we had things like this. (Laughing)\nI photo helpfully helpfully detecting faces"},"1032":{"dur":7,"text":"in baked goods. It's funny, sure. It's a harmless\nmistake, it's a false positive that's easy"},"1039":{"dur":6,"text":"to chuckle at. Some are less funny, such as\nin this next photo. Flicker classified it"},"1046":{"dur":7,"text":"as essentially children's playground equipment.\nFor those who are not familiar that's ash"},"1053":{"dur":11,"text":"wits. This was in May\u00a0\u2011\u2011\u00a0\u2011\u2011 a month\nlater Google photos mistagged this person"},"1065":{"dur":9,"text":"as an animal. Sorry that was actually flicker\nagain, apologize, it also tagged him as an"},"1075":{"dur":6,"text":"ape. Google photos a month after that tagged\nsomeone as a gorilla. You'll notice a common"},"1082":{"dur":7,"text":"theme here, black skin. How does that happen?\nWell, maybe some of it is just like those"},"1089":{"dur":5,"text":"Ad words our bias being reflected back, there's\nalso other answers for one of those you're"},"1094":{"dur":8,"text":"going to have go all the way back to the 1950s\nwhen color film stock was first being developed,"},"1103":{"dur":7,"text":"created it was optimized for white skin to\nget as much detame out of white skin as possible."},"1110":{"dur":6,"text":"And for decades labs were given these, they\nwere scall called Shirly cards they were used"},"1117":{"dur":8,"text":"to calibrate developers to make sure they\nwere accurately producing details and colors,"},"1125":{"dur":5,"text":"for decades every film stock was designed\nto optimize for white skin and to ignore black"},"1131":{"dur":6,"text":"skin. And black skin, to this day still has\na very hard time getting a nice accurate well"},"1137":{"dur":5,"text":"exposed photo. When we started moving to digital\nsensors the obvious thing to do is to replicate"},"1143":{"dur":7,"text":"the experience people were already having.\nIf we have sensors that are radically different"},"1151":{"dur":5,"text":"we would all complain about how terrible and\nfaulty our cameras were. What we have here"},"1156":{"dur":8,"text":"is repeatuation is racial an mouse from thed\n50s, we have decades of the data sets that"},"1165":{"dur":5,"text":"are contaminated with noise. And so when we\nhave these kind of misclassifications it's"},"1171":{"dur":6,"text":"easy to look at it and say, Hmm mistake or\nHmm racism. It goes deeper than that, these"},"1177":{"dur":4,"text":"are hard problems to solve, Big Data if we\nthrow enough data at it any problem can be"},"1182":{"dur":3,"text":"corrected is what we think. Where are you\ngoing to find the data that is an easy corrector"},"1185":{"dur":12,"text":"for this? A firm is a rather unusual credit\nlending company. They focus on lending for"},"1198":{"dur":6,"text":"certain small consumer purchases and make\na rather interesting set of criteria, the"},"1205":{"dur":4,"text":"basis for lending. Essentially just provide\na few thing, name, e\u2011mail, mobile phone"},"1210":{"dur":6,"text":"number, birthday and last four digit of identification\nnumber and then from there it starts evaluating"},"1216":{"dur":5,"text":"behavioral factors even were you given that\nmuch. Things like how long you take to fill"},"1221":{"dur":5,"text":"in that little form. What time\u00a0\u2011\u2011 how\nmuch time it takes you to remember stuff."},"1226":{"dur":3,"text":"And then if it needs more information it goes\nout and looks at your social accounts including"},"1230":{"dur":8,"text":"GitHub. Which is already starting to replicate\nprivilege in the real world because only 2\u00a0percent"},"1238":{"dur":4,"text":"of women\u00a0\u2011\u2011 sorry only 2\u00a0percent of\nOpen Source cent toes are women. So that means"},"1242":{"dur":6,"text":"GitHub is inevitably going to be biased towards\nfinding men, and if you're making the criteria"},"1248":{"dur":5,"text":"for lending participation on a site like GitHub\nautomatically it's always going to be biased"},"1254":{"dur":6,"text":"against a lot of women. Think about how much\ntime it takes to remember something. Who might"},"1260":{"dur":7,"text":"need more time? Someone with, say a cognitive\nprocessing disorder. Someone who's older."},"1267":{"dur":7,"text":"All sorts of biases built into the supposedly\nobjective algorithm. UK researchers my shopping"},"1275":{"dur":6,"text":"cart abandonment rate is high because my toddler\ngrabs my visa card and runs off screaming,"},"1282":{"dur":5,"text":"mine, mine, mine. All right, sometimes it's\nnot that we're inattentive because we somehow"},"1288":{"dur":5,"text":"are a bad credit risk, sometimes we're inattentive\nbecause other things distract us. This is"},"1293":{"dur":5,"text":"a person who's clock is invisibly ticking\nand losing opportunities that are financial"},"1298":{"dur":6,"text":"as a result of it. A firm analyzes those social\nmedia accounts, they're not the only one,"},"1304":{"dur":4,"text":"there are a number of other companies using\nsimilar models. In 2012, in fact Germany's"},"1309":{"dur":9,"text":"biggest credit rating agency considered evaluating\nFacebook relationships. More recently Facebook"},"1318":{"dur":6,"text":"pushes further down that line making credit\ndecisions about you based on the unrelated"},"1325":{"dur":12,"text":"credit history of your Facebook friends. Okay.\nWhat? So are they unaware that friends doesn't"},"1337":{"dur":7,"text":"equal Facebook friend? Like we got to tell\nFacebook about this. Here's an algorithm with"},"1344":{"dur":6,"text":"potential to deeply intrude on and alter personal\nrelationships. To just to prevent that algorithm"},"1351":{"dur":8,"text":"from financially shaming and pun ishing them.\nThis is a huge consequence. Data is not objective."},"1359":{"dur":8,"text":"It always has bias, it's inherent at minimum\nfrom how it was collected and interpreted."},"1367":{"dur":8,"text":"A firm says that it's algorithm uses 70,000\nfactors to reach it's conclusions. They say"},"1376":{"dur":4,"text":"they don't even know what all of them are.\nAll right, so how do we know how many have"},"1380":{"dur":4,"text":"potential for discriminatory outcomes then.\nHow would anyone of them now. If thaw don't"},"1385":{"dur":7,"text":"know how would the consumer do anything about\nmistakes? Forget about bias, just simple error."},"1393":{"dur":5,"text":"Rationals for the algorithm can only be seen\nfrom inside that black box. So let's take"},"1398":{"dur":10,"text":"a look at it. I took a photo from inside a\nreally, really black box. (Laughing) that's"},"1409":{"dur":6,"text":"what we can see. Making lending desessions\ninside a black box isn't a radical new business"},"1415":{"dur":8,"text":"model, it's a regression. What is disrupting\nis oversight and regulation. Right now we're"},"1424":{"dur":8,"text":"in an arms race. Facebook, Google, happening,\nMicrosoft, Yahoo. Baidu, IBM, AT&T Twitter,"},"1433":{"dur":5,"text":"so many companies are making big bets on deep\nlearning, some are already deploying, for"},"1439":{"dur":6,"text":"the moment, quality varies but we have to\nremember that deep learning is all about iteratively"},"1445":{"dur":7,"text":"drawing intuitions at extremely fine grained\nlevels. And what that means is that they're"},"1453":{"dur":4,"text":"continuously getting more precise in their\ncorrectness but also more damaging in their"},"1458":{"dur":6,"text":"wrongness. And that's a dilemma that we have\nto take seriously as developers. Because underlying"},"1465":{"dur":6,"text":"actions, influence, outcomes and influence\nconsequences. They have underlying assumptions"},"1471":{"dur":5,"text":"about meaning, about accuracy, about the world\nin which data has been generated, about how"},"1476":{"dur":10,"text":"code should assign meaning to to data. We\ncare about getting this stuff right (To Data)"},"1487":{"dur":5,"text":"the question is how do we flip the paradigm?\nWell, we can do a few things like taking some"},"1492":{"dur":5,"text":"lessons from professional ethicists because\nit turns out that's a thing. It turns out"},"1498":{"dur":5,"text":"our profession has professional ethicists,\nwho knew. These are a few that I've adapted"},"1503":{"dur":6,"text":"from the association from computer machinery\nand a few other sources. We need to consider"},"1510":{"dur":6,"text":"decisions impact, potential impacts on others.\nFor instance how might a false positive affect"},"1517":{"dur":6,"text":"someone, like those shutterfly customers,\nhow might a false negative affect someone,"},"1523":{"dur":4,"text":"have we built in resource for someone to easily\nget our conclusions corrected when we're wrong"},"1527":{"dur":6,"text":"about them. We need to be able to project\nthe likelihood of consequences to others and"},"1534":{"dur":5,"text":"to minimize negative consequences to others,\nand yes, I keep hammering on two others, we're"},"1540":{"dur":5,"text":"pretty good at taking care of ourselves. We\nhave to be honest and trustworthy. Not just"},"1545":{"dur":2,"text":"because those are the right things to do,\nbut because we need to be able to lean on"},"1548":{"dur":5,"text":"it when we make mistakes, we need to be able\nto buyback trust because we've earn it, because"},"1553":{"dur":5,"text":"we can say maya cull pa without that destroying\nus. We need to provide others with the full"},"1559":{"dur":6,"text":"disclosure of limitations and call attention\nto signs of risk of harm to them. And here's"},"1566":{"dur":5,"text":"a big one, we have to be visionary about counterrerring\nbias, we have to be visionaries about creating"},"1572":{"dur":8,"text":"more than one way to counteract it. To counteract\nbias data, bias analysis, bias impacts. And"},"1580":{"dur":7,"text":"here's the really big one. We have to be able\nto anticipate diverse ways to screw up. When"},"1587":{"dur":5,"text":"teams are charged with defining data collections\nuse and anal circumstance any time those are"},"1593":{"dur":4,"text":"less diverse than the intended user base,\nwe're going to keep on failing them, just"},"1597":{"dur":9,"text":"like this. We have to have decision making\nauthority in the hands of highly diverse teams,"},"1607":{"dur":7,"text":"highly. What does that mean? Culture fit is\nthe antithesis of diversity, it's superficial"},"1614":{"dur":5,"text":"variations being allowed to exist as long\nas their unique perspective is sure pressed"},"1620":{"dur":7,"text":"the purpose of culture fit is to avoid disruption\nof group think. UniI did mixal variety is"},"1627":{"dur":7,"text":"not diversity either. Diversity is widely\nvaried on as many areas as possible. Different"},"1635":{"dur":6,"text":"assumptions, different experiences, until\nyou get to the point where there's no such"},"1641":{"dur":8,"text":"thing as a majority you can't find it. We\nneed to cultivate, inform consent. What that"},"1650":{"dur":5,"text":"means is we ask for permission with the default\nbeing no and explain the consequences of a"},"1655":{"dur":5,"text":"yes. Focus on the many people that eerily\nwant to share themselves and enthusiastically"},"1660":{"dur":8,"text":"give consent and want to be served better\nby that. And we have the audit outcomes constantly,"},"1669":{"dur":4,"text":"the reason is going back to the black box,\nif we can't be sure what's happening inside"},"1673":{"dur":6,"text":"of it. We need to be able to look at the outcomes.\nThis is used a lot in checking for housing"},"1679":{"dur":4,"text":"discrimination and job discrimination. So\nyou put in two inputs that are exactly the"},"1684":{"dur":5,"text":"same on every criteria but one. One that should\nnot have any bias introduced and if the outcome"},"1690":{"dur":5,"text":"on those divers at all, we know we have an\nproblem with the algorithm. So this is something"},"1695":{"dur":3,"text":"we constantly have to be looking for. For\ninstance when Google photos made that mistake"},"1699":{"dur":5,"text":"with classifying people as gorillas, as soon\nas they saw that problem on flicker a month"},"1704":{"dur":12,"text":"earlier they should of been dog auditing,\ndo we have a the same problem? And why? Because"},"1717":{"dur":9,"text":"photo of a big black box. And that's why we\nalso have to commit to data transparency and"},"1726":{"dur":7,"text":"algorithmic transparency. And I do mean both\nbecause I recognize that these are hard decisions"},"1733":{"dur":5,"text":"to have internally. They truly are. But I\nalso think that, you know, it wasn't that"},"1738":{"dur":4,"text":"long ago that we were fighting for legitimacy\nof Open Source in our professional Toolkit."},"1743":{"dur":6,"text":"We push back, we were right, we're profession\nfalls, we won because we know what we're doing"},"1749":{"dur":5,"text":"and we made a good argument. We know that\ntransparency is crucial for drawing insights"},"1754":{"dur":5,"text":"that are general when and useful. So argue\nfor increasing transparency because it's for"},"1759":{"dur":7,"text":"a better product. Cleaner features, fewer\nbugs stronger tests happier users public trust."},"1767":{"dur":6,"text":"That's the argument. Because we want to build\nstuff that matters. We're hired for more than"},"1774":{"dur":5,"text":"just to write code, we're hired as professionals\nthat apply expertise and judgment about how"},"1779":{"dur":5,"text":"to solve problems. That's who we really are.\nWe're not code monkeys, we're people that"},"1785":{"dur":4,"text":"think about how to solve problems. Our role\nis to be opinionuated about how to make code"},"1789":{"dur":7,"text":"serve the problemtion based well. We can advocate.\nWhen we're asked to write code that presumed"},"1796":{"dur":5,"text":"to Intuit people as internal life and act\non those assumptions as professionals we have"},"1801":{"dur":6,"text":"to be people's proxies, we have to be their\nadvocates, say no on their behalf to using"},"1808":{"dur":7,"text":"their data in ways that they have not enthusiastically\nand knowingly consented to. Saying no to uncritically"},"1815":{"dur":6,"text":"reproducing systems that were based to begin\nwith. Say no to writing code that imposes"},"1821":{"dur":8,"text":"on authorized consequences on to their lives.\nIn short, refuse to play along. Thank you."},"1830":{"dur":0,"text":"(Applause)"}}