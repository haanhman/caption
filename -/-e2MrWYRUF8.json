{"0.34":{"start":"0.34","dur":"1.75","text":"ALAN WINFIELD: Thank\nyou very much indeed."},"4.49":{"start":"4.49","dur":"1.25","text":"It&#39;s really great to be here."},"5.74":{"start":"5.74","dur":"2.72","text":"And thank you so much\nfor the invitation."},"8.46":{"start":"8.46","dur":"2.81","text":"So yes, robot intelligence."},"11.27":{"start":"11.27","dur":"3.44","text":"So I&#39;ve titled the lecture\n&quot;The Thinking Robot.&quot;"},"14.71":{"start":"14.71","dur":"3.62","text":"But of course, that\nimmediately begs the question,"},"18.33":{"start":"18.33","dur":"3.28","text":"what on earth do we\nmean by thinking?"},"21.61":{"start":"21.61","dur":"1.98","text":"Well we could, of\ncourse, spend the whole"},"23.59":{"start":"23.59","dur":"5.14","text":"of the next hour debating\nwhat we mean by thinking."},"28.73":{"start":"28.73","dur":"3.73","text":"But I should say that I&#39;m\nparticularly interested in"},"32.46":{"start":"32.46","dur":"3.87","text":"and will focus on\nembodied intelligence."},"36.33":{"start":"36.33","dur":"3.66","text":"So in other words, the kind\nof intelligence that we have,"},"39.99":{"start":"39.99","dur":"3.99","text":"that animals including humans\nhave, and that robots have."},"43.98":{"start":"43.98","dur":"4.33","text":"So of course that\nslightly differentiates"},"48.31":{"start":"48.31","dur":"1.84","text":"what I&#39;m talking about from AI."},"50.15":{"start":"50.15","dur":"3.12","text":"But I regard robotics as\na kind of subset of AI."},"55.89":{"start":"55.89","dur":"2.77","text":"And of course one of the\nthings that we discovered"},"58.66":{"start":"58.66","dur":"2.62","text":"in the last 60 odd years\nof artificial intelligence"},"61.28":{"start":"61.28","dur":"4.13","text":"is that the things that we\nthought were really difficult"},"65.41":{"start":"65.41","dur":"2.07","text":"actually are relatively easy."},"67.48":{"start":"67.48","dur":"4.57","text":"Like playing chess, or\ngo, for that matter."},"72.05":{"start":"72.05","dur":"4.1","text":"Whereas the things that\nwe originally thought"},"76.15":{"start":"76.15","dur":"4.92","text":"were really easy, like making\na cup of tea, are really hard."},"81.07":{"start":"81.07","dur":"3.55","text":"So it&#39;s kind of the opposite\nof what was expected."},"84.62":{"start":"84.62","dur":"3.2","text":"So embodied intelligence\nin the real world"},"87.82":{"start":"87.82","dur":"4.21","text":"is really very difficult indeed."},"92.03":{"start":"92.03","dur":"2.42","text":"And that&#39;s what\nI&#39;m interested in."},"94.45":{"start":"94.45","dur":"5.74","text":"So this is the\noutline of the talk."},"100.19":{"start":"100.19","dur":"2.45","text":"I&#39;m going to talk initially\nabout intelligence"},"102.64":{"start":"102.64","dur":"2.95","text":"and offer some\nideas, if you like,"},"105.59":{"start":"105.59","dur":"3.1","text":"for a way of thinking\nabout intelligence"},"108.69":{"start":"108.69","dur":"2","text":"and breaking it\ndown into categories"},"110.69":{"start":"110.69","dur":"3.39","text":"or types of intelligence."},"114.08":{"start":"114.08","dur":"3.08","text":"And then I&#39;m going to choose\na particular one which"},"117.16":{"start":"117.16","dur":"4.54","text":"I&#39;ve been really working on\nthe last three or four years."},"121.70":{"start":"121.7","dur":"3.16","text":"And it&#39;s what I call\na generic architecture"},"124.86":{"start":"124.86","dur":"4.05","text":"for a functional imagination."},"128.91":{"start":"128.91","dur":"2.81","text":"Or in short, robots\nwith internal models."},"131.72":{"start":"131.72","dur":"2.282","text":"So that&#39;s really what\nI want to focus on."},"134.00":{"start":"134.002","dur":"1.458","text":"Because I really\nwanted to show you"},"135.46":{"start":"135.46","dur":"1.49","text":"some experimental\nwork that we&#39;ve"},"136.95":{"start":"136.95","dur":"4.24","text":"done the last couple\nof years in the lab."},"141.19":{"start":"141.19","dur":"2.11","text":"I mean, I&#39;m an\nelectronics engineer."},"143.30":{"start":"143.3","dur":"1.26","text":"I&#39;m an experimentalist."},"144.56":{"start":"144.56","dur":"4.92","text":"And so doing experiments\nis really important for me."},"149.48":{"start":"149.48","dur":"4.27","text":"So the first thing that\nwe ought to realize--"},"153.75":{"start":"153.75","dur":"5.32","text":"I&#39;m sure we do realize-- is that\nintelligence is not one thing"},"159.07":{"start":"159.07","dur":"3","text":"that we all, animals,\nhumans, and robots"},"162.07":{"start":"162.07","dur":"2.14","text":"have more or less of."},"164.21":{"start":"164.21","dur":"1.39","text":"Absolutely not."},"165.60":{"start":"165.6","dur":"3","text":"And you know, there are several\nways of breaking intelligence"},"168.60":{"start":"168.6","dur":"2.09","text":"down into different\nkind of categories,"},"170.69":{"start":"170.69","dur":"2.09","text":"if you like, of\nintelligence, different types"},"172.78":{"start":"172.78","dur":"1.45","text":"of intelligence."},"174.23":{"start":"174.23","dur":"3.06","text":"And here&#39;s one that I came\nup with in the last couple"},"177.29":{"start":"177.29","dur":"2.59","text":"of years."},"179.88":{"start":"179.88","dur":"2.86","text":"It&#39;s certainly not the only way\nof thinking about intelligence."},"182.74":{"start":"182.74","dur":"3.12","text":"But this really breaks\nintelligence into four,"},"185.86":{"start":"185.86","dur":"4.5","text":"if you like, types, four\nkinds of intelligence."},"190.36":{"start":"190.36","dur":"4.92","text":"You could say kinds\nof minds, I guess."},"195.28":{"start":"195.28","dur":"2.71","text":"The most fundamental\nis what we call"},"197.99":{"start":"197.99","dur":"1.97","text":"morphological intelligence."},"199.96":{"start":"199.96","dur":"2.04","text":"And that&#39;s the intelligence\nthat you get just"},"202.00":{"start":"202","dur":"3.19","text":"from having a physical body."},"205.19":{"start":"205.19","dur":"2.6","text":"And there are some\ninteresting questions"},"207.79":{"start":"207.79","dur":"3.04","text":"about how you design\nmorphological intelligence."},"210.83":{"start":"210.83","dur":"4.98","text":"You&#39;ve probably all seen\npictures of or movies of robots"},"215.81":{"start":"215.81","dur":"2.8","text":"that can walk, but in\nfact don&#39;t actually"},"218.61":{"start":"218.61","dur":"3.44","text":"have any computing, any\ncomputation whatsoever."},"222.05":{"start":"222.05","dur":"4.94","text":"In other words, the\nbehavior of walking"},"226.99":{"start":"226.99","dur":"2.51","text":"is an emergent property\nof the mechanics,"},"229.50":{"start":"229.5","dur":"4.6","text":"if you like, the springs and\nlevers and so on in the robot."},"234.10":{"start":"234.1","dur":"3.35","text":"So that&#39;s an example of\nmorphological intelligence."},"237.45":{"start":"237.45","dur":"3.22","text":"Individual intelligence is\nthe kind of intelligence"},"240.67":{"start":"240.67","dur":"4.4","text":"that you get from\nlearning individually."},"245.07":{"start":"245.07","dur":"1.77","text":"Social intelligence,\nI think, is really"},"246.84":{"start":"246.84","dur":"1.27","text":"interesting and important."},"248.11":{"start":"248.11","dur":"1.375","text":"And that&#39;s the\none that I&#39;m going"},"249.49":{"start":"249.485","dur":"1.635","text":"to focus on most in this talk."},"251.12":{"start":"251.12","dur":"1.81","text":"Social intelligence\nis the intelligence"},"252.93":{"start":"252.93","dur":"5.779","text":"that you get from learning\nsocially, from each other."},"258.71":{"start":"258.709","dur":"3.691","text":"And of course, we\nare a social species."},"262.40":{"start":"262.4","dur":"1.58","text":"And the other one\nwhich I&#39;ve been"},"263.98":{"start":"263.98","dur":"2.74","text":"working on a lot in\nthe last 20 odd years"},"266.72":{"start":"266.72","dur":"1.26","text":"is swarm intelligence."},"267.98":{"start":"267.98","dur":"2.47","text":"So this is the kind\nof intelligence"},"270.45":{"start":"270.45","dur":"5.425","text":"that we see most particularly\nin social animals, insects."},"279.17":{"start":"279.17","dur":"3.79","text":"The most interesting properties\nof swarm intelligence"},"282.96":{"start":"282.96","dur":"2.92","text":"tend to be emergent\nor self-organizing."},"285.88":{"start":"285.88","dur":"2.47","text":"So in other words,\nthe intelligence"},"288.35":{"start":"288.35","dur":"4.64","text":"is typically manifest as\na collective behavior that"},"292.99":{"start":"292.99","dur":"3.24","text":"emerges from the, if you\nlike, the micro interactions"},"296.23":{"start":"296.23","dur":"2.99","text":"between the individuals\nin that population."},"299.22":{"start":"299.22","dur":"1.672","text":"So emergence and\nself-organization"},"300.89":{"start":"300.892","dur":"2.488","text":"are particularly\ninteresting to me."},"303.38":{"start":"303.38","dur":"4.94","text":"But I said this is\nabsolutely not the only way"},"308.32":{"start":"308.32","dur":"1.98","text":"to think about intelligence."},"310.30":{"start":"310.3","dur":"3.15","text":"And I&#39;m going to\nshow you another way"},"313.45":{"start":"313.45","dur":"3.59","text":"of thinking about intelligence\nwhich I particularly like."},"317.04":{"start":"317.04","dur":"5.21","text":"And this is Dan Dennett&#39;s\ntower of generate and test."},"322.25":{"start":"322.25","dur":"4.09","text":"So in Darwin&#39;s Dangerous\nIdea, and several other books,"},"326.34":{"start":"326.34","dur":"5.39","text":"I think, Dan Dennett\nsuggests that a good way"},"331.73":{"start":"331.73","dur":"3.42","text":"of thinking about intelligence\nis to think about the fact"},"335.15":{"start":"335.15","dur":"4.31","text":"that all animals,\nincluding ourselves, need"},"339.46":{"start":"339.46","dur":"2.45","text":"to decide what actions to take."},"341.91":{"start":"341.91","dur":"5.25","text":"So choosing the next action is\nreally critically important."},"347.16":{"start":"347.16","dur":"4.18","text":"I mean it&#39;s critically important\nfor all of us, including"},"351.34":{"start":"351.34","dur":"0.81","text":"humans."},"352.15":{"start":"352.15","dur":"2.75","text":"Even though the wrong\naction may not kill us,"},"354.90":{"start":"354.9","dur":"1.587","text":"as it were, for humans."},"356.49":{"start":"356.487","dur":"1.583","text":"But for many animals,\nthe wrong action"},"358.07":{"start":"358.07","dur":"2.3","text":"may well kill that animal."},"360.37":{"start":"360.37","dur":"4.8","text":"And Dennett talks\nabout what he calls"},"365.17":{"start":"365.17","dur":"3.34","text":"the tower of generate and test\nwhich I want to show you here."},"368.51":{"start":"368.51","dur":"3.35","text":"It&#39;s a really cool\nbreakdown, if you like, way"},"371.86":{"start":"371.86","dur":"2.13","text":"of thinking about intelligence."},"373.99":{"start":"373.99","dur":"4.43","text":"So at the bottom of his tower\nare Darwinian creatures."},"378.42":{"start":"378.42","dur":"2.31","text":"And the thing about\nDarwinian creatures"},"380.73":{"start":"380.73","dur":"3.21","text":"is that they have\nonly one way of,"},"383.94":{"start":"383.94","dur":"5.7","text":"as it were, learning\nfrom, if you like,"},"389.64":{"start":"389.64","dur":"2.32","text":"generating and testing\nnext possible actions."},"391.96":{"start":"391.96","dur":"3.53","text":"And that is natural selection."},"395.49":{"start":"395.49","dur":"4.79","text":"So Darwinian creatures in\nhis schema cannot learn."},"400.28":{"start":"400.28","dur":"2.48","text":"They can only try out an action."},"402.76":{"start":"402.76","dur":"2.43","text":"If it kills them, well\nthat&#39;s the end of that."},"405.19":{"start":"405.19","dur":"3.36","text":"So by the laws of\nnatural selection,"},"408.55":{"start":"408.55","dur":"2.12","text":"that particular action\nis unlikely to be"},"410.67":{"start":"410.67","dur":"4.54","text":"passed on to descendants."},"415.21":{"start":"415.21","dur":"3.29","text":"Now, of course, all\nanimals on the planet"},"418.50":{"start":"418.5","dur":"2.6","text":"are Darwinian creatures,\nincluding ourselves."},"421.10":{"start":"421.1","dur":"3.91","text":"But a subset of what Dennett\ncalls Skinnerian creatures."},"425.01":{"start":"425.01","dur":"5.32","text":"So Skinnerian creatures\nare able to generate"},"430.33":{"start":"430.33","dur":"2.82","text":"a next possible candidate\naction, if you like,"},"433.15":{"start":"433.15","dur":"3.66","text":"a next possible\naction and try it out."},"436.81":{"start":"436.81","dur":"3.4","text":"And here&#39;s the thing,\nif it doesn&#39;t kill them"},"440.21":{"start":"440.21","dur":"3.33","text":"but it&#39;s actually a bad action,\nthen they&#39;ll learn from that."},"443.54":{"start":"443.54","dur":"2.88","text":"Or even if it&#39;s a good\naction, a Skinnerian creature"},"446.42":{"start":"446.42","dur":"2.89","text":"will learn from\ntrying out an action."},"449.31":{"start":"449.31","dur":"5.79","text":"So really, Skinnerian creatures\nare a subset of Darwinians,"},"455.10":{"start":"455.1","dur":"3.83","text":"actually a small subset\nthat are able to learn"},"458.93":{"start":"458.93","dur":"4.95","text":"by trial and error, individually\nlearn by trial and error."},"463.88":{"start":"463.88","dur":"4.35","text":"Now, the third layer,\nor story, if you"},"468.23":{"start":"468.23","dur":"3.14","text":"like, in Dennett&#39;s tower, he\ncalls Popperian creatures,"},"471.37":{"start":"471.37","dur":"3.75","text":"after, obviously, the\nphilosopher, Karl Popper."},"475.12":{"start":"475.12","dur":"3.49","text":"And Popperian creatures\nhave a big advantage"},"478.61":{"start":"478.61","dur":"3.03","text":"over Darwinians and\nSkinnerians in that they"},"481.64":{"start":"481.64","dur":"3.7","text":"have an internal model of\nthemselves in the world."},"485.34":{"start":"485.34","dur":"1.73","text":"And with an internal\nmodel, it means"},"487.07":{"start":"487.07","dur":"3.06","text":"that you can try out\nan action, a candidate"},"490.13":{"start":"490.13","dur":"5.24","text":"next possible action, if\nyou like, by imagining it."},"495.37":{"start":"495.37","dur":"2.1","text":"And it means that you\ndon&#39;t have to actually have"},"497.47":{"start":"497.47","dur":"3.73","text":"to put yourself to the\nrisk of trying it out"},"501.20":{"start":"501.2","dur":"2.08","text":"for real physically\nin the world,"},"503.28":{"start":"503.28","dur":"5.55","text":"and possibly it killing you,\nor at least harming you."},"508.83":{"start":"508.83","dur":"4.69","text":"So Popperian creatures have\nthis amazing invention,"},"513.52":{"start":"513.52","dur":"1.659","text":"which is internal modeling."},"515.18":{"start":"515.179","dur":"4.161","text":"And of course, we are examples\nof Popperian creatures."},"519.34":{"start":"519.34","dur":"2.61","text":"But there are plenty of\nother animals-- again,"},"521.95":{"start":"521.95","dur":"2.85","text":"it&#39;s not a huge proportion."},"524.80":{"start":"524.8","dur":"2.37","text":"It&#39;s rather a small proportion,\nin fact, of all animals."},"527.17":{"start":"527.17","dur":"1.82","text":"But certainly there\nare plenty of animals"},"528.99":{"start":"528.99","dur":"5.03","text":"that are capable in some\nform of modeling their world"},"534.02":{"start":"534.02","dur":"4.34","text":"and, as it were, imagining\nactions before trying them out."},"538.36":{"start":"538.36","dur":"2.66","text":"And just to complete\nDennett&#39;s tower,"},"541.02":{"start":"541.02","dur":"5.34","text":"he adds another layer that\nhe calls Gregorian creatures."},"546.36":{"start":"546.36","dur":"3.38","text":"Here&#39;s he&#39;s naming this\nlayer after Richard Gregory,"},"549.74":{"start":"549.74","dur":"5.06","text":"the British psychologist."},"554.80":{"start":"554.8","dur":"3.28","text":"And the thing that\nGregorian creatures have"},"558.08":{"start":"558.08","dur":"3.32","text":"is that in addition\nto internal models,"},"561.40":{"start":"561.4","dur":"4.42","text":"they have mind tools like\nlanguage and mathematics."},"565.82":{"start":"565.82","dur":"5.82","text":"Especially language because it\nmeans that Gregorian creatures"},"571.64":{"start":"571.64","dur":"2.77","text":"can share their experiences."},"574.41":{"start":"574.41","dur":"3.3","text":"In fact, a Gregorian\ncreature could, for instance,"},"577.71":{"start":"577.71","dur":"8.11","text":"model in its brain, in its\nmind, the possible consequences"},"585.82":{"start":"585.82","dur":"3.15","text":"of doing a particular thing,\nand then actually pass"},"588.97":{"start":"588.97","dur":"0.94","text":"that knowledge to you."},"589.91":{"start":"589.91","dur":"2.42","text":"So you don&#39;t even have\nto model it yourself."},"592.33":{"start":"592.33","dur":"3.87","text":"So the Gregorian\ncreatures really"},"596.20":{"start":"596.2","dur":"2.14","text":"have the kind of\nsocial intelligence"},"598.34":{"start":"598.34","dur":"4.34","text":"that we probably--\nperhaps not uniquely,"},"602.68":{"start":"602.68","dur":"1.97","text":"but there are obviously\nonly a handful"},"604.65":{"start":"604.65","dur":"6.24","text":"of species that are able to\ncommunicate, if you like,"},"610.89":{"start":"610.89","dur":"3.04","text":"traditions with each other."},"613.93":{"start":"613.93","dur":"5.99","text":"So I think internal models are\nreally, really interesting."},"619.92":{"start":"619.92","dur":"2.17","text":"And as I say, I&#39;ve been\nspending the last couple"},"622.09":{"start":"622.09","dur":"5.26","text":"of years thinking about\nrobots with internal models."},"627.35":{"start":"627.35","dur":"2.38","text":"And actually doing\nexperiments with"},"629.73":{"start":"629.73","dur":"1.41","text":"robots with internal models."},"631.14":{"start":"631.14","dur":"4.74","text":"So are robots with\ninternal models self-aware?"},"635.88":{"start":"635.88","dur":"3.81","text":"Well probably not in the\nsense that-- the everyday"},"639.69":{"start":"639.69","dur":"3.01","text":"sense that we mean by\nself-aware, sentient."},"642.70":{"start":"642.7","dur":"1.98","text":"But certainly internal\nmodels, I think,"},"644.68":{"start":"644.68","dur":"1.72","text":"can provide a\nminimal level of kind"},"646.40":{"start":"646.4","dur":"2.22","text":"of functional self-awareness."},"648.62":{"start":"648.62","dur":"5.33","text":"And absolutely enough to allow\nus to ask what if questions."},"653.95":{"start":"653.95","dur":"4.24","text":"So with internal models, we have\npotentially a really powerful"},"658.19":{"start":"658.19","dur":"2.01","text":"technique for robots."},"660.20":{"start":"660.2","dur":"2.66","text":"Because it means that\nthey can actually ask"},"662.86":{"start":"662.86","dur":"3.38","text":"themselves questions\nabout what if I take this"},"666.24":{"start":"666.24","dur":"2.47","text":"or that next possible action."},"668.71":{"start":"668.71","dur":"2.24","text":"So there&#39;s the action\nselection, if you like."},"673.95":{"start":"673.95","dur":"4.79","text":"So really, I&#39;m kind of\nfollowing Dennett&#39;s model."},"678.74":{"start":"678.74","dur":"3.11","text":"I&#39;m really interested in\nbuilding Popperian creatures."},"681.85":{"start":"681.85","dur":"2.56","text":"Actually, I&#39;m interested in\nbuilding Gregorian creatures."},"684.41":{"start":"684.41","dur":"5.22","text":"But that&#39;s another, if you\nlike, another step in the story."},"689.63":{"start":"689.63","dur":"2.23","text":"So really, here I&#39;m\nfocusing primarily"},"691.86":{"start":"691.86","dur":"1.91","text":"on Popperian creatures."},"693.77":{"start":"693.77","dur":"1.54","text":"So robots with internal models."},"698.52":{"start":"698.52","dur":"3.06","text":"And what I&#39;m talking\nabout in particular"},"701.58":{"start":"701.58","dur":"4.45","text":"is a robot with a\nsimulation of itself"},"706.03":{"start":"706.03","dur":"3.7","text":"and it&#39;s currently perceived\nenvironment and of the actors"},"709.73":{"start":"709.73","dur":"1.89","text":"inside itself."},"711.62":{"start":"711.62","dur":"2.07","text":"So it takes a bit of\ngetting your head around."},"713.69":{"start":"713.69","dur":"2.74","text":"The idea of a robot with\na simulation of itself"},"716.43":{"start":"716.43","dur":"0.97","text":"inside itself."},"717.40":{"start":"717.4","dur":"3.48","text":"But that&#39;s really what\nI&#39;m talking about."},"720.88":{"start":"720.88","dur":"3.18","text":"And the famous, the late\nJohn Holland, for instance,"},"724.06":{"start":"724.06","dur":"5.49","text":"rather perceptively\nwrote an internal model"},"729.55":{"start":"729.55","dur":"1.63","text":"that allows a\nsystem to look ahead"},"731.18":{"start":"731.18","dur":"2.66","text":"to the future\nconsequences of actions"},"733.84":{"start":"733.84","dur":"2.46","text":"without committing\nitself to those actions."},"736.30":{"start":"736.3","dur":"1.86","text":"I don&#39;t know\nwhether John Holland"},"738.16":{"start":"738.16","dur":"2.72","text":"was aware of Dennett&#39;s tower."},"740.88":{"start":"740.88","dur":"0.92","text":"Possibly not."},"741.80":{"start":"741.8","dur":"4.74","text":"But really saying the same\nkind of thing as Dan Dennett."},"746.54":{"start":"746.54","dur":"4.57","text":"Now before I come on to the\nwork that I&#39;ve been doing,"},"751.11":{"start":"751.11","dur":"3.81","text":"I want to show you some\nexamples of-- a few examples,"},"754.92":{"start":"754.92","dur":"4.03","text":"there aren&#39;t many, in fact--\nof robots with self-simulation."},"761.48":{"start":"761.48","dur":"3.85","text":"The first one, as\nfar as I&#39;m aware,"},"765.33":{"start":"765.33","dur":"2.66","text":"was by Richard\nVaughan and his team."},"767.99":{"start":"767.99","dur":"2.94","text":"And he used a simulation\ninside a robot"},"770.93":{"start":"770.93","dur":"6.53","text":"to allow it to plan a safe\nroute with incomplete knowledge."},"777.46":{"start":"777.46","dur":"3.25","text":"So as far as I&#39;m aware, this\nis the world&#39;s first example"},"780.71":{"start":"780.71","dur":"2.38","text":"of robots with self-simulation."},"786.42":{"start":"786.42","dur":"3.6","text":"Perhaps an example that you\nmight already be familiar with,"},"790.02":{"start":"790.02","dur":"4.32","text":"this is Josh Bongard\nand Hod Lipson&#39;s work."},"794.34":{"start":"794.34","dur":"2.38","text":"Very notable, very\ninteresting work."},"796.72":{"start":"796.72","dur":"4.45","text":"Here, self-simulation, but\nfor a different purpose."},"801.17":{"start":"801.17","dur":"2.62","text":"So this is not\nself-simulation to choose,"},"803.79":{"start":"803.79","dur":"2.26","text":"as it were, gross\nactions in the world."},"806.05":{"start":"806.05","dur":"2.37","text":"But instead,\nself-simulation to learn"},"808.42":{"start":"808.42","dur":"2.11","text":"how to control your own body."},"810.53":{"start":"810.53","dur":"5.1","text":"So that the idea here is that\nif you have a complex body, then"},"815.63":{"start":"815.63","dur":"2.68","text":"a self-simulation is a really\ngood way of figuring out"},"818.31":{"start":"818.31","dur":"1.99","text":"how to control\nyourself, including"},"820.30":{"start":"820.3","dur":"2.5","text":"how to repair yourself\nif parts of you"},"822.80":{"start":"822.8","dur":"6","text":"should break or fail or\nbe damaged, for instance."},"828.80":{"start":"828.8","dur":"3.56","text":"So that&#39;s a really\ninteresting example"},"832.36":{"start":"832.36","dur":"2.36","text":"of what you can do\nwith self-simulation."},"834.72":{"start":"834.72","dur":"5.09","text":"And a similar idea,\nreally, was tested"},"839.81":{"start":"839.81","dur":"3.33","text":"by my old friend, Owen Holland."},"843.14":{"start":"843.14","dur":"3.03","text":"He built this kind of\nscary looking robot."},"846.17":{"start":"846.17","dur":"2.34","text":"Initially it was called\nChronos, but but then it"},"848.51":{"start":"848.51","dur":"2.99","text":"became known as ECCE-robot."},"851.50":{"start":"851.5","dur":"6.69","text":"And this robot is deliberately\ndesigned to be hard to control."},"858.19":{"start":"858.19","dur":"2.855","text":"In fact, Owen refers to\nit as anthropomimetic."},"864.03":{"start":"864.03","dur":"3.08","text":"Which means anthropic\nfrom the inside out."},"867.11":{"start":"867.11","dur":"4.83","text":"So most humanoid robots are\nonly humanoid on the outside."},"871.94":{"start":"871.94","dur":"3.85","text":"But here, we have a robot\nthat has a skeletal structure,"},"875.79":{"start":"875.79","dur":"3.33","text":"it has tendons,\nit&#39;s very-- and you"},"879.12":{"start":"879.12","dur":"1.46","text":"can see from the\nlittle movie clip"},"880.58":{"start":"880.58","dur":"3.47","text":"there, if any part\nof the robot moves,"},"884.05":{"start":"884.05","dur":"3.71","text":"then the whole of\nthe rest of the robot"},"887.76":{"start":"887.76","dur":"6.37","text":"tends to flex, rather like\nhuman bodies or animal bodies."},"894.13":{"start":"894.13","dur":"5.12","text":"So Owen was particularly\ninterested in a robot"},"899.25":{"start":"899.25","dur":"2.35","text":"that is difficult to control."},"901.60":{"start":"901.6","dur":"4.66","text":"And the idea then of using an\ninternal simulation of yourself"},"906.26":{"start":"906.26","dur":"2.87","text":"in order to be able to\ncontrol yourself or learn"},"909.13":{"start":"909.13","dur":"1.44","text":"to control yourself."},"910.57":{"start":"910.57","dur":"4.84","text":"And he was the first to\ncome up with this phrase,"},"915.41":{"start":"915.41","dur":"2.82","text":"functional imagination."},"918.23":{"start":"918.23","dur":"2.874","text":"Really interesting work,\nso do check that out."},"923.71":{"start":"923.71","dur":"1.88","text":"And the final example\nI want to give"},"925.59":{"start":"925.59","dur":"5.61","text":"you is from my own lab,\nwhere-- this is swarm robotics"},"931.20":{"start":"931.2","dur":"5.36","text":"work-- where in fact we&#39;re doing\nevolutionary swarm robotics"},"936.56":{"start":"936.56","dur":"1.35","text":"here."},"937.91":{"start":"937.91","dur":"6.83","text":"And we&#39;ve put a simulation\nof each robot and the swarm"},"944.74":{"start":"944.74","dur":"2.52","text":"inside each robot."},"947.26":{"start":"947.26","dur":"3.04","text":"And in fact, we&#39;re using\nthose internal simulations"},"950.30":{"start":"950.3","dur":"1.53","text":"as part of a genetic algorithm."},"951.83":{"start":"951.83","dur":"4.34","text":"So each robot, in fact, is\nevolving its own controller."},"956.17":{"start":"956.17","dur":"3.66","text":"And in fact, it actually\nupdates its own controller"},"959.83":{"start":"959.83","dur":"1.47","text":"about once a second."},"961.30":{"start":"961.3","dur":"4.09","text":"So again, it&#39;s a bit an odd\nthing to get your head around."},"965.39":{"start":"965.39","dur":"3.59","text":"So about once a\nsecond, each robot"},"968.98":{"start":"968.98","dur":"3.33","text":"becomes its own great, great,\ngreat, great grandchild."},"972.31":{"start":"972.31","dur":"3.095","text":"In other words, its\ncontroller is a descendant."},"977.98":{"start":"977.98","dur":"4.95","text":"But the problem with this is\nthat the internal simulation"},"982.93":{"start":"982.93","dur":"1.63","text":"tends to be wrong."},"984.56":{"start":"984.56","dur":"2.2","text":"And we have what we\ncall the reality gap."},"986.76":{"start":"986.76","dur":"3.38","text":"So the gap between the\nsimulation and the real world."},"990.14":{"start":"990.14","dur":"3.11","text":"And so we got round that-- my\nstudent Paul O&#39;Dowd came up"},"993.25":{"start":"993.25","dur":"1.93","text":"with the idea that\nwe could co-evolve"},"995.18":{"start":"995.18","dur":"4.73","text":"the simulators, as well as\nthe controllers in the robots."},"999.91":{"start":"999.91","dur":"2.86","text":"So we have a\npopulation of robots"},"1002.77":{"start":"1002.77","dur":"3","text":"inside each individual\nphysical robot, as it were,"},"1005.77":{"start":"1005.77","dur":"1.43","text":"simulated robots."},"1007.20":{"start":"1007.2","dur":"3.7","text":"But then you also have\na swarm of 10 robots."},"1010.90":{"start":"1010.9","dur":"4.65","text":"And therefore, we have a\npopulation of 10 simulators."},"1015.55":{"start":"1015.55","dur":"2.51","text":"So we actually co-evolve\nhere, the simulators"},"1018.06":{"start":"1018.06","dur":"3.75","text":"and the robot controllers."},"1021.81":{"start":"1021.81","dur":"3.59","text":"So I want to now\nshow you the newer"},"1025.40":{"start":"1025.4","dur":"4.37","text":"work I&#39;ve been doing on\nrobots with internal models."},"1029.77":{"start":"1029.77","dur":"5.569","text":"And primarily-- I was\ntelling [? Yan ?] earlier"},"1035.34":{"start":"1035.339","dur":"3.581","text":"that, you know, I&#39;m kind of\nan old fashioned electronics"},"1038.92":{"start":"1038.92","dur":"0.5","text":"engineer."},"1039.42":{"start":"1039.42","dur":"3.08","text":"Spent much of my career\nbuilding safety systems,"},"1042.50":{"start":"1042.5","dur":"1.15","text":"safety critical systems."},"1043.65":{"start":"1043.65","dur":"3.14","text":"So safety is something\nthat&#39;s very important to me"},"1046.79":{"start":"1046.79","dur":"1.59","text":"and to robotics."},"1048.38":{"start":"1048.38","dur":"2.86","text":"So here&#39;s a kind of\ngeneric internal modeling"},"1051.24":{"start":"1051.24","dur":"2.45","text":"architecture for safety."},"1053.69":{"start":"1053.69","dur":"6.09","text":"So this is, in fact, Dennett&#39;s\nloop of generate and test."},"1059.78":{"start":"1059.78","dur":"2.31","text":"So the idea is that we have\nan internal model, which"},"1062.09":{"start":"1062.09","dur":"4.11","text":"is a self-simulation, that\nis initialized to match"},"1066.20":{"start":"1066.2","dur":"2.55","text":"the current real world."},"1068.75":{"start":"1068.75","dur":"4.42","text":"And then you try out,\nyou run the simulator"},"1073.17":{"start":"1073.17","dur":"3.04","text":"for each of your next\npossible actions."},"1076.21":{"start":"1076.21","dur":"4.26","text":"To put it very simply,\nimagine that you&#39;re a robot,"},"1080.47":{"start":"1080.47","dur":"3.46","text":"and you could either turn left,\nturn right, go straight ahead,"},"1083.93":{"start":"1083.93","dur":"1.02","text":"or stand still."},"1084.95":{"start":"1084.95","dur":"2.77","text":"So you have four\npossible next actions."},"1087.72":{"start":"1087.72","dur":"3.39","text":"And therefore, you&#39;d loop\nthrough this internal model"},"1091.11":{"start":"1091.11","dur":"2.84","text":"for each of those\nnext possible actions."},"1093.95":{"start":"1093.95","dur":"3.96","text":"And then moderate the\naction selection mechanism"},"1097.91":{"start":"1097.91","dur":"1.05","text":"in your controller."},"1098.96":{"start":"1098.96","dur":"2.27","text":"So this is not part\nof the controller."},"1101.23":{"start":"1101.23","dur":"2.47","text":"It&#39;s a kind of\nmoderator, if you like."},"1103.70":{"start":"1103.7","dur":"4.88","text":"So you could imagine\nthat the regular robot"},"1108.58":{"start":"1108.58","dur":"3.76","text":"controller, the thing in\nred, has a set of four"},"1112.34":{"start":"1112.34","dur":"2.33","text":"next possible actions."},"1114.67":{"start":"1114.67","dur":"3.92","text":"But your internal\nmodel determines"},"1118.59":{"start":"1118.59","dur":"3.18","text":"that only two of them are safe."},"1121.77":{"start":"1121.77","dur":"2.58","text":"So it would effectively,\nif you like,"},"1124.35":{"start":"1124.35","dur":"3.91","text":"moderate or govern the\naction selection mechanism"},"1128.26":{"start":"1128.26","dur":"2.4","text":"of the robot&#39;s controller,\nso that the robot"},"1130.66":{"start":"1130.66","dur":"4.931","text":"controller, in fact, will not\nchoose the unsafe actions."},"1138.75":{"start":"1138.75","dur":"5.2","text":"Interestingly, if you have\na learning controller,"},"1143.95":{"start":"1143.95","dur":"5.16","text":"then that&#39;s fine because we\ncan effectively extend or copy"},"1149.11":{"start":"1149.11","dur":"4.26","text":"the learned behaviors\ninto the internal model."},"1153.37":{"start":"1153.37","dur":"1.15","text":"That&#39;s fine."},"1154.52":{"start":"1154.52","dur":"2.15","text":"So in principle-- we\nhaven&#39;t done this."},"1156.67":{"start":"1156.67","dur":"2.52","text":"But we&#39;re starting to do\nit now-- in principle,"},"1159.19":{"start":"1159.19","dur":"5.24","text":"we can extend this architecture\nto, as it were, to adaptive"},"1164.43":{"start":"1164.43","dur":"1.045","text":"or learning robots."},"1168.58":{"start":"1168.58","dur":"2.19","text":"Here&#39;s a simple\nthought experiment."},"1170.77":{"start":"1170.77","dur":"5.53","text":"Imagine a robot with several\nsafety hazards facing it."},"1176.30":{"start":"1176.3","dur":"2.48","text":"It has four next\npossible actions."},"1178.78":{"start":"1178.78","dur":"7.05","text":"Well, your internal\nmodel can figure out"},"1185.83":{"start":"1185.83","dur":"4.59","text":"what the consequence of each\nof those actions might be."},"1190.42":{"start":"1190.42","dur":"7.61","text":"So two of them-- so either\nturn right or stay still"},"1198.03":{"start":"1198.03","dur":"1.16","text":"are safe actions."},"1199.19":{"start":"1199.19","dur":"1.964","text":"So that&#39;s a very simple\nthought experiment."},"1203.95":{"start":"1203.95","dur":"4.48","text":"And here&#39;s a slightly more\ncomplicated thought experiment."},"1208.43":{"start":"1208.43","dur":"1.68","text":"So imagine that\nthe robot, there&#39;s"},"1210.11":{"start":"1210.11","dur":"1.56","text":"another actor in\nthe environment."},"1211.67":{"start":"1211.67","dur":"1.33","text":"It&#39;s a human."},"1213.00":{"start":"1213","dur":"2.15","text":"The human is not looking\nwhere they&#39;re going."},"1215.15":{"start":"1215.15","dur":"2.83","text":"Perhaps walking down the\nstreet peering at a smartphone."},"1217.98":{"start":"1217.98","dur":"2.03","text":"That never happens,\ndoes it, of course."},"1220.01":{"start":"1220.01","dur":"4.72","text":"And about to walk into\na hole in the pavement."},"1224.73":{"start":"1224.73","dur":"5.57","text":"Well, of course, if\nit were you noticing"},"1230.30":{"start":"1230.3","dur":"2.45","text":"that human about to walk\ninto a hole in the pavement,"},"1232.75":{"start":"1232.75","dur":"2.12","text":"you would almost certainly\nintervene, of course."},"1234.87":{"start":"1234.87","dur":"2.66","text":"And it&#39;s not just because\nyou&#39;re a good person."},"1237.53":{"start":"1237.53","dur":"2.56","text":"It&#39;s because you have\nthe cognitive machinery"},"1240.09":{"start":"1240.09","dur":"4.43","text":"to predict the consequences of\nboth your and their actions."},"1244.52":{"start":"1244.52","dur":"1.59","text":"And you can figure\nout that if you"},"1246.11":{"start":"1246.11","dur":"2.455","text":"were to rush over\ntowards them, you"},"1248.57":{"start":"1248.565","dur":"2.375","text":"might be able to prevent them\nfrom falling into the hole."},"1250.94":{"start":"1250.94","dur":"3.19","text":"So here&#39;s the same kind of idea."},"1254.13":{"start":"1254.13","dur":"0.81","text":"But with the robot."},"1254.94":{"start":"1254.94","dur":"2.47","text":"Imagine it&#39;s not\nyou, but a robot."},"1257.41":{"start":"1257.41","dur":"3.83","text":"And imagine now that\nyou are modeling"},"1261.24":{"start":"1261.24","dur":"3.17","text":"the consequences of\nyours and the human&#39;s"},"1264.41":{"start":"1264.41","dur":"4.04","text":"actions for each one of\nyour next possible actions."},"1268.45":{"start":"1268.45","dur":"2.94","text":"And you can see\nthat now this time,"},"1271.39":{"start":"1271.39","dur":"2.45","text":"we&#39;ve given a kind\nof numerical scale."},"1273.84":{"start":"1273.84","dur":"5.53","text":"So 0 is perfectly safe, whereas\n10 is seriously dangerous,"},"1279.37":{"start":"1279.37","dur":"3.94","text":"kind of danger of\ndeath, if you like."},"1283.31":{"start":"1283.31","dur":"4.35","text":"And you can see that\nthe safest outcome"},"1287.66":{"start":"1287.66","dur":"2.27","text":"is if the robot turns right."},"1289.93":{"start":"1289.93","dur":"2.69","text":"In other words, the\nsafest for the human."},"1292.62":{"start":"1292.62","dur":"2.12","text":"I mean, clearly the\nsafest for the robot"},"1294.74":{"start":"1294.74","dur":"2.44","text":"is either turn\nleft or stay still."},"1297.18":{"start":"1297.18","dur":"4.66","text":"But in both cases, the human\nwould fall into the hole."},"1301.84":{"start":"1301.84","dur":"1.84","text":"So you can see that\nwe could actually"},"1303.68":{"start":"1303.68","dur":"4.67","text":"invent a rule which\nwould represent"},"1308.35":{"start":"1308.35","dur":"3.31","text":"the best outcome for the human."},"1311.66":{"start":"1311.66","dur":"2","text":"And this is what it looks like."},"1313.66":{"start":"1313.66","dur":"3.79","text":"So if all robot actions,\nthe human is equally safe,"},"1317.45":{"start":"1317.45","dur":"3.1","text":"then that means that we don&#39;t\nneed to worry about the human,"},"1320.55":{"start":"1320.55","dur":"7.07","text":"so the internal model will\noutput the safest actions"},"1327.62":{"start":"1327.62","dur":"2.05","text":"for the robot."},"1329.67":{"start":"1329.67","dur":"3.97","text":"Else, then output\nthe robot actions"},"1333.64":{"start":"1333.64","dur":"3.58","text":"for the least unsafe\nhuman outcomes."},"1337.22":{"start":"1337.22","dur":"3.895","text":"Now remarkably-- and\nwe didn&#39;t intend this,"},"1341.12":{"start":"1341.115","dur":"2.315","text":"this actually is\nan implementation"},"1343.43":{"start":"1343.43","dur":"2.96","text":"of Asimov&#39;s first\nlaw of robotics."},"1346.39":{"start":"1346.39","dur":"3.22","text":"So a robot may not\ninjure a human being,"},"1349.61":{"start":"1349.61","dur":"1.995","text":"or through inaction--\nthat&#39;s important,"},"1351.61":{"start":"1351.605","dur":"4.495","text":"the or through inaction-- allow\na human being to come to harm."},"1356.10":{"start":"1356.1","dur":"5.33","text":"So we kind of ended up\nbuilding Asimovian robot,"},"1361.43":{"start":"1361.43","dur":"4.62","text":"simple Asimovian ethical robot."},"1366.05":{"start":"1366.05","dur":"2.51","text":"So what does it look like?"},"1368.56":{"start":"1368.56","dur":"3.85","text":"Well, we&#39;ve now extended\nto humanoid robots."},"1372.41":{"start":"1372.41","dur":"1.94","text":"But we started with\nthe e-puck robots,"},"1374.35":{"start":"1374.35","dur":"5.21","text":"these little-- they&#39;re about\nthe size of a salt shaker,"},"1379.56":{"start":"1379.56","dur":"5.21","text":"I guess, about seven\ncentimeters tall."},"1384.77":{"start":"1384.77","dur":"5.18","text":"And this is the little\narena in the lab."},"1389.95":{"start":"1389.95","dur":"6.44","text":"And what we actually have\ninside the ethical robot is--"},"1396.39":{"start":"1396.39","dur":"2.13","text":"this is the internal\narchitecture."},"1398.52":{"start":"1398.52","dur":"4.71","text":"So so you can see that we have\nthe robot controller, which"},"1403.23":{"start":"1403.23","dur":"4.08","text":"is, in fact, a mirror of\nthe real robot controller,"},"1407.31":{"start":"1407.31","dur":"2.69","text":"a model of the robot, and\na model of the world, which"},"1410.00":{"start":"1410","dur":"2.45","text":"includes others in the world."},"1412.45":{"start":"1412.45","dur":"1.24","text":"So this is the simulator."},"1413.69":{"start":"1413.69","dur":"4.84","text":"This is a more or less a\nregular robot simulator."},"1418.53":{"start":"1418.53","dur":"2.39","text":"So you probably know\nthat robot simulators"},"1420.92":{"start":"1420.92","dur":"1.56","text":"are quite commonplace."},"1422.48":{"start":"1422.48","dur":"5.536","text":"We roboticists use them all\nthe time to test robots in,"},"1428.02":{"start":"1428.016","dur":"1.374","text":"as it were, in\nthe virtual world,"},"1429.39":{"start":"1429.39","dur":"2.111","text":"before then trying\nout the code for real."},"1431.50":{"start":"1431.501","dur":"1.749","text":"But what we&#39;ve done\nhere is we&#39;ve actually"},"1433.25":{"start":"1433.25","dur":"6.07","text":"put an off the shelf\nsimulator inside the robot"},"1439.32":{"start":"1439.32","dur":"2.03","text":"and made it work in real time."},"1441.35":{"start":"1441.35","dur":"3.23","text":"So the output of the\nsimulator for each"},"1444.58":{"start":"1444.58","dur":"4.61","text":"of those next possible actions\nis evaluated and then goes"},"1449.19":{"start":"1449.19","dur":"1.94","text":"through a logic layer."},"1451.13":{"start":"1451.13","dur":"3.65","text":"Which is essentially the\nrule, the if then else rule"},"1454.78":{"start":"1454.78","dur":"3.74","text":"that I showed you a\ncouple of slides ago."},"1458.52":{"start":"1458.52","dur":"3.63","text":"And that effectively\ndetermines or moderates"},"1462.15":{"start":"1462.15","dur":"4.618","text":"the action selection\nmechanism of the real robot."},"1469.78":{"start":"1469.78","dur":"1.76","text":"So this is the\nsimulation budget."},"1471.54":{"start":"1471.54","dur":"3.56","text":"So we&#39;re actually using\nthe open source simulator"},"1475.10":{"start":"1475.1","dur":"4","text":"Stage, a well-known simulator."},"1479.10":{"start":"1479.1","dur":"3.18","text":"And in fact, we managed to get\nStage to run about 600 times"},"1482.28":{"start":"1482.28","dur":"2.68","text":"real time."},"1484.96":{"start":"1484.96","dur":"2.28","text":"Which means that\nwe&#39;re actually cycling"},"1487.24":{"start":"1487.24","dur":"2.77","text":"through our internal\nmodel twice a second."},"1490.01":{"start":"1490.01","dur":"3.42","text":"And for each one\nof those cycles,"},"1493.43":{"start":"1493.43","dur":"5.05","text":"we&#39;re actually modeling not four\nbut 30 next possible actions."},"1498.48":{"start":"1498.48","dur":"3.64","text":"And we&#39;re modeling about\n10 seconds into the future."},"1502.12":{"start":"1502.12","dur":"5.15","text":"So every half a second, our\nrobot with an internal model"},"1507.27":{"start":"1507.27","dur":"7.66","text":"is looking ahead 10 seconds for\nabout 30 next possible actions,"},"1514.93":{"start":"1514.93","dur":"2.4","text":"30 of its own next\npossible actions."},"1517.33":{"start":"1517.33","dur":"3.05","text":"But of course, it&#39;s also\nmodeling the consequences"},"1520.38":{"start":"1520.38","dur":"3.1","text":"of each of the other\nactors, dynamic actors"},"1523.48":{"start":"1523.48","dur":"1.99","text":"in its environment."},"1525.47":{"start":"1525.47","dur":"5.317","text":"So this is quite nice to\nactually do this in real time."},"1530.79":{"start":"1530.787","dur":"2.583","text":"And let me show you some of the\nresults that we got from that."},"1533.37":{"start":"1533.37","dur":"3.95","text":"So ignore the kind\nof football pitch."},"1537.32":{"start":"1537.32","dur":"3.27","text":"So what we have here is\nthe ethical robot, which we"},"1540.59":{"start":"1540.59","dur":"3.65","text":"call the A-robot, after Asimov."},"1544.24":{"start":"1544.24","dur":"1.78","text":"And we have a hole\nin the ground."},"1546.02":{"start":"1546.02","dur":"2.57","text":"It&#39;s not a real hole, it&#39;s a\nvirtual hole in the ground."},"1548.59":{"start":"1548.59","dur":"3.26","text":"We don&#39;t need to be digging\nholes into the lab floor."},"1551.85":{"start":"1551.85","dur":"4.26","text":"And we&#39;re using another\ne-perk as a proxy human"},"1556.11":{"start":"1556.11","dur":"1.16","text":"we call this the H-robot."},"1560.12":{"start":"1560.12","dur":"2.17","text":"So let me show\nyou what happened."},"1562.29":{"start":"1562.29","dur":"6.42","text":"Well we ran it, first of\nall, with no H-robot at all,"},"1568.71":{"start":"1568.71","dur":"1.81","text":"as a kind of baseline."},"1570.52":{"start":"1570.52","dur":"3.47","text":"And you can see on\nthe left, in 26 runs,"},"1573.99":{"start":"1573.99","dur":"2.72","text":"those are the traces\nof the A-robot."},"1576.71":{"start":"1576.71","dur":"1.64","text":"So you can see the\nA-robot, in fact,"},"1578.35":{"start":"1578.35","dur":"2.05","text":"is maintaining its own safety."},"1580.40":{"start":"1580.4","dur":"3.34","text":"Its avoiding, its\nskirting around the edge"},"1583.74":{"start":"1583.74","dur":"4.72","text":"almost optimally skirting the\nedge of the hole in the ground."},"1588.46":{"start":"1588.46","dur":"1.92","text":"But then when we\nintroduce the H-robot,"},"1590.38":{"start":"1590.38","dur":"3.19","text":"you get this wonderful\nbehavior here."},"1593.57":{"start":"1593.57","dur":"3.86","text":"Where as soon as the A-robot\nnotices that the H-robot is"},"1597.43":{"start":"1597.43","dur":"2.74","text":"heading towards the hole,\nwhich is about here, then"},"1600.17":{"start":"1600.17","dur":"4.59","text":"it deflects, it diverts\nfrom its original course."},"1604.76":{"start":"1604.76","dur":"4.33","text":"And in fact, more\nor less collides."},"1609.09":{"start":"1609.09","dur":"1.65","text":"They don&#39;t actually\nphysically collide"},"1610.74":{"start":"1610.74","dur":"3.05","text":"because they have low\nlevel collision avoidance."},"1613.79":{"start":"1613.79","dur":"1.44","text":"So they don&#39;t actually collide."},"1615.23":{"start":"1615.23","dur":"2.48","text":"But nevertheless, the\nA-robot effectively"},"1617.71":{"start":"1617.71","dur":"5.05","text":"heads off the H-robot, but\nthen bounces off safely,"},"1622.76":{"start":"1622.76","dur":"2.07","text":"goes off in another direction."},"1624.83":{"start":"1624.83","dur":"5.78","text":"And the A-robot then resumes its\ncourse to its target position."},"1630.61":{"start":"1630.61","dur":"2.01","text":"Which is really nice."},"1632.62":{"start":"1632.62","dur":"4.96","text":"And interestingly, even though\nour simulator is rather low"},"1637.58":{"start":"1637.58","dur":"2.59","text":"fidelity, it doesn&#39;t matter."},"1640.17":{"start":"1640.17","dur":"1.44","text":"Surprisingly, it doesn&#39;t matter."},"1641.61":{"start":"1641.61","dur":"3.11","text":"Because the closer the\nA-robot to the H-robot"},"1644.72":{"start":"1644.72","dur":"4.58","text":"gets, then the better its\npredictions about colliding."},"1649.30":{"start":"1649.3","dur":"3.75","text":"So this is why, even with a\nrather low fidelity simulator,"},"1653.05":{"start":"1653.05","dur":"6.93","text":"we can collide with really good\nprecision with the H-robot."},"1659.98":{"start":"1659.98","dur":"7.95","text":"So let me show you the movies of\nthis trial with a single proxy"},"1667.93":{"start":"1667.93","dur":"1.75","text":"human."},"1669.68":{"start":"1669.68","dur":"5.79","text":"And I think the movie starts\nin-- so this is real time."},"1675.47":{"start":"1675.47","dur":"4.35","text":"And you can see the\nA-robot nicely heading off"},"1679.82":{"start":"1679.82","dur":"3.68","text":"the H-robot which\nthen disappears off"},"1683.50":{"start":"1683.5","dur":"1","text":"towards the left."},"1687.94":{"start":"1687.94","dur":"3.66","text":"I think then we&#39;ve\nspeeded it four times."},"1691.60":{"start":"1691.6","dur":"2.98","text":"And this is a\nwhole load of runs."},"1694.58":{"start":"1694.58","dur":"3.18","text":"So you can see that\nit really does work."},"1697.76":{"start":"1697.76","dur":"3.15","text":"And also notice that every\nexperiment is a bit different."},"1700.91":{"start":"1700.91","dur":"2.1","text":"And of course, that&#39;s what\ntypically happens when"},"1703.01":{"start":"1703.01","dur":"2.76","text":"you have real physical robots."},"1705.77":{"start":"1705.77","dur":"2.65","text":"Simply because of the\nnoise in the system,"},"1708.42":{"start":"1708.42","dur":"3.05","text":"the fact that these are real\nrobots with imperfect motors"},"1711.47":{"start":"1711.47","dur":"1.537","text":"and sensors and what have you."},"1715.88":{"start":"1715.88","dur":"5.7","text":"So we wrote the paper\nand were about to submit"},"1721.58":{"start":"1721.58","dur":"2.09","text":"the paper, when we\nkind of thought, well,"},"1723.67":{"start":"1723.67","dur":"1.42","text":"this is a bit boring, isn&#39;t it?"},"1725.09":{"start":"1725.09","dur":"4.39","text":"We built this\nrobot and it works."},"1729.48":{"start":"1729.48","dur":"7.65","text":"So we had the idea to put a\nsecond human in the-- oh sorry."},"1737.13":{"start":"1737.13","dur":"1.32","text":"I&#39;ve forgotten one slide."},"1738.45":{"start":"1738.45","dur":"2.04","text":"So before I get to\nthat, I just wanted"},"1740.49":{"start":"1740.49","dur":"8.08","text":"to show you a little animation\nof-- these little filaments"},"1748.57":{"start":"1748.57","dur":"6.13","text":"here are the traces of the\nA-robot and its prediction"},"1754.70":{"start":"1754.7","dur":"1.78","text":"of what might happen."},"1756.48":{"start":"1756.48","dur":"2.84","text":"So at the point\nwhere this turns red,"},"1759.32":{"start":"1759.32","dur":"2.5","text":"the A-robot then\nstarts to intersect."},"1761.82":{"start":"1761.82","dur":"4.68","text":"And each one of those\ntraces is its prediction"},"1766.50":{"start":"1766.5","dur":"4.7","text":"of the consequences of both\nitself and the H-robot."},"1771.20":{"start":"1771.2","dur":"6.37","text":"This is really nice because you\ncan kind of look into the mind,"},"1777.57":{"start":"1777.57","dur":"3.2","text":"to put it that\nway, of the robot,"},"1780.77":{"start":"1780.77","dur":"2","text":"and actually see\nwhat it&#39;s doing."},"1782.77":{"start":"1782.77","dur":"2.45","text":"Which is very nice, very cool."},"1785.22":{"start":"1785.22","dur":"6.6","text":"But I was about to say we tried\nthe same experiment, in fact,"},"1791.82":{"start":"1791.82","dur":"3.78","text":"identical code,\nwith two H-robots."},"1795.60":{"start":"1795.6","dur":"3.53","text":"And this is the robot&#39;s dilemma."},"1799.13":{"start":"1799.13","dur":"2.95","text":"This may be the first time\nthat a real physical robot"},"1802.08":{"start":"1802.08","dur":"3.16","text":"has faced an ethical dilemma."},"1805.24":{"start":"1805.24","dur":"3","text":"So you can see the two\nH-robots are more or less"},"1808.24":{"start":"1808.24","dur":"2.54","text":"equidistant from the hole."},"1810.78":{"start":"1810.78","dur":"3.24","text":"And there is the\nA-robot which, in fact,"},"1814.02":{"start":"1814.02","dur":"4.64","text":"fails to save either of them."},"1818.66":{"start":"1818.66","dur":"3.76","text":"So what&#39;s going on there?"},"1822.42":{"start":"1822.42","dur":"4.01","text":"We know that it can save\none of them every time."},"1826.43":{"start":"1826.43","dur":"2.14","text":"But in fact, it&#39;s just\nfailed to save either."},"1831.24":{"start":"1831.24","dur":"3.07","text":"And oh, yeah, it does\nactually save one of them."},"1834.31":{"start":"1834.31","dur":"3.91","text":"And has a look at the other\none, but it&#39;s too late."},"1838.22":{"start":"1838.22","dur":"3.43","text":"So this is really\nvery interesting."},"1841.65":{"start":"1841.65","dur":"1.815","text":"And not at all what we expected."},"1851.81":{"start":"1851.81","dur":"2.83","text":"In fact, let me show\nyou the statistics."},"1854.64":{"start":"1854.64","dur":"11.14","text":"So in 33 runs, the\nethical robot failed"},"1865.78":{"start":"1865.78","dur":"5.35","text":"to save either of the H-robots\njust under half the time."},"1871.13":{"start":"1871.13","dur":"3.8","text":"So about 14 times, it\nfailed to save either."},"1874.93":{"start":"1874.93","dur":"4.64","text":"It saved one of them just\nover 15, perhaps 16 times."},"1879.57":{"start":"1879.57","dur":"2.6","text":"And amazingly, saved\nboth of them twice,"},"1882.17":{"start":"1882.17","dur":"3.01","text":"which is quite surprising."},"1885.18":{"start":"1885.18","dur":"2.01","text":"It really should perform\nbetter than that."},"1890.54":{"start":"1890.54","dur":"3.14","text":"And in fact, when we started\nto really look at this,"},"1893.68":{"start":"1893.68","dur":"2.74","text":"we discovered that\nthe-- so here&#39;s"},"1896.42":{"start":"1896.42","dur":"3.11","text":"a particularly good\nexample of dithering."},"1899.53":{"start":"1899.53","dur":"4.72","text":"So we realized\nthat we made a sort"},"1904.25":{"start":"1904.25","dur":"2.922","text":"of pathologically\nindecisive ethical robot."},"1907.17":{"start":"1907.172","dur":"1.958","text":"So I&#39;m going to save this\none-- oh no, no, that"},"1909.13":{"start":"1909.13","dur":"1.97","text":"one-- oh no, no,\nthis one-- that one."},"1911.10":{"start":"1911.1","dur":"3.36","text":"And of course, by the\ntime our ethical robot"},"1914.46":{"start":"1914.46","dur":"2.48","text":"has changed its mind\nthree or four times,"},"1916.94":{"start":"1916.94","dur":"1.41","text":"well, it&#39;s too late."},"1918.35":{"start":"1918.35","dur":"1.07","text":"So this is the problem."},"1919.42":{"start":"1919.42","dur":"5.68","text":"The problem, fundamentally,\nis that our ethical robot"},"1925.10":{"start":"1925.1","dur":"3.21","text":"doesn&#39;t make a decision\nand stick to it."},"1928.31":{"start":"1928.31","dur":"2.39","text":"In fact, it&#39;s a\nconsequence of the fact"},"1930.70":{"start":"1930.7","dur":"4.26","text":"that we are running\nour consequence engine,"},"1934.96":{"start":"1934.96","dur":"1.94","text":"as I mentioned, twice a second."},"1936.90":{"start":"1936.9","dur":"2.35","text":"So every half a second,\nour ethical robot"},"1939.25":{"start":"1939.25","dur":"2.6","text":"has the opportunity\nto change its mind."},"1941.85":{"start":"1941.85","dur":"1.68","text":"That&#39;s clearly a bad strategy."},"1943.53":{"start":"1943.53","dur":"3.27","text":"But nevertheless, it\nwas an interesting kind"},"1946.80":{"start":"1946.8","dur":"5.58","text":"of unexpected consequence\nof the experiment."},"1952.38":{"start":"1952.38","dur":"3.76","text":"We&#39;ve now transferred the\nwork to these humanoid robots."},"1956.14":{"start":"1956.14","dur":"2.03","text":"And we get the same thing."},"1958.17":{"start":"1958.17","dur":"2.9","text":"So here, there\nare two red robots"},"1961.07":{"start":"1961.07","dur":"1.94","text":"both heading toward danger."},"1963.01":{"start":"1963.01","dur":"3.68","text":"The blue one, the ethical\nrobot, changes its mind,"},"1966.69":{"start":"1966.69","dur":"1.98","text":"and goes and saves\nthe one on the left,"},"1968.67":{"start":"1968.67","dur":"2.54","text":"even though it could have\nsaved the one on the right."},"1971.21":{"start":"1971.21","dur":"8.58","text":"So another example of our\ndithering ethical robot."},"1979.79":{"start":"1979.79","dur":"4.17","text":"And as I&#39;ve just\nhinted at, the reason"},"1983.96":{"start":"1983.96","dur":"2.38","text":"that there our ethical\nrobot is so indecisive"},"1986.34":{"start":"1986.34","dur":"3.51","text":"is because it&#39;s essentially\na memory-less architecture."},"1989.85":{"start":"1989.85","dur":"5.62","text":"So you could say that the\nrobot has a-- again, borrowing"},"1995.47":{"start":"1995.47","dur":"4.09","text":"Owen Holland&#39;s description, it\nhas a functional imagination."},"1999.56":{"start":"1999.56","dur":"2.05","text":"But it has no\nautobiographical memory."},"2001.61":{"start":"2001.61","dur":"1.92","text":"So it doesn&#39;t\nremember the decision"},"2003.53":{"start":"2003.53","dur":"2.04","text":"it made half a second ago."},"2005.57":{"start":"2005.57","dur":"3.78","text":"Which is clearly\nnot a good strategy."},"2009.35":{"start":"2009.35","dur":"3.77","text":"Really, an ethical\nrobot, just like you"},"2013.12":{"start":"2013.12","dur":"3.29","text":"if you are acting in\na similar situation,"},"2016.41":{"start":"2016.41","dur":"2","text":"it&#39;s probably a\ngood idea for you"},"2018.41":{"start":"2018.41","dur":"2.53","text":"to stick to the first\ndecision that you made."},"2020.94":{"start":"2020.94","dur":"2.42","text":"But probably not forever."},"2023.36":{"start":"2023.36","dur":"2.34","text":"So you know, I think\nthe decisions probably"},"2025.70":{"start":"2025.7","dur":"1.99","text":"need to be sticky somehow."},"2027.69":{"start":"2027.69","dur":"3.58","text":"So decisions like this\nmay need a half life."},"2031.27":{"start":"2031.27","dur":"3.38","text":"You know, sticky but not\nbut not absolutely rigid."},"2034.65":{"start":"2034.65","dur":"3.964","text":"So actually, at this\npoint, we decided"},"2038.61":{"start":"2038.614","dur":"2.416","text":"that we&#39;re not going to worry\ntoo much about this problem."},"2041.03":{"start":"2041.03","dur":"3.47","text":"Because in a sense, this is\nmore of a problem for ethicists"},"2044.50":{"start":"2044.5","dur":"1.929","text":"than engineers, perhaps."},"2046.43":{"start":"2046.429","dur":"0.541","text":"I don&#39;t know."},"2046.97":{"start":"2046.97","dur":"1.619","text":"But maybe we could\ntalk about that."},"2051.68":{"start":"2051.679","dur":"2.721","text":"Before finishing,\nI want to show you"},"2054.40":{"start":"2054.4","dur":"2.839","text":"another experiment that we did\nwith the same architecture,"},"2057.24":{"start":"2057.239","dur":"1.991","text":"exactly the same architecture."},"2059.23":{"start":"2059.23","dur":"3.09","text":"And this is what we call\nthe corridor experiment."},"2062.32":{"start":"2062.32","dur":"5.58","text":"So here we have a robot\nwith this internal model."},"2067.90":{"start":"2067.9","dur":"4.17","text":"And it has to get from the\nleft hand to the right hand"},"2072.07":{"start":"2072.07","dur":"3.18","text":"of a crowded corridor\nwithout bumping"},"2075.25":{"start":"2075.25","dur":"3.32","text":"into any of the other robots\nthat are in the same corridor."},"2078.57":{"start":"2078.57","dur":"4.06","text":"So imagine you&#39;re walking\ndown a corridor in an airport"},"2082.63":{"start":"2082.63","dur":"2.589","text":"and everybody else is coming\nin the opposite direction."},"2085.22":{"start":"2085.219","dur":"2.77","text":"And you want to try and get to\nthe other end of the corridor"},"2087.99":{"start":"2087.989","dur":"1.761","text":"without crashing\ninto any of them."},"2089.75":{"start":"2089.75","dur":"3.86","text":"But in fact, you have a\nrather large body space."},"2093.61":{"start":"2093.61","dur":"2.7","text":"You don&#39;t want to get\neven close to any of them."},"2096.31":{"start":"2096.31","dur":"5.39","text":"So you want to maintain\nyour private body space."},"2101.70":{"start":"2101.7","dur":"4.77","text":"And what the blue\nrobot here is doing"},"2106.47":{"start":"2106.47","dur":"4.86","text":"is, in fact, modeling the\nconsequences of its actions"},"2111.33":{"start":"2111.33","dur":"2.77","text":"and the other ones within\nthis radius of attention."},"2114.10":{"start":"2114.1","dur":"2.76","text":"So this blue circle is\na radius of attention."},"2116.86":{"start":"2116.86","dur":"4.29","text":"So here, we&#39;re looking at a\nsimple attention mechanism."},"2121.15":{"start":"2121.15","dur":"3.57","text":"Which is only worry about\nthe other dynamic actors"},"2124.72":{"start":"2124.72","dur":"3.19","text":"within your radius of attention."},"2127.91":{"start":"2127.91","dur":"2.64","text":"In fact, we don&#39;t even worry\nabout ones that are behind us."},"2130.55":{"start":"2130.55","dur":"2.82","text":"It&#39;s only the ones that are\nmore or less in front of us."},"2133.37":{"start":"2133.37","dur":"5.59","text":"And you can see that the\nrobot does eventually make it"},"2138.96":{"start":"2138.96","dur":"1.19","text":"to the end of the corridor."},"2140.15":{"start":"2140.15","dur":"4.84","text":"But with lots of kind\nof stops and back tracks"},"2144.99":{"start":"2144.99","dur":"2.05","text":"in order to prevent it\nfrom-- because it&#39;s really"},"2147.04":{"start":"2147.04","dur":"3.585","text":"frightened of any kind of\ncontact with the other robots."},"2153.59":{"start":"2153.59","dur":"5.83","text":"And here, we&#39;re not\nshowing all of the sort"},"2159.42":{"start":"2159.42","dur":"1.7","text":"of filaments of prediction."},"2161.12":{"start":"2161.12","dur":"1.925","text":"Only the ones that are chosen."},"2168.96":{"start":"2168.96","dur":"4.4","text":"And here are some results\nwhich interestingly show us--"},"2173.36":{"start":"2173.36","dur":"6.19","text":"so perhaps the best one to\nlook at is this danger ratio."},"2179.55":{"start":"2179.55","dur":"7.26","text":"And dumb simply means robots\nwith no internal model at all."},"2186.81":{"start":"2186.81","dur":"4.98","text":"And intelligent means\nrobots with internal models."},"2191.79":{"start":"2191.79","dur":"4.04","text":"So here, the danger ratio\nis the number of times"},"2195.83":{"start":"2195.83","dur":"3.02","text":"that you actually come\nclose to another robot."},"2198.85":{"start":"2198.85","dur":"2.35","text":"And of course it&#39;s very high."},"2201.20":{"start":"2201.2","dur":"2.97","text":"This is simulated\nin real robots."},"2204.17":{"start":"2204.17","dur":"3.126","text":"Very good correlation between\nthe real and simulated."},"2207.30":{"start":"2207.296","dur":"2.964","text":"And with the intelligent\nrobot, the robot"},"2210.26":{"start":"2210.26","dur":"3.36","text":"with the internal model, we\nget a really very much safer"},"2213.62":{"start":"2213.62","dur":"1.71","text":"performance."},"2215.33":{"start":"2215.33","dur":"3.78","text":"Clearly there is some\ncost in the sense"},"2219.11":{"start":"2219.11","dur":"4.83","text":"that, for instance,\nthe intelligent robot"},"2223.94":{"start":"2223.94","dur":"3.05","text":"runs with internal models\ntend to cover more ground."},"2226.99":{"start":"2226.99","dur":"3.74","text":"But surprisingly, not that\nmuch further distance."},"2230.73":{"start":"2230.73","dur":"1.64","text":"It&#39;s less than you&#39;d expect."},"2232.37":{"start":"2232.37","dur":"2.56","text":"And clearly, there&#39;s\na computational cost."},"2234.93":{"start":"2234.93","dur":"2.82","text":"Because the computational\ncost of simulating clearly"},"2237.75":{"start":"2237.75","dur":"4.45","text":"is zero for the dumb robots,\nwhereas it&#39;s quite high for"},"2242.20":{"start":"2242.2","dur":"3.74","text":"the intelligent robot, the\nrobot with internal models."},"2245.94":{"start":"2245.94","dur":"3.21","text":"But again, computation is\nrelatively free these days."},"2249.15":{"start":"2249.15","dur":"2.05","text":"So actually, we&#39;re\ntrading safety"},"2251.20":{"start":"2251.2","dur":"4.76","text":"for computation, which I\nthink is a good trade off."},"2255.96":{"start":"2255.96","dur":"5","text":"So really, I want\nto conclude there."},"2260.96":{"start":"2260.96","dur":"2.89","text":"I&#39;ve not, of course,\ntalked about all aspects"},"2263.85":{"start":"2263.85","dur":"1.53","text":"of robot intelligence."},"2265.38":{"start":"2265.38","dur":"1.85","text":"That would be a\nthree hour seminar."},"2267.23":{"start":"2267.23","dur":"3.32","text":"And even then, I wouldn&#39;t\nbe able to cover it all."},"2270.55":{"start":"2270.55","dur":"3.33","text":"But what I hope I&#39;ve shown\nyou in the last few minutes"},"2273.88":{"start":"2273.88","dur":"4.28","text":"is that with internal\nmodels, we have"},"2278.16":{"start":"2278.16","dur":"2.86","text":"a very powerful generic\narchitecture which we could"},"2281.02":{"start":"2281.02","dur":"3.9","text":"call a functional imagination."},"2284.92":{"start":"2284.92","dur":"3.28","text":"And this is where I&#39;m being\na little bit speculative."},"2288.20":{"start":"2288.2","dur":"2.13","text":"Perhaps this moves\nus in the direction"},"2290.33":{"start":"2290.33","dur":"4.1","text":"of artificial theory of mind,\nperhaps even self-awareness."},"2294.43":{"start":"2294.43","dur":"2.37","text":"I&#39;m not going to use the\nword machine consciousness."},"2296.80":{"start":"2296.8","dur":"0.75","text":"Well, I just have."},"2297.55":{"start":"2297.55","dur":"6.07","text":"But that&#39;s a very much more\ndifficult goal, I think."},"2303.62":{"start":"2303.62","dur":"2.56","text":"And I think there\nis practical value,"},"2306.18":{"start":"2306.18","dur":"4.9","text":"I think there&#39;s real practical\nvalue in robotics of robots"},"2311.08":{"start":"2311.08","dur":"3.69","text":"with self and other simulation."},"2314.77":{"start":"2314.77","dur":"2.57","text":"Because as I hope\nI&#39;ve demonstrated,"},"2317.34":{"start":"2317.34","dur":"3.76","text":"at least in a kind of prototype\nsense, proof of concept,"},"2321.10":{"start":"2321.1","dur":"4.61","text":"that such simulation moves\nus towards safer and possibly"},"2325.71":{"start":"2325.71","dur":"4.82","text":"ethical systems in\nunpredictable environments"},"2330.53":{"start":"2330.53","dur":"2.1","text":"with other dynamic actors."},"2332.63":{"start":"2332.63","dur":"2.72","text":"So thank you very much\nindeed for listening."},"2335.35":{"start":"2335.35","dur":"3.3","text":"I&#39;d obviously be delighted\nto take any questions."},"2338.65":{"start":"2338.65","dur":"1.09","text":"Thank you."},"2339.74":{"start":"2339.74","dur":"3.64","text":"[APPLAUSE]"},"2345.77":{"start":"2345.77","dur":"2.39","text":"HOST: Thank you very much for\nthis very fascinating view"},"2348.16":{"start":"2348.16","dur":"1.8","text":"on robotics today."},"2349.96":{"start":"2349.96","dur":"1.59","text":"We have time for questions."},"2351.55":{"start":"2351.55","dur":"2.56","text":"Please wait until you&#39;ve\ngot a microphone so we have"},"2354.11":{"start":"2354.11","dur":"1.63","text":"the answer also on the video."},"2360.55":{"start":"2360.55","dur":"5.24","text":"AUDIENCE: The game playing\ncomputers-- or perhaps more"},"2365.79":{"start":"2365.79","dur":"3.64","text":"accurately would be saying\ngame playing algorithms,"},"2369.43":{"start":"2369.43","dur":"4.04","text":"predated the examples\nyou listed as computers"},"2373.47":{"start":"2373.47","dur":"1.59","text":"with internal models."},"2375.06":{"start":"2375.06","dur":"2.16","text":"Still, you didn&#39;t mention those."},"2377.22":{"start":"2377.22","dur":"4.47","text":"Is there a particular\nreason why you didn&#39;t?"},"2381.69":{"start":"2381.69","dur":"2.42","text":"ALAN WINFIELD: I guess I\nshould have mentioned them."},"2384.11":{"start":"2384.11","dur":"0.9","text":"You&#39;re quite right."},"2385.01":{"start":"2385.01","dur":"2.69","text":"I mean, the-- what\nI&#39;m thinking of here"},"2387.70":{"start":"2387.7","dur":"4.34","text":"is particularly robots\nwith explicit simulations"},"2392.04":{"start":"2392.04","dur":"2.43","text":"of themselves and the world."},"2394.47":{"start":"2394.47","dur":"3.46","text":"So I was limiting my examples\nto simulations of themselves"},"2397.93":{"start":"2397.93","dur":"0.71","text":"in the world."},"2398.64":{"start":"2398.64","dur":"1.92","text":"I mean, you&#39;re quite\nright that of course"},"2400.56":{"start":"2400.56","dur":"4.44","text":"game-playing algorithms need to\nhave a simulation of the game."},"2405.00":{"start":"2405","dur":"2.68","text":"And quite likely,\nof the-- in fact,"},"2407.68":{"start":"2407.68","dur":"5.55","text":"certainly, of the possible\nmoves of the opponent,"},"2413.23":{"start":"2413.23","dur":"4.604","text":"as well as the game-playing\nAI&#39;s own moves."},"2417.83":{"start":"2417.834","dur":"0.916","text":"So you&#39;re quite right."},"2418.75":{"start":"2418.75","dur":"2.26","text":"I mean, it&#39;s a different\nkind of simulation."},"2421.01":{"start":"2421.01","dur":"1.999","text":"But I should include that."},"2423.01":{"start":"2423.009","dur":"0.541","text":"You&#39;re right."},"2426.07":{"start":"2426.07","dur":"1.83","text":"AUDIENCE: Hi there."},"2427.90":{"start":"2427.9","dur":"6.15","text":"In your simulation, you had\nthe H-robot with one goal,"},"2434.05":{"start":"2434.05","dur":"2.73","text":"and the A-robot with\na different goal."},"2436.78":{"start":"2436.78","dur":"2.76","text":"And they interacted\nwith each other halfway"},"2439.54":{"start":"2439.54","dur":"1.93","text":"through the goals."},"2441.47":{"start":"2441.47","dur":"3.82","text":"What happens when they\nhave the same goal?"},"2445.29":{"start":"2445.29","dur":"1.465","text":"ALAN WINFIELD: The same goal."},"2446.76":{"start":"2446.755","dur":"3.465","text":"AUDIENCE: Reaching the\nsame spot, for example."},"2450.22":{"start":"2450.22","dur":"2.145","text":"ALAN WINFIELD: I don&#39;t\nknow is the short answer."},"2455.06":{"start":"2455.06","dur":"4.53","text":"It depends on whether that\nspot is a safe spot or not."},"2459.59":{"start":"2459.59","dur":"4.93","text":"I mean, if it&#39;s a safe spot,\nthen they&#39;ll both go toward it."},"2464.52":{"start":"2464.52","dur":"3.14","text":"They&#39;ll both reach it,\nbut without crashing"},"2467.66":{"start":"2467.66","dur":"1.1","text":"into each other."},"2468.76":{"start":"2468.76","dur":"2.64","text":"Because the A-robot\nwill make sure"},"2471.40":{"start":"2471.4","dur":"2.622","text":"that it avoids the H-robot."},"2474.02":{"start":"2474.022","dur":"1.458","text":"In fact, that&#39;s\nmore or less what&#39;s"},"2475.48":{"start":"2475.48","dur":"2.58","text":"happening in the\ncorridor experiment."},"2478.06":{"start":"2478.06","dur":"0.81","text":"That&#39;s right."},"2478.87":{"start":"2478.87","dur":"0.56","text":"Yeah."},"2479.43":{"start":"2479.43","dur":"2.25","text":"But it&#39;s a good question,\nwe should try that."},"2493.79":{"start":"2493.785","dur":"1.375","text":"AUDIENCE: The\nsimulation that you"},"2495.16":{"start":"2495.16","dur":"2.92","text":"did for the corridor experiment,\nthe actual real world"},"2498.08":{"start":"2498.08","dur":"4.23","text":"experiment, the simulation\ntrack the other robots"},"2502.31":{"start":"2502.31","dur":"0.75","text":"movements as well?"},"2503.06":{"start":"2503.06","dur":"1.791","text":"Meaning what information\ndid the simulation"},"2504.85":{"start":"2504.851","dur":"3.2","text":"have that it began with,\nversus what did it perceive?"},"2508.05":{"start":"2508.051","dur":"1.874","text":"Because, I mean, the\nother robots are moving."},"2509.93":{"start":"2509.925","dur":"1.775","text":"And in the real\nworld, they might not"},"2511.70":{"start":"2511.7","dur":"1.76","text":"move as you predict them to be."},"2513.46":{"start":"2513.46","dur":"4.04","text":"How did the blue robot\nactually know for each step"},"2517.50":{"start":"2517.5","dur":"1.18","text":"where the robots were?"},"2518.68":{"start":"2518.68","dur":"1.75","text":"ALAN WINFIELD: Sure."},"2520.43":{"start":"2520.43","dur":"1.92","text":"That&#39;s a very good question."},"2522.35":{"start":"2522.35","dur":"2.82","text":"In fact we cheated,\nin the sense that we"},"2525.17":{"start":"2525.17","dur":"2.13","text":"used-- for the real\nrobot experiments,"},"2527.30":{"start":"2527.3","dur":"3.07","text":"we used a tracking system."},"2530.37":{"start":"2530.37","dur":"6.18","text":"Which means that essentially\nthe robot with an internal model"},"2536.55":{"start":"2536.55","dur":"2.93","text":"has access to the position."},"2539.48":{"start":"2539.48","dur":"4.58","text":"It&#39;s like a GPS,\ninternal GPS system."},"2544.06":{"start":"2544.06","dur":"2.752","text":"But in a way, that&#39;s\nreally just a kind"},"2546.81":{"start":"2546.812","dur":"6.918","text":"of-- it&#39;s kind of cheating,\nbut even a robot with a vision"},"2553.73":{"start":"2553.73","dur":"3.28","text":"system would be able\nto track all the robots"},"2557.01":{"start":"2557.01","dur":"2.38","text":"in its field of vision."},"2559.39":{"start":"2559.39","dur":"4.51","text":"And as for the second\npart of your question,"},"2563.90":{"start":"2563.9","dur":"3.28","text":"our kind of model of what\nthe other robot that would do"},"2567.18":{"start":"2567.18","dur":"0.76","text":"is very simple."},"2567.94":{"start":"2567.94","dur":"2.29","text":"Which is it&#39;s kind\nof a ballistic model."},"2570.23":{"start":"2570.23","dur":"3.26","text":"Which is if a robot is\nmoving at a particular speed"},"2573.49":{"start":"2573.49","dur":"1.78","text":"in a particular\ndirection, then we"},"2575.27":{"start":"2575.27","dur":"3.97","text":"assume it will continue to\ndo so until it encounters"},"2579.24":{"start":"2579.24","dur":"0.6","text":"an obstacle."},"2582.82":{"start":"2582.82","dur":"3.36","text":"So very simple kind\nof ballistic model."},"2586.18":{"start":"2586.18","dur":"5.25","text":"Which even for humans is useful\nfor very simple behaviors,"},"2591.43":{"start":"2591.43","dur":"1.79","text":"like moving in a crowded space."},"2600.38":{"start":"2600.38","dur":"2.34","text":"Oh hi."},"2602.72":{"start":"2602.72","dur":"2.46","text":"AUDIENCE: In the\nsame experiment--"},"2605.18":{"start":"2605.18","dur":"2.43","text":"it&#39;s a continuation of\nthe previous question."},"2607.61":{"start":"2607.61","dur":"2.74","text":"So in between some of\nthe red robots, how"},"2610.35":{"start":"2610.35","dur":"4.73","text":"changed their direction\nrandomly-- I guess so."},"2615.08":{"start":"2615.08","dur":"4.31","text":"Does the internal model of\nthe blue robot consider that?"},"2619.39":{"start":"2619.39","dur":"1.25","text":"ALAN WINFIELD: Not explicitly."},"2620.64":{"start":"2620.64","dur":"5.02","text":"But it does in the\nsense that because it&#39;s"},"2625.66":{"start":"2625.66","dur":"3.82","text":"pre- or re-initializing it&#39;s\ninternal model every half"},"2629.48":{"start":"2629.48","dur":"4.92","text":"a second, then if the positions\nand directions of the actors"},"2634.40":{"start":"2634.4","dur":"2.41","text":"in its environment\nare changed, then they"},"2636.81":{"start":"2636.81","dur":"3.56","text":"will reflect the new positions."},"2640.37":{"start":"2640.37","dur":"0.57","text":"So--"},"2640.94":{"start":"2640.94","dur":"2.05","text":"AUDIENCE: Not exactly\nthe positions."},"2642.99":{"start":"2642.99","dur":"3.27","text":"But as you said, you have\nconsidered the ballistic motion"},"2646.26":{"start":"2646.26","dur":"1.29","text":"of the objects."},"2647.55":{"start":"2647.55","dur":"4.27","text":"So if there is any randomness\nin the environment-- so"},"2651.82":{"start":"2651.82","dur":"2.66","text":"does the internal\nmodel of the blue robot"},"2654.48":{"start":"2654.48","dur":"2.5","text":"consider the\nrandomness, and change"},"2656.98":{"start":"2656.98","dur":"2.45","text":"the view of the red robots?"},"2659.43":{"start":"2659.43","dur":"3.2","text":"It&#39;s like it views the red\nrobot as a ballistic motion."},"2662.63":{"start":"2662.63","dur":"3.78","text":"So does it change its\nview of the red robot"},"2666.41":{"start":"2666.41","dur":"4.13","text":"that red robots more in\nthe ballistic motion?"},"2670.54":{"start":"2670.54","dur":"2.75","text":"ALAN WINFIELD: Well, it&#39;s\na very good question."},"2673.29":{"start":"2673.29","dur":"1.58","text":"I think the answer is no."},"2674.87":{"start":"2674.87","dur":"5.24","text":"I think we&#39;re probably assuming\na more or less deterministic"},"2680.11":{"start":"2680.11","dur":"3","text":"model of the world."},"2683.11":{"start":"2683.11","dur":"3.08","text":"Deterministic, yes, I think\npretty much deterministic."},"2686.19":{"start":"2686.19","dur":"2.26","text":"But we&#39;re relying\non the fact that we"},"2688.45":{"start":"2688.45","dur":"3.92","text":"are updating and\nrerunning the model,"},"2692.37":{"start":"2692.37","dur":"3.32","text":"reinitializing and rerunning\nthe model every half a second,"},"2695.69":{"start":"2695.69","dur":"3.66","text":"to, if you like, track\nthe stochasticity which is"},"2699.35":{"start":"2699.35","dur":"3.3","text":"inevitable in the real world."},"2702.65":{"start":"2702.65","dur":"4.4","text":"We probably do need to\nintroduce some stochasticity"},"2707.05":{"start":"2707.05","dur":"2.74","text":"into the internal model, yes."},"2709.79":{"start":"2709.79","dur":"1.967","text":"But not yet."},"2711.76":{"start":"2711.757","dur":"0.833","text":"AUDIENCE: Thank you."},"2712.59":{"start":"2712.59","dur":"1.593","text":"ALAN WINFIELD: But\nvery good question."},"2717.29":{"start":"2717.29","dur":"1.062","text":"AUDIENCE: Hello."},"2718.35":{"start":"2718.352","dur":"2.338","text":"With real life applications\nwith this technology,"},"2720.69":{"start":"2720.69","dur":"3.36","text":"like driverless\ncars, for example,"},"2724.05":{"start":"2724.05","dur":"3.13","text":"I think it becomes a lot more\nimportant how you program"},"2727.18":{"start":"2727.18","dur":"2.23","text":"the robots in terms of ethics."},"2729.41":{"start":"2729.41","dur":"4.24","text":"So I mean, there could be\ndilemma like if the robot has"},"2733.65":{"start":"2733.65","dur":"2.4","text":"a choice between saving\na school bus full of kids"},"2736.05":{"start":"2736.05","dur":"5.37","text":"versus one driver, that logic\nneeds to be programmed, right?"},"2741.42":{"start":"2741.42","dur":"3.45","text":"And you made a distinction\nbetween being an engineer"},"2744.87":{"start":"2744.87","dur":"2.87","text":"yourself and then had\nbeen an ethicist earlier."},"2747.74":{"start":"2747.74","dur":"3.62","text":"So to what extent\nis the engineer"},"2751.36":{"start":"2751.36","dur":"1.85","text":"responsible in that case?"},"2753.21":{"start":"2753.21","dur":"4.29","text":"And also does a project\nlike this in real life"},"2757.50":{"start":"2757.5","dur":"1.752","text":"always require the ethicist?"},"2759.25":{"start":"2759.252","dur":"2.918","text":"How do you see this field\nin real life applications"},"2762.17":{"start":"2762.17","dur":"1.07","text":"evolving?"},"2763.24":{"start":"2763.24","dur":"0.833","text":"ALAN WINFIELD: Sure."},"2764.07":{"start":"2764.073","dur":"2.597","text":"That&#39;s a really great question."},"2766.67":{"start":"2766.67","dur":"4.63","text":"I mean, you&#39;re right that\ndriverless cars will-- well,"},"2771.30":{"start":"2771.3","dur":"4.23","text":"it&#39;s debatable whether they will\nhave to make such decisions."},"2775.53":{"start":"2775.53","dur":"4.09","text":"But many people think they will\nhave to make such decisions."},"2779.62":{"start":"2779.62","dur":"3.41","text":"Which are kind of the driverless\ncar equivalent of the trolley"},"2783.03":{"start":"2783.03","dur":"4.57","text":"problem, which is a well-known\nkind of ethical dilemma thought"},"2787.60":{"start":"2787.6","dur":"1.71","text":"experiment."},"2789.31":{"start":"2789.31","dur":"5.87","text":"Now my view is\nthat the rules will"},"2795.18":{"start":"2795.18","dur":"3.98","text":"need to be decided not by the\nengineers, but if you like,"},"2799.16":{"start":"2799.16","dur":"2.27","text":"by the whole of society."},"2801.43":{"start":"2801.43","dur":"3.73","text":"So ultimately, the\nrules that decide"},"2805.16":{"start":"2805.16","dur":"3.96","text":"how the driverless\ncar should behave"},"2809.12":{"start":"2809.12","dur":"3.88","text":"under these difficult\ncircumstances, impossible,"},"2813.00":{"start":"2813","dur":"3.26","text":"in fact,\ncircumstances-- and even"},"2816.26":{"start":"2816.26","dur":"3.15","text":"if we should, in fact, program\nthose rules into the car."},"2819.41":{"start":"2819.41","dur":"4.74","text":"So some people argue that the\ndriverless cars should not"},"2824.15":{"start":"2824.15","dur":"6.26","text":"attempt to, as it were,\nmake a rule driven decision."},"2830.41":{"start":"2830.41","dur":"2.63","text":"But just leave it to chance."},"2833.04":{"start":"2833.04","dur":"2.1","text":"And again, I think\nthat&#39;s an open question."},"2835.14":{"start":"2835.14","dur":"5.2","text":"But this is really why I\nthink this dialogue and debate"},"2840.34":{"start":"2840.34","dur":"7.47","text":"and conversations with\nregulators, lawyers, ethicists,"},"2847.81":{"start":"2847.81","dur":"3.88","text":"and the general public,\nusers of driverless cars,"},"2851.69":{"start":"2851.69","dur":"2.27","text":"I think is why we need\nto have this debate."},"2853.96":{"start":"2853.96","dur":"2.52","text":"Because whatever those\nrules are, and even"},"2856.48":{"start":"2856.48","dur":"2.39","text":"whether we have them\nor not, is something"},"2858.87":{"start":"2858.87","dur":"5.38","text":"that should be decided,\nas it were, collectively."},"2864.25":{"start":"2864.25","dur":"3.5","text":"I mean, someone\nasked me last week,"},"2867.75":{"start":"2867.75","dur":"3.48","text":"should you be able to alter the\nethics of your own driverless"},"2871.23":{"start":"2871.23","dur":"0.95","text":"car?"},"2872.18":{"start":"2872.18","dur":"2.08","text":"My answer is absolutely not."},"2874.26":{"start":"2874.26","dur":"1.87","text":"I mean, that should be illegal."},"2876.13":{"start":"2876.13","dur":"3.04","text":"So I think that if\ndriverless cars were"},"2879.17":{"start":"2879.17","dur":"1.87","text":"to have a set of\nrules, and especially"},"2881.04":{"start":"2881.04","dur":"3.75","text":"if those rules had numbers\nassociated with them."},"2884.79":{"start":"2884.79","dur":"3.61","text":"I mean, let&#39;s think of\na less emotive example."},"2888.40":{"start":"2888.4","dur":"6.2","text":"Imagine a driverless car and\nan animal runs into the road."},"2894.60":{"start":"2894.6","dur":"6.55","text":"Well, , the driverless car\ncan either ignore the animal"},"2901.15":{"start":"2901.15","dur":"5.64","text":"and definitely kill the animal,\nor it could try and brake,"},"2906.79":{"start":"2906.79","dur":"4.11","text":"possibly causing harm to the\ndriver or the passengers."},"2910.90":{"start":"2910.9","dur":"3.37","text":"But effectively\nreducing the probability"},"2914.27":{"start":"2914.27","dur":"1.44","text":"of killing the animal."},"2915.71":{"start":"2915.71","dur":"3.09","text":"So there&#39;s an example\nwhere you have some numbers"},"2918.80":{"start":"2918.8","dur":"3.8","text":"to tweak if you\nlike, parameters."},"2922.60":{"start":"2922.6","dur":"3.86","text":"So if these rules are\nbuilt into driverless cars,"},"2926.46":{"start":"2926.46","dur":"1.67","text":"they&#39;ll be parameterized."},"2928.13":{"start":"2928.13","dur":"2.14","text":"And I think it\nshould be absolutely"},"2930.27":{"start":"2930.27","dur":"6.61","text":"illegal to hack those\nparameters, to change them."},"2936.88":{"start":"2936.88","dur":"2.75","text":"In the same way that it&#39;s\nprobably illegal right now"},"2939.63":{"start":"2939.63","dur":"4.35","text":"to hack an aircraft autopilot."},"2943.98":{"start":"2943.98","dur":"2.95","text":"I suspect that\nprobably is illegal."},"2946.93":{"start":"2946.93","dur":"1.7","text":"If it isn&#39;t, it should be."},"2948.63":{"start":"2948.63","dur":"2.65","text":"So I think that you\ndon&#39;t need to go"},"2951.28":{"start":"2951.28","dur":"3.45","text":"far down this line of\nargument before realizing"},"2954.73":{"start":"2954.73","dur":"4.91","text":"that the regulation\nand legislation has"},"2959.64":{"start":"2959.64","dur":"1.32","text":"to come into play."},"2960.96":{"start":"2960.96","dur":"6.41","text":"In fact, I saw a piece in\njust this morning in Wired"},"2967.37":{"start":"2967.37","dur":"5.16","text":"that, I think, in the US,\nregulation for driverless cars"},"2972.53":{"start":"2972.53","dur":"2.12","text":"is now on the table."},"2974.65":{"start":"2974.65","dur":"1.61","text":"Which is absolutely right."},"2976.26":{"start":"2976.26","dur":"3.92","text":"I mean, we need to have\nregulatory framework,"},"2980.18":{"start":"2980.18","dur":"4.17","text":"or what I call governance\nframeworks for driverless cars."},"2984.35":{"start":"2984.35","dur":"2.47","text":"And in fact, lots of\nother autonomous systems."},"2986.82":{"start":"2986.82","dur":"1.14","text":"Not just driverless cars."},"2987.96":{"start":"2987.96","dur":"3.98","text":"But great question, thank you."},"2991.94":{"start":"2991.94","dur":"2.22","text":"AUDIENCE: In the experiment\nwith the corridor,"},"2994.16":{"start":"2994.16","dur":"2.92","text":"you always assume-- even in the\nother experiments-- you always"},"2997.08":{"start":"2997.08","dur":"2.23","text":"assume that the main actor\nis the most intelligent"},"2999.31":{"start":"2999.31","dur":"1.044","text":"and the others are not."},"3000.35":{"start":"3000.354","dur":"1.416","text":"Like they&#39;re dumb,\nor like they&#39;re"},"3001.77":{"start":"3001.77","dur":"2.01","text":"ballistic models\nor linear models."},"3003.78":{"start":"3003.78","dur":"2.38","text":"Have you tried doing\na similar experiment"},"3006.16":{"start":"3006.16","dur":"5.894","text":"in which still each actor\nis intelligent but assumes"},"3012.05":{"start":"3012.054","dur":"1.916","text":"that the others are not,\nbut actually everyone"},"3013.97":{"start":"3013.97","dur":"0.81","text":"is intelligent?"},"3014.78":{"start":"3014.78","dur":"2.83","text":"So like everyone is a\nblue dot in the experiment"},"3017.61":{"start":"3017.61","dur":"1.56","text":"with the model that you have."},"3019.17":{"start":"3019.17","dur":"2.458","text":"And also, have you considered\nchanging the model so that he"},"3021.63":{"start":"3021.628","dur":"2.342","text":"assumes that the others\nhave the same model"},"3023.97":{"start":"3023.97","dur":"2.49","text":"that that particular\nactor has, as well."},"3026.46":{"start":"3026.46","dur":"1.19","text":"[INTERPOSING VOICES]"},"3027.65":{"start":"3027.65","dur":"2.3","text":"ALAN WINFIELD: No, we&#39;re\ndoing it right now."},"3029.95":{"start":"3029.95","dur":"2.7","text":"So we&#39;re doing that\nexperiment right now."},"3032.65":{"start":"3032.65","dur":"2.45","text":"And if you ask me\nback in a year,"},"3035.10":{"start":"3035.1","dur":"4.54","text":"perhaps I can tell you what\nhapp-- I mean, it&#39;s really mad."},"3039.64":{"start":"3039.64","dur":"2.25","text":"But it does take us\ndown this direction"},"3041.89":{"start":"3041.89","dur":"4.38","text":"of artificial theory of mind."},"3046.27":{"start":"3046.27","dur":"3.41","text":"So if you have several\nrobots or actors,"},"3049.68":{"start":"3049.68","dur":"3.48","text":"each of which is modeling\nthe behavior of the other,"},"3053.16":{"start":"3053.16","dur":"5.86","text":"then you get-- I\nmean, some of the--"},"3059.02":{"start":"3059.02","dur":"2.62","text":"I don&#39;t even have a\nmovie to show you."},"3061.64":{"start":"3061.64","dur":"3.48","text":"But in simulation\nwe&#39;ve tried this"},"3065.12":{"start":"3065.12","dur":"5.724","text":"where we have two robots which\nare kind of like-- imagine,"},"3070.84":{"start":"3070.844","dur":"1.916","text":"this happens to all of\nus, you&#39;re walking down"},"3072.76":{"start":"3072.76","dur":"4.95","text":"the pavement and you do\nthe sort of sidestep dance"},"3077.71":{"start":"3077.71","dur":"2.246","text":"with someone who&#39;s\ncoming towards you."},"3079.96":{"start":"3079.956","dur":"1.624","text":"And so the research\nquestion that we&#39;re"},"3081.58":{"start":"3081.58","dur":"2.71","text":"asking ourselves is do\nwe get the same thing."},"3084.29":{"start":"3084.29","dur":"2.15","text":"And it seems to be that we do."},"3086.44":{"start":"3086.44","dur":"3.85","text":"So if the robots are\nsymmetrical, in other words,"},"3090.29":{"start":"3090.29","dur":"2.12","text":"they&#39;re each modeling\nthe other, then"},"3092.41":{"start":"3092.41","dur":"6.144","text":"we can get these kind of little\ninteresting dances, where each"},"3098.55":{"start":"3098.554","dur":"2.416","text":"is trying to get out of the\nway of the other, but in fact,"},"3100.97":{"start":"3100.97","dur":"2.42","text":"choosing in a\nsense the opposite."},"3103.39":{"start":"3103.39","dur":"2.76","text":"So one chooses to step right,\nthe other chooses to step left,"},"3106.15":{"start":"3106.15","dur":"3.08","text":"and they still can&#39;t\ngo past each other."},"3109.23":{"start":"3109.23","dur":"1.92","text":"But it&#39;s hugely interesting."},"3111.15":{"start":"3111.15","dur":"1.02","text":"Yes, hugely interesting."},"3117.74":{"start":"3117.74","dur":"2.04","text":"AUDIENCE: Hi."},"3119.78":{"start":"3119.78","dur":"1.62","text":"I think it&#39;s really\ninteresting how"},"3121.40":{"start":"3121.4","dur":"2.51","text":"you point out the\nimportance of simulations"},"3123.91":{"start":"3123.91","dur":"1.73","text":"and internal models."},"3125.64":{"start":"3125.64","dur":"2.55","text":"But I feel that one thing\nthat is slightly left out"},"3128.19":{"start":"3128.19","dur":"4.63","text":"there is a huge gap from going\nfrom simulation to real world"},"3132.82":{"start":"3132.82","dur":"1.06","text":"robots, for example."},"3133.88":{"start":"3133.88","dur":"3.02","text":"And I assume that\nin these simulations"},"3136.90":{"start":"3136.9","dur":"4.48","text":"you kind of assume that the\nsensors are 100% reliable."},"3141.38":{"start":"3141.38","dur":"2.51","text":"And that&#39;s obviously\nnot the case in reality."},"3143.89":{"start":"3143.89","dur":"3.89","text":"And especially if we&#39;re talking\nabout autonomous cars or robots"},"3147.78":{"start":"3147.78","dur":"1.79","text":"and safety."},"3149.57":{"start":"3149.57","dur":"2.97","text":"How do you calculate\nthe uncertainty"},"3152.54":{"start":"3152.54","dur":"1.947","text":"that comes with the\nsensors in the equation?"},"3154.49":{"start":"3154.487","dur":"0.833","text":"ALAN WINFIELD: Sure."},"3155.32":{"start":"3155.32","dur":"2.42","text":"I mean, this is a deeply\ninteresting question."},"3157.74":{"start":"3157.74","dur":"2.21","text":"And the short answer\nis I don&#39;t know."},"3159.95":{"start":"3159.95","dur":"1.956","text":"I mean, this is all future work."},"3165.24":{"start":"3165.24","dur":"3.24","text":"I mean, my instinct\nis that a robot"},"3168.48":{"start":"3168.48","dur":"3.26","text":"with a simulation,\ninternal simulation,"},"3171.74":{"start":"3171.74","dur":"6.36","text":"even if that simulation\nin a sense is idealized,"},"3178.10":{"start":"3178.1","dur":"2.73","text":"is still probably going to be\nsafer than a robot that has"},"3180.83":{"start":"3180.83","dur":"2.45","text":"no internal simulation at all."},"3183.28":{"start":"3183.28","dur":"6.45","text":"And you know, I think we humans\nhave multiple simulations"},"3189.73":{"start":"3189.73","dur":"1.41","text":"running all the time."},"3191.14":{"start":"3191.14","dur":"3.54","text":"So I think we have sort of quick\nand dirty, kind of low fidelity"},"3194.68":{"start":"3194.68","dur":"4.48","text":"simulations when we\nneed to move fast."},"3199.16":{"start":"3199.16","dur":"4.27","text":"But clearly when you need\nto plan something, plan"},"3203.43":{"start":"3203.43","dur":"4.102","text":"some complicated\naction, like where"},"3207.53":{"start":"3207.532","dur":"1.708","text":"you are going to go\non holiday next year,"},"3209.24":{"start":"3209.24","dur":"4.59","text":"you clearly don&#39;t use the same\ninternal model, same simulation"},"3213.83":{"start":"3213.83","dur":"3.07","text":"as for when you try\nand stop someone"},"3216.90":{"start":"3216.9","dur":"2.47","text":"from running into the road."},"3219.37":{"start":"3219.37","dur":"3.93","text":"So I think that future\nintelligent robots"},"3223.30":{"start":"3223.3","dur":"3.44","text":"will need also to have\nmultiple simulators."},"3226.74":{"start":"3226.74","dur":"3.45","text":"And also strategies\nfor choosing which"},"3230.19":{"start":"3230.19","dur":"4.57","text":"fidelity simulator to\nuse at a particular time."},"3234.76":{"start":"3234.76","dur":"3.98","text":"And if a particular\nsituation requires"},"3238.74":{"start":"3238.74","dur":"3.82","text":"that you need high\nfidelity, then for instance,"},"3242.56":{"start":"3242.56","dur":"1.5","text":"one of the things\nthat you could do,"},"3244.06":{"start":"3244.06","dur":"2.02","text":"which actually I think\nhumans probably do,"},"3246.08":{"start":"3246.08","dur":"3.9","text":"is that you simply move more\nslowly to give your self time."},"3249.98":{"start":"3249.98","dur":"2.89","text":"Or even stop to\ngive yourself time"},"3252.87":{"start":"3252.87","dur":"1.88","text":"to figure out what&#39;s going on."},"3254.75":{"start":"3254.75","dur":"2.44","text":"And in a sense,\nplan your strategy."},"3257.19":{"start":"3257.19","dur":"8.83","text":"So I think even with the\ncomputational power we have,"},"3266.02":{"start":"3266.02","dur":"3.26","text":"there will still be a\nlimited simulation budget."},"3269.28":{"start":"3269.28","dur":"2.2","text":"And I suspect that\nthat simulation budget"},"3271.48":{"start":"3271.48","dur":"1.85","text":"will mean that in\nreal time, when you&#39;re"},"3273.33":{"start":"3273.33","dur":"5.26","text":"doing this in real time, you\nprobably can&#39;t run your highest"},"3278.59":{"start":"3278.59","dur":"1.66","text":"fidelity simulator."},"3280.25":{"start":"3280.25","dur":"7.31","text":"And taking into account all\nof those probabilistic, noisy"},"3287.56":{"start":"3287.56","dur":"3.31","text":"sensors and actuators\nand so on, you probably"},"3290.87":{"start":"3290.87","dur":"2.22","text":"can&#39;t run that\nsimulator all the time."},"3293.09":{"start":"3293.09","dur":"2.23","text":"So I think we&#39;re\ngoing to have to have"},"3295.32":{"start":"3295.32","dur":"3.91","text":"a nuanced approach where we\nhave perhaps multiple simulators"},"3299.23":{"start":"3299.23","dur":"1.49","text":"with multiple fidelities."},"3300.72":{"start":"3300.72","dur":"2.58","text":"Or maybe a sort of\ntuning, where you can tune"},"3303.30":{"start":"3303.3","dur":"3.4","text":"the fidelity of your simulator."},"3306.70":{"start":"3306.7","dur":"2.046","text":"So this is kind of a\nnew area of research."},"3308.75":{"start":"3308.746","dur":"2.374","text":"I don&#39;t know anybody who&#39;s\nthinking about this yet, apart"},"3311.12":{"start":"3311.12","dur":"1.49","text":"from ourselves."},"3312.61":{"start":"3312.61","dur":"2.083","text":"So great."},"3314.69":{"start":"3314.693","dur":"2.307","text":"AUDIENCE: [INAUDIBLE]."},"3317.00":{"start":"3317","dur":"3.69","text":"ALAN WINFIELD: It\nis pretty hard, yes."},"3320.69":{"start":"3320.69","dur":"0.886","text":"Please."},"3321.58":{"start":"3321.576","dur":"2.334","text":"AUDIENCE: [INAUDIBLE]."},"3323.91":{"start":"3323.91","dur":"1.77","text":"ALAN WINFIELD: Do you\nwant the microphone?"},"3325.68":{"start":"3325.68","dur":"0.499","text":"Sorry."},"3328.61":{"start":"3328.609","dur":"2.291","text":"AUDIENCE: Have you considered\nthis particular situation"},"3330.90":{"start":"3330.9","dur":"1.64","text":"where there are\ntwo Asimov robots--"},"3332.54":{"start":"3332.54","dur":"4.32","text":"and that would be an extension\nof the question that he asked."},"3336.86":{"start":"3336.86","dur":"2.93","text":"So for example, if there\nare two guys walking"},"3339.79":{"start":"3339.79","dur":"2.57","text":"on a pavement and there\ncould be a possibility"},"3342.36":{"start":"3342.36","dur":"1.77","text":"of mutual cooperation."},"3344.13":{"start":"3344.13","dur":"2.989","text":"As in one might communicate\nwhether that I might step out"},"3347.12":{"start":"3347.119","dur":"1.291","text":"of this place and you might go."},"3348.41":{"start":"3348.41","dur":"1.89","text":"And then I&#39;ll go after that."},"3350.30":{"start":"3350.3","dur":"2.019","text":"So if there are\ntwo Asimov robots,"},"3352.32":{"start":"3352.319","dur":"1.541","text":"will there be a\npossibility, and have"},"3353.86":{"start":"3353.86","dur":"2.52","text":"you considered this fact\nthat both will communicate"},"3356.38":{"start":"3356.38","dur":"2.72","text":"with each other, and they will\neventually come to a conclusion"},"3359.10":{"start":"3359.1","dur":"4.05","text":"that I will probably walk,\nand the other will get out"},"3363.15":{"start":"3363.15","dur":"1.01","text":"of the way."},"3364.16":{"start":"3364.16","dur":"1.73","text":"And the second part\nof this question"},"3365.89":{"start":"3365.89","dur":"2.53","text":"would be what if\none of the robots"},"3368.42":{"start":"3368.42","dur":"3.93","text":"actually does not\nagree to cooperate?"},"3372.35":{"start":"3372.35","dur":"2.919","text":"I mean, since they both would\nhave different simulators."},"3375.27":{"start":"3375.269","dur":"1.541","text":"They could have\ndifferent simulators."},"3376.81":{"start":"3376.81","dur":"2.458","text":"And one might actually try to\ncommunicate that you step out"},"3379.27":{"start":"3379.268","dur":"3.072","text":"of the way so that I might go."},"3382.34":{"start":"3382.34","dur":"2.54","text":"And the other one\ndoesn&#39;t agree with that."},"3384.88":{"start":"3384.88","dur":"2.08","text":"I mean, what would\nthe [INAUDIBLE]."},"3386.96":{"start":"3386.96","dur":"1.75","text":"ALAN WINFIELD: Yeah,\nit&#39;s a good question."},"3388.71":{"start":"3388.71","dur":"3.18","text":"In fact, we&#39;ve actually\ngotten a new paper which"},"3391.89":{"start":"3391.89","dur":"3.4","text":"we&#39;re just writing right now."},"3395.29":{"start":"3395.29","dur":"5.43","text":"And the sort of working\ntitle is &quot;The Dark Side"},"3400.72":{"start":"3400.72","dur":"2.21","text":"of Ethical Robots.&quot;"},"3402.93":{"start":"3402.93","dur":"4.35","text":"And one of the things that we\ndiscovered-- it&#39;s actually not"},"3407.28":{"start":"3407.28","dur":"4.91","text":"surprising-- is that you only\nneed to change one line of code"},"3412.19":{"start":"3412.19","dur":"5.22","text":"for a co-operative robot to\nbecome a competitive robot,"},"3417.41":{"start":"3417.41","dur":"2.97","text":"or even an aggressive robot."},"3420.38":{"start":"3420.38","dur":"5.37","text":"So it&#39;s fairly obvious, when\nyou start to think about it,"},"3425.75":{"start":"3425.75","dur":"4.24","text":"if your ethical rules\nare very simply written,"},"3429.99":{"start":"3429.99","dur":"1.73","text":"and are a kind of\nlayer, if you like,"},"3431.72":{"start":"3431.72","dur":"2.45","text":"on top of the rest\nof the architecture,"},"3434.17":{"start":"3434.17","dur":"2.33","text":"then it&#39;s not that difficult\nto change those rules."},"3439.33":{"start":"3439.33","dur":"1.61","text":"And yes, we&#39;ve done\nsome experiments."},"3440.94":{"start":"3440.94","dur":"2.32","text":"And again, I don&#39;t have\nany videos to show you."},"3443.26":{"start":"3443.26","dur":"5","text":"But they&#39;re pretty\ninteresting, showing"},"3448.26":{"start":"3448.26","dur":"4.49","text":"how easy it is to make a\ncompetitive robot, or even"},"3452.75":{"start":"3452.75","dur":"3.96","text":"an aggressive robot\nusing this approach."},"3456.71":{"start":"3456.71","dur":"3.97","text":"In fact, on the BBC\nsix months ago or so,"},"3460.68":{"start":"3460.68","dur":"3.09","text":"I was asked surely if you\ncan make an ethical robot,"},"3463.77":{"start":"3463.77","dur":"3.01","text":"doesn&#39;t that mean you can\nmake an unethical robot?"},"3466.78":{"start":"3466.78","dur":"2.49","text":"And the answer,\nI&#39;m afraid, is yes."},"3469.27":{"start":"3469.27","dur":"3.49","text":"It does mean that."},"3472.76":{"start":"3472.76","dur":"3.09","text":"But this really goes back\nto your question earlier,"},"3475.85":{"start":"3475.85","dur":"2.49","text":"which is that it should\nbe-- we should make"},"3478.34":{"start":"3478.34","dur":"3.37","text":"sure it&#39;s illegal\nto convert, to turn,"},"3481.71":{"start":"3481.71","dur":"3.2","text":"if you like, to recode\nan ethical robot"},"3484.91":{"start":"3484.91","dur":"1.33","text":"as an unethical robot."},"3486.24":{"start":"3486.24","dur":"3.73","text":"Or even it should be illegal\nto make unethical robots."},"3489.97":{"start":"3489.97","dur":"0.89","text":"Something like that."},"3490.86":{"start":"3490.86","dur":"1.35","text":"But it&#39;s a great question."},"3492.21":{"start":"3492.21","dur":"4.11","text":"And short answer, yes."},"3496.32":{"start":"3496.32","dur":"2.63","text":"And yes, we have some\ninteresting new results,"},"3498.95":{"start":"3498.95","dur":"5.46","text":"new paper on, as it\nwere, unethical robots."},"3504.41":{"start":"3504.41","dur":"1.54","text":"Yeah."},"3505.95":{"start":"3505.95","dur":"2.08","text":"HOST: All right, we are\nrunning out of time now."},"3508.03":{"start":"3508.03","dur":"1.867","text":"Thanks everyone\nfor coming today."},"3509.90":{"start":"3509.897","dur":"1.333","text":"Thanks, Professor Alan Winfield."},"3511.23":{"start":"3511.23","dur":"1.041","text":"ALAN WINFIELD: Thank you."},"3512.27":{"start":"3512.271","dur":"1.429","text":"[APPLAUSE]"}}