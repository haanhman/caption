{"2":{"dur":7,"text":">>Tim O'Reilly: one question I'd like to start\nwith, Ray, is the question of choices. You"},"13":{"dur":6,"text":"know, your graphs have this remarkable sense\nof inevitability about them."},"19":{"dur":7,"text":"And, yet, we know in our everyday life and\nwe know in the life of nations that there"},"27":{"dur":6,"text":"are choices to be made and that, if we make\nthe wrong choice -- at least in the short-term"},"33":{"dur":6,"text":"-- things can go very wrong. At least there's\nevidence from history that they can go very"},"39":{"dur":6,"text":"wrong for a long time. One of the things -- I\nthink, being trained as a classist original,"},"45":{"dur":4,"text":"I think about things like the fact that the\nHagia Sophia was the largest building in the"},"50":{"dur":6,"text":"world for a thousand years. It's not -- when\nprogress failed in the west, the western Roman"},"57":{"dur":6,"text":"empire, moved to the eastern Roman empire,\nmoved to the Arabic world and back to Europe,"},"63":{"dur":5,"text":"you know, we're increasingly one world. And\nwe screw up, we screw up for everybody."},"69":{"dur":3,"text":">>Ray Kurzweil: In terms of inevitability,\nsometimes people say why don't we just sit"},"72":{"dur":5,"text":"back and let it happen? Why are we working\nso hard? If we did that, it wouldn't happen."},"78":{"dur":7,"text":"In a way, we're counting on people's passion\nto follow their inspiration and be creative"},"86":{"dur":5,"text":"and the increasing enabling of the democratization\nof the tools of innovation, which I talked"},"92":{"dur":3,"text":"about.\nHowever, there's another reason to get involved."},"95":{"dur":4,"text":"They say war is too important to leave to\nthe generals. Technology is too important"},"99":{"dur":5,"text":"to leave to the technologists. I talked somewhat\nabout the promise, but there's also peril."},"104":{"dur":4,"text":"The same technology we're using to reprogram\nbiology away from disease could be also be"},"109":{"dur":7,"text":"applied by a bioterrorist to reprogram a biological\nvirus to be a deadly weapon. We're not defenseless"},"116":{"dur":4,"text":"against that. We can create a defensive system.\nI've been working, actually, with the Army"},"121":{"dur":5,"text":"on doing that, a rapid response system for\nbiological viruses like we do have for software"},"127":{"dur":6,"text":"viruses. But there is promise and peril. That's\nbeen true of technology since fire, which"},"133":{"dur":4,"text":"kept us warm but also burned down our villages.\nAnd that's the reason to get involved. And"},"138":{"dur":7,"text":"there are also subtle issues that are important\nbeyond the existential risks. Privacy, protection"},"145":{"dur":6,"text":"of intellectual property so that we can actually\ncreate information of value and so on."},"151":{"dur":7,"text":">>Tim O'Reilly: So let me shift over to your\nfocus on health and wellness as IT. I think"},"159":{"dur":5,"text":"there's an enormous opportunity there. Some\nof it is in areas like genomics. But there"},"164":{"dur":5,"text":"are also enormous opportunities just in creating\nlearning loops. You know, one of the things"},"170":{"dur":6,"text":"I like to think about with Google and advertising,\nof course, this being a conference that has"},"176":{"dur":6,"text":"its roots in that world, one of the amazing\nthings we learned was how to solve what you"},"183":{"dur":4,"text":"could describe as the Wanamaker problem. You\nknow, half of my advertising doesn't work."},"187":{"dur":4,"text":"I just don't know which half. Google made\na big dent in solving that problem for a certain"},"191":{"dur":7,"text":"class of advertising. As we move into healthcare\nas IT, we're actually trying to do that same"},"198":{"dur":5,"text":"thing. We're, actually, trying to use collective\nintelligence, massive amounts of data to actually"},"203":{"dur":3,"text":"figure out what's working and what isn't.\n>>Ray Kurzweil: There's many aspects of that."},"207":{"dur":6,"text":"There's actual collective decision making\nusing the tools that are becoming available."},"214":{"dur":4,"text":"Patients are perfectly good scientific and\nmedical researchers. And groups of patients"},"218":{"dur":6,"text":"are -- have a motivation to solve a disease.\nAnd that is happening. And patient goes into"},"225":{"dur":4,"text":"a doctor's office with a chronic disease,\nshe is armed with the latest knowledge from,"},"230":{"dur":4,"text":"you know, whole community of people who have\nthat and who have a passion for addressing"},"234":{"dur":4,"text":"that condition. And she may very well know\nmore about it than her physician."},"239":{"dur":4,"text":">>Tim O'Reilly: That kind of brings me back\nto an issue of choices. You know, one of the"},"243":{"dur":6,"text":"big areas that I know when I talk to people\nin medical research, some of the privacy fears"},"250":{"dur":5,"text":"actually are holding us back. You know, patients\nwill quite willingly share their medical history"},"256":{"dur":5,"text":"with other patients, if you look at a community\nlike patients like me, people are sharing"},"261":{"dur":4,"text":"everything they know, because, my gosh, they're\ntrying to save their life."},"266":{"dur":4,"text":"Yet, our system penalizes people, makes it\ndifficult to share."},"270":{"dur":4,"text":"Do we need to change our culture of data sharing\nin areas like this?"},"274":{"dur":6,"text":">>Ray Kurzweil: Yes, I think so. HIPAA has\nslowed down the sharing of data to do outcome"},"281":{"dur":6,"text":"studies.\nThere -- that is changing, and there are large"},"288":{"dur":5,"text":"institutions, like Mayo Clinic and so on,\nwho are harvesting and harnessing this data"},"293":{"dur":6,"text":"and stripping off the patient information\nand being able to do outcome studies. NIH"},"300":{"dur":5,"text":"is collecting a million genomes to relate\ngenetic states to diseases so we can do personalized"},"305":{"dur":4,"text":"genetic medicine. That wasn't feasible, by\nthe way, when the genome cost a billion dollars"},"310":{"dur":3,"text":"each. Now that it's approaching a thousand\ndollars each, that becomes feasible."},"314":{"dur":6,"text":"So privacy is a very important thing to solve.\nI think it is solvable. I think the technologies"},"320":{"dur":5,"text":"of privacy encryption have kept ahead of the\ntechnologies of breaking privacy, which is"},"325":{"dur":2,"text":"decryption.\n>>Tim O'Reilly: There's kind of another interesting"},"328":{"dur":7,"text":"element to this health care arena that I find\nreally instructive, and that is a shift in"},"336":{"dur":7,"text":"the model from diagnosis at the front end,\nfollowed by treatment, to a situation where"},"343":{"dur":4,"text":"we're doing constant diagnosis to say, oh,\nthis treatment working? I was at a recent"},"347":{"dur":5,"text":"health care event with G.E., and that's a\nbig part of their focus now, is shifting that"},"353":{"dur":4,"text":"model. And it really makes a lot of what we've\nlearned on the consumer Internet so much more"},"357":{"dur":4,"text":"relevant. Because what we're always doing\nis testing, did this work. We're learning"},"362":{"dur":5,"text":"constantly in our algorithms, gathering new\ndata. And it's remarkable to me that health"},"367":{"dur":3,"text":"care is following that same trajectory.\n>>Ray Kurzweil: You mentioned Watson. Watson"},"370":{"dur":6,"text":"is working with nuance, which is -- that's\nmy first company, actually -- to have it read"},"377":{"dur":2,"text":"all medical literature.\n>>Tim O'Reilly: Right."},"379":{"dur":6,"text":">>Ray Kurzweil: To use it as a diagnostician.\nMedical doctors simply cannot read all the"},"385":{"dur":3,"text":"tens of thousands of articles that come out\neach year in their area."},"388":{"dur":3,"text":">>Tim O'Reilly: Yeah.\n>>Ray Kurzweil: So that --"},"392":{"dur":5,"text":">>Tim O'Reilly: Yeah, I'm talking, though,\nspecifically about actual diagnostic devices,"},"397":{"dur":4,"text":"we look at personalized medicine, you're actually\nperhaps looking at the biochemistry, looking"},"402":{"dur":4,"text":"at the genetics, looking at is this drug actually\nworking, which patients does it work for,"},"406":{"dur":3,"text":"which ones does it not work for and you're\ntailoring treatment."},"410":{"dur":2,"text":"So there's kind of an interesting --\n>>Ray Kurzweil: There's a big interest in"},"412":{"dur":5,"text":"outcome studies, and we've done almost none\nof that. You know, in terms of Google's philosophy"},"418":{"dur":6,"text":"that data is power, which is kind of a variation\nof (indiscernible) knowledge is power, having"},"424":{"dur":4,"text":"that data is tremendously important. Find\npeople who have taken a particular supplement"},"429":{"dur":4,"text":"don't get a particular disease, that's really\nvaluable to know. And that information is"},"433":{"dur":5,"text":"out there. And it's going to be harvested\nnow, maybe by Google, but certainly -- or"},"439":{"dur":2,"text":"by the companies here.\n>>Tim O'Reilly: Let me ask you another question:"},"441":{"dur":5,"text":"You have, you know, famously been, you know,\nquoted as saying that, you know, you think"},"447":{"dur":3,"text":"that it will be possible at some point for\nhumans to live forever."},"451":{"dur":4,"text":"What are the moral implications of that?\n>>Ray Kurzweil: Well, it's never forever."},"455":{"dur":1,"text":"I mean --\n>>Tim O'Reilly: Not forever."},"457":{"dur":4,"text":">>Ray Kurzweil: But come to Google Zeitgeist\nand say, I've done it, I've lived forever."},"461":{"dur":3,"text":">>Tim O'Reilly: But certainly --\n>>Ray Kurzweil: I think the threshold we're"},"465":{"dur":5,"text":"going for is to be at more than a year -- add\nmore of a year to your remaining life expectancy."},"470":{"dur":5,"text":"And that's not a guarantee. It's not going\nto come suddenly. Bit by bit, as we overcome"},"475":{"dur":6,"text":"different diseases, reverse aging processes,\nall of which is feasible, we will be extending"},"481":{"dur":3,"text":"human longevity.\nNow, if there were the only thing we were"},"485":{"dur":2,"text":"doing, you could actually make a case that\nisn't moral, because we're going to run out"},"487":{"dur":5,"text":"of resources. But the same technologies that\ncan extend longevity are going to extend resources."},"493":{"dur":4,"text":"I didn't get to discuss, for example, solar\nenergy, which I worked on with Larry Page"},"498":{"dur":4,"text":"at the National Academy of Engineering. We\nnoted that it's growing exponentially. It's"},"502":{"dur":3,"text":"now a half a percent of the world's energy\nneeds. But it's doubling every two years,"},"506":{"dur":5,"text":"and it has been for 25 years. And it's only\neight doublings now from 100%. And people"},"511":{"dur":5,"text":"tend to dismiss how it's half a percent, it's\na fringe player, not important, but -- and"},"516":{"dur":4,"text":"they ignore the exponential, just as they\ndid with the genome and the Internet."},"521":{"dur":5,"text":">>Tim O'Reilly: There are other issues, though,\nwhen you look at a world that's reshaped demographically"},"526":{"dur":6,"text":"in that way. There's a huge shift in power.\nWe see right now around the world young people"},"532":{"dur":4,"text":"without jobs. We -- you know, the question\nis, do we really want to shift more people"},"537":{"dur":4,"text":"-- more power to people who are older?\n>>Ray Kurzweil: I don't think the statistics"},"541":{"dur":4,"text":"show that.\nIf you look, there's always a lot of political"},"545":{"dur":4,"text":"consequence on what happened, you know, this\nmonth and this quarter. If you look at it"},"550":{"dur":5,"text":"over a broad period of time, we have doubled\nthe percentage of the population working,"},"556":{"dur":5,"text":"and the jobs pay now ten times as much in\nconstant dollars compared to a century ago."},"561":{"dur":4,"text":"If I were (indiscernible) as a futurist in\n1900, I would say a third of you work on farms,"},"565":{"dur":4,"text":"a third of you work in factories. But in a\nhundred years, the year 2000, that's going"},"569":{"dur":4,"text":"to be 3% and 3%. And everyone would go, \"Oh,\nmy God, we're going to be out of work.\""},"573":{"dur":4,"text":"And I'd say, \"Don't worry. You'll get jobs\nin genetic sequencing and new search algorithms,\""},"578":{"dur":5,"text":"and nobody would know what I'm talking about.\nMost of the jobs today didn't exist 50 years"},"583":{"dur":4,"text":"ago, and that will continue to be the case.\nAnd we are investing more in education as"},"588":{"dur":3,"text":"a result. We had 55,000 college students in\n1870. We have ten million today."},"591":{"dur":4,"text":">>Tim O'Reilly: But still, I think the real\nimplication is, there are enormous disruptions"},"596":{"dur":6,"text":"ahead, disruptions that aren't just technological,\nbut social and economic. And we need to actually"},"602":{"dur":3,"text":"have innovators tackle all of those things.\n>>Ray Kurzweil: What's amazing is how quickly"},"606":{"dur":4,"text":"we get used to change. When things happen,\nit's like, wow, it's a search engine where"},"610":{"dur":5,"text":"you can find out any of the information in\nthe world in a few seconds. We get used to"},"615":{"dur":2,"text":"it overnight.\n>>Tim O'Reilly: That's right, we do."},"617":{"dur":2,"text":"Well, with that, we're going to have to wrap.\nWe're out of time."},"620":{"dur":2,"text":"Thank you very much, Ray.\nAnd --"},"622":{"dur":6,"text":"[ Applause ]\n>>Tim O'Reilly: -- thank you, all for staying"},"629":{"dur":2,"text":"here.\n[ Applause ]"}}