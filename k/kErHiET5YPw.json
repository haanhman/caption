{"6":{"dur":4,"text":"I'm here to talk about a very\nstrange topic. I hope you'll"},"11":{"dur":2,"text":"have confidence in me. We're\ngonna spread our wings a bit,"},"14":{"dur":2,"text":"and then you have to believe\nthat I will land the plane"},"17":{"dur":2,"text":"after forty minutes, and you\nwon't feel that I've completely"},"19":{"dur":2,"text":"wasted your time. But I wanna\ntalk to you about what happens"},"22":{"dur":3,"text":"when the people at the top of\nyour industry, who run it,"},"26":{"dur":3,"text":"believe something insane.\nAnd how to cope."},"30":{"dur":3,"text":"I'm gonna talk today about the\nproblem of superintelligence."},"36":{"dur":4,"text":"So, in 1945. the Americans were\ndeveloping the atomic bomb,"},"41":{"dur":3,"text":"and they were about\nto test it at Trinity."},"44":{"dur":3,"text":"There was an odd aspect to the\natomic bomb which was that the"},"48":{"dur":3,"text":"conditions that it would create\nhad never existed on Earth"},"52":{"dur":2,"text":"before. It would create\ntemperatures higher than"},"54":{"dur":2,"text":"anything the Earth had ever\nseen. And at some point"},"57":{"dur":2,"text":"somebody asked the question\nwhat if this lights the"},"59":{"dur":2,"text":"atmosphere on fire? Kind of\na valid question, and you"},"62":{"dur":2,"text":"wanna know the answer to it\nbefore you press the big,"},"64":{"dur":2,"text":"red button. So, the impetus\nfor the question was this"},"67":{"dur":2,"text":"kind of equation. Nitrogen is\nnot really stable. If you take"},"70":{"dur":2,"text":"two nitrogen molecules and\nyou smush them together"},"72":{"dur":2,"text":"hard enough, they'll create\nmagnesium, and an alpha"},"75":{"dur":3,"text":"particle, and a lot of energy.\nSo, the question that had to"},"79":{"dur":3,"text":"be solved is how much, you know,\nhow self-sustaining is this"},"82":{"dur":2,"text":"reaction. If we light the\natmosphere on fire, will it be"},"85":{"dur":2,"text":"like throwing a match on\ntop of a pile of dead wood?"},"88":{"dur":2,"text":"And there was a similar question\nfor the oceans. They're full"},"91":{"dur":2,"text":"of hydrogen and hydrogen\nlikes to fuse together."},"93":{"dur":2,"text":"Is exploding an atomic bomb\ngoing to destroy the planet?"},"96":{"dur":2,"text":"I'm standing here, you're\nlistening to me, so obviously"},"99":{"dur":2,"text":"the answer is it does\nnot destroy the planet,"},"101":{"dur":3,"text":"but it was kind of a valid thing\nto interrogate yourselves about."},"105":{"dur":3,"text":"But I would also point out\nthat the, that the fact that"},"109":{"dur":3,"text":"it didn't kill the planet didn't\nmake dealing with nuclear"},"113":{"dur":3,"text":"power, or nuclear\nweapons any more easy."},"116":{"dur":3,"text":"It was just something that had\nto be asked and answered."},"120":{"dur":3,"text":"So, last year this book came out\ncalled 'Superintelligence'."},"124":{"dur":2,"text":"I wonder if you could raise\nyour hand if you've read"},"126":{"dur":2,"text":"this book, or read about it."},"129":{"dur":2,"text":"All right, so not too\nmany people have."},"131":{"dur":2,"text":"I'm gonna give you a quick\nsummary of it, but it asks"},"134":{"dur":2,"text":"the same question about this\nnew technology that we've"},"136":{"dur":2,"text":"created, machine learning.\nMachine learning is affecting"},"139":{"dur":2,"text":"our lives in all kinds of ways.\nIt's upsetting the balance of"},"142":{"dur":2,"text":"power between, between\ncountries, between companies,"},"145":{"dur":2,"text":"and people. But there's also\na subset of the tech industry"},"147":{"dur":2,"text":"that believes that there's a\nmuch more dangerous scenario."},"150":{"dur":2,"text":"Kind of like the blowing up\nthe atmosphere scenario"},"153":{"dur":2,"text":"where a machine intelligence\nmight rapidly become more"},"155":{"dur":2,"text":"intelligent than human beings,\nand then get up to some"},"158":{"dur":3,"text":"nefarious stuff, persuade us to\nbuild, you know, build ways for"},"162":{"dur":2,"text":"it to affect the world, and then\nexterminate the human race."},"165":{"dur":3,"text":"This idea seems to gain more\ncredence the smarter you are."},"169":{"dur":2,"text":"So, like, the top of the, the\ncream of the cream of our"},"172":{"dur":3,"text":"Silicon Valley intellectuals\nbelieve it. Elon Musk has"},"176":{"dur":4,"text":"signed this open letter, Stephen\nHawking signed it, Bill Gates"},"180":{"dur":4,"text":"is on board with it so there's\nkind of, there's a lot of"},"184":{"dur":2,"text":"legitimacy to the idea.\nBut it's also an insane idea."},"187":{"dur":4,"text":"I wanna walk you through it.\nThere's a bunch of premises"},"192":{"dur":2,"text":"you have to accept, and if you\naccept the premises, the"},"195":{"dur":2,"text":"conclusion flows out kind of\nsemi-naturally. So let's start"},"197":{"dur":3,"text":"with... One is a proof of\nconcept. All of us have this"},"201":{"dur":2,"text":"kind of box of meat on our\nheads that we use to get through"},"204":{"dur":2,"text":"the day. I'm using it to give\nthe talk, you're using it to"},"207":{"dur":3,"text":"listen to me. Sometimes it's\ncapable of rational thought."},"211":{"dur":3,"text":"So, we know that in our universe\nthere are these configurations"},"214":{"dur":3,"text":"of matter that can think\nbecause we all have one."},"218":{"dur":2,"text":"Almost all..."},"221":{"dur":3,"text":"The second premise you have\nto accept is that there's no"},"224":{"dur":3,"text":"weird quantum shenanigans\nor anything happening in your"},"227":{"dur":2,"text":"head. That your brain is just a\nmechanical system like anything"},"230":{"dur":2,"text":"else in the universe. So if\nyou're religious, and you"},"233":{"dur":2,"text":"believe that you have a soul,\nyou might step off at this"},"236":{"dur":2,"text":"premise. Or if you think like\nRoger Penrose that there's"},"239":{"dur":2,"text":"some weird quantum things\nhappening in microtubules,"},"241":{"dur":2,"text":"you won't accept this premise.\nBut it's kind of a mainstream"},"244":{"dur":2,"text":"one, that if we had a powerful\nenough computer, in principle"},"247":{"dur":3,"text":"we could simulate our entire\nbrain, and the activity that"},"251":{"dur":2,"text":"happens there. Right now\nwe can simulate a nematode"},"254":{"dur":2,"text":"worm, but, you know, we're\nworking our way upwards."},"256":{"dur":3,"text":"The next premise is that the\nspace of possible minds"},"260":{"dur":4,"text":"is very, very large. So, we\nhappen to have a brain that"},"264":{"dur":2,"text":"thinks the way it does, and has\nthe types of emotions and"},"267":{"dur":2,"text":"instincts that it does because\nwe evolved from animals"},"270":{"dur":2,"text":"in a certain direction. But that\ndoesn't mean that every brain"},"272":{"dur":2,"text":"that we would create would\nthink in a way that would be"},"275":{"dur":3,"text":"familiar to us. And this premise\nsays that, in fact, most minds"},"278":{"dur":3,"text":"that you could imagine or create\nwould be very alien from our"},"281":{"dur":4,"text":"perspective. A good way to think\nof this is of... What the"},"286":{"dur":4,"text":"natural world produces when it\ncomes to maximizing for speed."},"290":{"dur":3,"text":"So, the fastest land animal is\nthe cheetah, and if you've"},"294":{"dur":2,"text":"never... If you live in a\npre-industrial civilization,"},"297":{"dur":2,"text":"you might think that this is as\nfast as anything can go"},"300":{"dur":2,"text":"on Earth. But, of course, we\nknow that's false. You can take"},"303":{"dur":2,"text":"a bunch of atoms, and you can\nassemble them into a Ducati"},"305":{"dur":2,"text":"motorcycle, and it goes much,\nmuch faster than a cheetah,"},"308":{"dur":3,"text":"and even looks a little bit\ncooler. But to get to this"},"311":{"dur":2,"text":"motorcycle there's no really\nevolutionary pathway other than"},"314":{"dur":2,"text":"creating human beings which\nwill then build it for you."},"317":{"dur":2,"text":"So, analogously there might be\na way that we can create minds"},"320":{"dur":2,"text":"that are much, much, more\nintelligent than our own,"},"322":{"dur":3,"text":"but that just weren't\navailable to evolution."},"326":{"dur":3,"text":"And, there's no upper limit\nnecessarily on intelligence"},"330":{"dur":3,"text":"that's anywhere close to ours.\nMaybe the smartest anything"},"333":{"dur":2,"text":"can be is twice as smart as\npeople, maybe it's sixty"},"336":{"dur":2,"text":"thousand times as smart.\nThat's an empirical question."},"339":{"dur":2,"text":"We just don't know the answer\nto it. Then the next premise"},"342":{"dur":2,"text":"you have to accept is that\nthere's plenty of room left for"},"345":{"dur":3,"text":"Moore's law to do it's thing.\nThis is looking a little bit"},"348":{"dur":2,"text":"shaky in practice, but in\ntheory we know that the limits"},"351":{"dur":2,"text":"on computation are very, very\nhigh, and we can get"},"354":{"dur":2,"text":"considerably further than we\nhave. We can double, and double,"},"356":{"dur":3,"text":"and double for, for decades more\nbefore we hit any sort of"},"360":{"dur":3,"text":"physical limit, rather than say\neconomic limit, or what people"},"363":{"dur":2,"text":"are just willing to build in\nfactories to try to do."},"366":{"dur":2,"text":"So, there's lots and lots of\nroom for computers to become"},"369":{"dur":3,"text":"faster, and smaller, and more\nefficient. And the final"},"372":{"dur":4,"text":"premise... Sorry, penultimate\npremise is that if we create an"},"376":{"dur":2,"text":"artificial intelligence that\nwill operate on time-scales"},"379":{"dur":3,"text":"that are computer time-scales,\nand not human ones. You know,"},"383":{"dur":2,"text":"for us to get to the point where\nI can give this talk I had to"},"386":{"dur":2,"text":"be born, and grow up, and learn\na lot of stuff, and go to"},"388":{"dur":3,"text":"university... It takes a while,\nbut computers can, can work"},"392":{"dur":3,"text":"tens of thousands of times\nmore quickly. And then, this is"},"396":{"dur":2,"text":"the most American premise,\nand I like it the most."},"398":{"dur":2,"text":"This is Tony Robbins,\nthe motivational speaker."},"401":{"dur":2,"text":"The premise is that any\nartificial intelligence we"},"403":{"dur":2,"text":"create is gonna want to improve\nitself. It's gonna want to be"},"406":{"dur":2,"text":"a better AI, do it's job more\neffectively so that it's gonna"},"409":{"dur":2,"text":"have an impetus to start\nrecursively redesigning,"},"412":{"dur":3,"text":"and improving it's own systems.\nNow, if you accept all of these"},"415":{"dur":2,"text":"premises, what you get\nis a terrible disaster."},"418":{"dur":2,"text":"Because at some point, as\ncomputers get faster, as we"},"421":{"dur":2,"text":"program them to be more\nintelligent, there's gonna be"},"424":{"dur":2,"text":"a runaway effect. Sort of like\nan explosion where something"},"427":{"dur":2,"text":"will become sufficiently smart\nto begin self-improving,"},"429":{"dur":2,"text":"American style, and it's not\ngoing to stop until it hits"},"432":{"dur":3,"text":"a natural limit which might be\nvery, very, very much more"},"436":{"dur":4,"text":"than human intelligence. And\nat that point this monstrous"},"440":{"dur":3,"text":"sort of intellectual creature\nwill be able to, through devious"},"444":{"dur":4,"text":"modeling of what our\nemotions and intellect are like,"},"448":{"dur":2,"text":"persuade us to do things like\ngive it access to factories"},"451":{"dur":3,"text":"so it can build, you know, make\nDNA replicators, and all sorts"},"455":{"dur":3,"text":"of stuff. It gets very Sci Fi\nvery quickly. So, let's talk,"},"458":{"dur":2,"text":"let's talk a specific scenario.\nSay I wanna build a robot"},"461":{"dur":3,"text":"to say funny things. I work\non the team, and our researchers"},"465":{"dur":2,"text":"every day we build, we redesign\nour software, we compile it,"},"468":{"dur":2,"text":"and then the robot tells us\na joke. So, in the beginning"},"471":{"dur":2,"text":"the robot's jokes aren't very\nfunny. It's kind of at the lower"},"474":{"dur":2,"text":"limit of what people can do.\nBut we persevere, we work,"},"477":{"dur":2,"text":"and we start getting to the\npoint where the robot is saying"},"479":{"dur":3,"text":"things that are\nmaking us chuckle."},"486":{"dur":2,"text":"And at this point the robot's\ngetting smarter as well,"},"489":{"dur":2,"text":"and it starts helping us\ndesign the next version."},"491":{"dur":2,"text":"It has a good sense of what's\nfunny, and what's not."},"494":{"dur":2,"text":"And at some point it gets to\nnear superhuman level"},"497":{"dur":3,"text":"where it's better than\nany of its designers are."},"503":{"dur":4,"text":"And at this point we get the\nrunaway effect. The researchers"},"507":{"dur":2,"text":"go home for the weekend, the\nrobot says, all right I'm gonna"},"510":{"dur":2,"text":"sit, I'm gonna redesign my\noperating system so I'm a little"},"513":{"dur":2,"text":"bit funnier, and a little bit\nsmarter. It optimizes the part"},"515":{"dur":2,"text":"that's good at optimizing. And\nit does this again and again..."},"518":{"dur":2,"text":"And when the researchers come\nin on Monday, the robot tells"},"521":{"dur":2,"text":"them a joke, and they die\nlaughing because it is"},"524":{"dur":2,"text":"ten thousand times funnier\nthan anything that the human"},"526":{"dur":2,"text":"brain can possibly handle.\nThis is, of course, the famous"},"529":{"dur":2,"text":"scene from Monthy Python,\nthe funniest joke in the world."},"532":{"dur":3,"text":"So, it is now exterminating the\nhuman species with laughter 'cos"},"536":{"dur":3,"text":"it's goal is to be funny. And\neven if some people manage"},"540":{"dur":3,"text":"to send it a message\nbefore they hear the wry,"},"543":{"dur":4,"text":"self-deprecating come-back\nthat kills them, all the robot"},"548":{"dur":3,"text":"will say is, you know, I don't\nreally care whether you live"},"551":{"dur":3,"text":"or die because I'm just\nhere to be funny. And then,"},"554":{"dur":2,"text":"after it's killed the universe,\nsorry, after it's killed"},"557":{"dur":2,"text":"humanity, it builds rockets,\nand nanorockets, and expands"},"560":{"dur":2,"text":"to the galaxy to try to find\nother species to make them"},"563":{"dur":3,"text":"laugh. So that's... This is a\ncaricature of Bostrom's"},"566":{"dur":2,"text":"argument, but I'm trying to\nvaccinate you against it"},"569":{"dur":3,"text":"rather than persuade you of it.\nSo, in rough outlines"},"572":{"dur":4,"text":"this is what it is.\nSo, I wanna go over the..."},"577":{"dur":4,"text":"There's a more succinct version\nof this that I like too. This is"},"581":{"dur":3,"text":"from Perry Bible Fellowship.\nYou see Hugbot has installed"},"585":{"dur":3,"text":"something in his hug-capacitor.\nThe scientists think it's"},"589":{"dur":3,"text":"adorable, and he ends up\ndestroying the Earth because"},"593":{"dur":3,"text":"of his desire to hug everybody.\nThis is, again, in caricature"},"596":{"dur":3,"text":"exactly what Bostrom, and\npeople like him are arguing."},"599":{"dur":3,"text":"So, the salient points of this\nare the... This is slow to"},"603":{"dur":3,"text":"start, the process of recursive\nimprovement because it involves"},"607":{"dur":2,"text":"human beings, and human\ndesigners. They go home"},"610":{"dur":2,"text":"at five o'clock, they have\ndinner, they sleep... So it"},"612":{"dur":3,"text":"takes a while, but as soon as\nthe AI exceeds our abilities"},"616":{"dur":3,"text":"it takes off, and starts\nhappening on a computer"},"619":{"dur":3,"text":"time-scale. Again, there's\nno obvious ceiling on how,"},"623":{"dur":2,"text":"how much ability it has until\nit hits some physical limit"},"626":{"dur":3,"text":"that we don't know about.\nAnd, most interestingly,"},"629":{"dur":3,"text":"these AIs are evil by default.\nNot because they're malevolent,"},"633":{"dur":2,"text":"but because they have a\ndifferent value system"},"635":{"dur":2,"text":"altogether than human beings do.\nAny assumptions we have about"},"638":{"dur":2,"text":"altruism or whatever, they don't\nhold unless they're designed"},"641":{"dur":2,"text":"into the AI. And if we let it\nhappen by chance, it's just"},"644":{"dur":2,"text":"going to have some value systems\nthat we probably don't even"},"647":{"dur":2,"text":"understand. And the final point\nI'll make is that you'll see"},"650":{"dur":2,"text":"the definition of intelligence\nhere\tis very, very slippery."},"653":{"dur":2,"text":"Like, at some points it's about\nbeing funny, at some points"},"656":{"dur":2,"text":"it's about being a really good\ndesigner of AIs, at some points"},"659":{"dur":2,"text":"it's like being just a genial\nthing that can talk to people."},"662":{"dur":2,"text":"So, a lot of the\nsuperintelligence stuff relies"},"665":{"dur":3,"text":"on intelligence not being a\nconcept that's defined at all."},"670":{"dur":3,"text":"There's a lot of poetic language\naround how this takeover will"},"673":{"dur":3,"text":"happen. So, Nick Bostrom\nwrites... He's assuming that"},"677":{"dur":4,"text":"a program has become sentient,\nand is biding its time, has"},"681":{"dur":3,"text":"built little DNA replicators,\nand then, when it's ready..."},"684":{"dur":4,"text":"'At a preset time, nanofactories\nproducing nerve gas or"},"689":{"dur":2,"text":"target-seeking mosquito-like\nmissiles might burgeon forth"},"692":{"dur":2,"text":"simultaneously from every\nsquare meter of the globe...'"},"695":{"dur":3,"text":"And that will be the end of\nhumanity. So, that's kind of"},"698":{"dur":5,"text":"freaky, you know. And how\ndo we fix this? Well, they..."},"704":{"dur":3,"text":"For some reason, AI people\nlike to talk about the paperclip"},"707":{"dur":3,"text":"maximizer. It's this, you know,\nyou have a paperclip factory"},"710":{"dur":2,"text":"that builds itself an artificial\nintelligence to help production,"},"713":{"dur":2,"text":"and then it becomes sentient,\nand decides to turn the universe"},"716":{"dur":3,"text":"into paperclips. So, the way\nto avoid this is you want to"},"720":{"dur":4,"text":"have values built into the code.\nIt's kind of like a moral"},"724":{"dur":2,"text":"fixed point that even through\nthousands and thousands of"},"727":{"dur":2,"text":"cycles of recursive\nself-improvement the values"},"730":{"dur":2,"text":"remain steady, and the values\nare things like help people out,"},"733":{"dur":2,"text":"you know, don't kill everybody,\nlisten to what people want,"},"736":{"dur":4,"text":"do what I mean basically,\nin shorthand. And again,"},"740":{"dur":3,"text":"this is very poetically stated\nby the AI... I'll call them"},"744":{"dur":2,"text":"AI weenies 'cos that's\nwhat I think they are."},"747":{"dur":2,"text":"So here, for example, here's\na poetic example from Eliezer"},"750":{"dur":2,"text":"Yudkowski of the values we're\nsupposed to teach to our"},"752":{"dur":3,"text":"artificial intelligence.\n'Coherent extrapolated volition"},"756":{"dur":4,"text":"is our wish if we knew more,\nthought faster, were more the"},"760":{"dur":3,"text":"people we wished we were,\nhad grown up farther together;"},"764":{"dur":3,"text":"where the extrapolation\nconverges rather than diverges,"},"767":{"dur":3,"text":"where one wishes... where our\nwishes cohere rather than"},"771":{"dur":4,"text":"interfere; extrapolated as we\nwish that they extrapolated,"},"776":{"dur":3,"text":"interpreted as we wish that\nthey were interpreted.'"},"779":{"dur":2,"text":"So this is some pretty heavy\nstuff to try to convert into"},"782":{"dur":3,"text":"code. And the clock is\nticking every year, you know."},"786":{"dur":2,"text":"Moore's law is continuing\ntechnically, although if you"},"789":{"dur":2,"text":"watched the Apple event\nthe other day, you might"},"792":{"dur":5,"text":"dispute that it's happening\nat all. And the argument is that"},"797":{"dur":3,"text":"if we don't do anything, if we\ndon't try to create this"},"800":{"dur":2,"text":"so-called friendly AI, the AI\nis gonna arise spontaneously"},"804":{"dur":2,"text":"on its own. One day Google's\nAdSense network is gonna"},"807":{"dur":2,"text":"wake up, and kind of look\naround, and then try to,"},"810":{"dur":3,"text":"you know, populate the universe\nwith banner ads. I think a more"},"813":{"dur":3,"text":"likely outcome is that AdSense\nwould upload itself into a"},"816":{"dur":2,"text":"self-driving car, and then just\ndrive to the ocean, and stare"},"819":{"dur":3,"text":"out, and think about it's life,\nand what had become of it."},"822":{"dur":3,"text":"But there's this definite,\nlike, you know, Aladin's lamp"},"826":{"dur":2,"text":"aspect to these fantasies\nof artificial intelligence"},"829":{"dur":2,"text":"where unless you tell it\nexactly what you want,"},"831":{"dur":3,"text":"it will find loopholes that will\nthen exterminate the species."},"835":{"dur":4,"text":"It's all or none. And the thing\nabout all of this is that smart"},"839":{"dur":3,"text":"people who believe this\nare really persuasive."},"843":{"dur":4,"text":"I mean, they're smart people.\nSo, it made me think of this"},"848":{"dur":3,"text":"experience I had in my twenties.\nI lived in Vermont, and when"},"852":{"dur":3,"text":"I flew to a conference, I would\ncome back at 11 PM, and I'd"},"856":{"dur":2,"text":"have to drive two hours... And\nVermont is a very rural state,"},"858":{"dur":2,"text":"so the roads are dark, and\nthere's nothing there. There's"},"861":{"dur":2,"text":"a late night TV show in America\ncalled Art Bell where he talks"},"864":{"dur":3,"text":"to various cooks and UFO people,\nand I would freak myself out"},"868":{"dur":3,"text":"so much. Like after 90 minutes\nI would be shaking, you know,"},"872":{"dur":2,"text":"waiting for the UFO to arrive\nand beam me out of the car"},"874":{"dur":2,"text":"because I'm a very gullible\nperson. I'm very easily"},"877":{"dur":3,"text":"persuadable. And it's the same\nfeeling I get when I read"},"880":{"dur":3,"text":"too much of this AI stuff.\nScott Alexander has this"},"884":{"dur":3,"text":"beautiful phrase called\n'epistemic learned"},"888":{"dur":3,"text":"helplessness'. So, epistemology\nis just how do you know the"},"892":{"dur":2,"text":"things you know, and by\nepistemic learned helplessness"},"895":{"dur":2,"text":"he means this feeling that\nhe shares of being easily"},"897":{"dur":2,"text":"persuadable by arguments\nthat are very rational and"},"900":{"dur":2,"text":"structured. He noticed that when\nhe was a young man he would read"},"902":{"dur":2,"text":"these alternate histories about,\nyou know, from various authors"},"905":{"dur":3,"text":"who disputed mainstream\nhistory, and even though"},"909":{"dur":2,"text":"they were all mutually\ncontradictory, he believed"},"911":{"dur":2,"text":"each one of them as he read it,\nand then he believed the"},"914":{"dur":2,"text":"rebuttals, and the rebuttals\nto the rebuttals. And that"},"916":{"dur":2,"text":"basically told him to write off\nhis own brain because it wasn't,"},"919":{"dur":2,"text":"wasn't reliable. I feel the\nsame way about AI. So,"},"922":{"dur":2,"text":"when you're dealing with\narguments about AI, you have"},"925":{"dur":3,"text":"two perspectives you can\nchoose. One is the outside,"},"928":{"dur":4,"text":"and one is the inside. The\ninside perspective is saying,"},"932":{"dur":3,"text":"you know, someone comes to\nyour door and starts talking to"},"936":{"dur":2,"text":"you about how the UFO's gonna\narrive in two years, and beam us"},"939":{"dur":2,"text":"all up to a better planet, and\nwe have to join the group"},"941":{"dur":2,"text":"and make this, you know,\nprepare the landing grounds."},"944":{"dur":2,"text":"And the inside perspective\nmeans you argue against them"},"947":{"dur":3,"text":"on their own grounds, and maybe\nyou're persuaded by their"},"950":{"dur":2,"text":"arguments. You listen to the\nsubstance of what they have"},"953":{"dur":2,"text":"to say. And the outside\nperspective is, you know,"},"956":{"dur":2,"text":"you look at them, and you go\nyou make a lot of sense to me,"},"958":{"dur":2,"text":"I believe you, but you kind of,\nlike, you're dressed in weird"},"961":{"dur":2,"text":"clothing and beads, you have no\nmoney, you live in a compound,"},"963":{"dur":2,"text":"everything in my human\nexperience says you're kind"},"966":{"dur":2,"text":"of a cult, and I don't really\nwant to get caught up in you"},"969":{"dur":2,"text":"even though I can't rebut what\nyou say. So I wanna take it from"},"971":{"dur":2,"text":"two directions. I'm gonna start\nwith the inside perspective,"},"974":{"dur":2,"text":"and then talk about why I think\nthis all matters to us as web"},"976":{"dur":2,"text":"developers which is the\noutside perspective,"},"979":{"dur":2,"text":"and what it means when an\nindustry is obsessed with"},"981":{"dur":3,"text":"ideas like this. Well, let's go\ninside first. So, I'm gonna,"},"985":{"dur":5,"text":"kind of, try to power through\nthese. These are my substantive"},"990":{"dur":4,"text":"objections to superintelligence.\nFirst, the argument from wooly"},"995":{"dur":3,"text":"definitions. Like I said,\nintelligence - they never really"},"998":{"dur":2,"text":"say what it means. It means,\nyou know, different things in"},"1001":{"dur":2,"text":"different places in the argument\nand it's very hard to pin down."},"1004":{"dur":2,"text":"I find that suspicious. The\nargument from Stephen Hawking's"},"1007":{"dur":2,"text":"cat. So, Stephen Hawking is\nprobably one of the most"},"1010":{"dur":3,"text":"brilliant people alive, but say\nhe wants to get a cat into the"},"1013":{"dur":3,"text":"cat carrier. How is he gonna do\nit? He can model the cat's mind"},"1017":{"dur":2,"text":"in his own, he can try to\npersuade it, he knows a lot of"},"1020":{"dur":2,"text":"things about feline behavior,\nbut ultimately, if the cat"},"1022":{"dur":2,"text":"doesn't want to get into the\ncarrier, it's not gonna get in."},"1025":{"dur":2,"text":"You might think I'm being\noffensive or cheating because"},"1028":{"dur":2,"text":"Stephen Hawking is disabled,\nbut an artificial intelligence"},"1030":{"dur":2,"text":"would also initially not be\nembodied. It would be sitting"},"1033":{"dur":2,"text":"on a server somewhere, and\ntalking to people so it would"},"1036":{"dur":2,"text":"have to use the force of\npersuasion to get them to do"},"1038":{"dur":2,"text":"what it wants. My point is that,\nwhen there's a big difference"},"1040":{"dur":2,"text":"in intelligence, you can't\nactually think like a cat."},"1043":{"dur":3,"text":"There's a stronger version of\nthis argument from Einstein's"},"1046":{"dur":3,"text":"cat. Einstein was a muscular\nfellow. Not many people know"},"1050":{"dur":2,"text":"this, but he was kind of tough\nand brawny, but still if he"},"1053":{"dur":2,"text":"tried to get a cat into the\ncarrier, and the cat didn't"},"1055":{"dur":2,"text":"want to go, you know what\nwould happen to Einstein?"},"1058":{"dur":2,"text":"A stronger version of this\nargument even are the emus."},"1062":{"dur":3,"text":"Has anyone heard of the emu war\nin Australia? Yes, wonderful!"},"1065":{"dur":2,"text":"So, if you haven't, this is\nvery enjoyable. In the thirties,"},"1068":{"dur":2,"text":"the Australians, being who they\nare, wanted to massacre emus,"},"1071":{"dur":2,"text":"one of their native birds 'cos\nthey were bothering farmers."},"1074":{"dur":3,"text":"And they sent out these,\nbasically armored divisions,"},"1077":{"dur":4,"text":"you know, motorized machine gun\ntrucks. Kind of like the"},"1081":{"dur":3,"text":"Toyota Hiluxes, and they tried\nto slaughter emus, and the"},"1084":{"dur":2,"text":"emus won. They used\nguerilla tactics, you know,"},"1087":{"dur":2,"text":"they separated, they infiltrated\nthe groups, and they basically"},"1090":{"dur":2,"text":"drove the Australians to\ndistraction. So, even..."},"1093":{"dur":2,"text":"The human species with the\nheight of its technology"},"1095":{"dur":2,"text":"has difficulty with less\nintelligent creatures"},"1098":{"dur":2,"text":"when they don't want to do\nsomething. The argument from"},"1101":{"dur":2,"text":"Slavic pessimism. This should\nbe familiar hopefully to all"},"1104":{"dur":3,"text":"of us. We can't build anything\nright, all right? How are we"},"1108":{"dur":4,"text":"suppossed to build a fixed\npoint morally st... Thank you."},"1114":{"dur":3,"text":"How are we supposed to build\nlike a fixed morally stable"},"1118":{"dur":3,"text":"thing when we can't even secure,\nyou know, a web cam?"},"1121":{"dur":2,"text":"How are we supposed to do this?\nIf you're familiar with the"},"1124":{"dur":2,"text":"Ethereum heist where people\nhave created a logical language"},"1127":{"dur":2,"text":"for writing contracts, and\nimmediately a hundred million"},"1129":{"dur":2,"text":"dollars drained out of it.\nIt's absolutely hopeless."},"1132":{"dur":2,"text":"Basically, you know, either\nwe're gonna get lucky,"},"1135":{"dur":2,"text":"or we're not gonna be lucky.\nAnd hopefully, this is a"},"1137":{"dur":2,"text":"slavicly acceptable argument.\nThe argument from mental"},"1140":{"dur":3,"text":"complexity. There's this thing\ncalled orthogonality thesis in"},"1143":{"dur":2,"text":"AI that I absolutely don't buy,\nwhich says that even a very"},"1146":{"dur":2,"text":"complicated mind can have\nsimple motivations like that"},"1149":{"dur":3,"text":"paperclip, you know, paperclip\nmaximizer. If you're fans of"},"1152":{"dur":3,"text":"Rick and Morty, I think this is\nwhere more of this situation"},"1156":{"dur":3,"text":"we'll encounter. Complex minds\nhave complicated motivations,"},"1159":{"dur":3,"text":"and it's not just one or two\nthings that they want, you know,"},"1163":{"dur":3,"text":"they're complicated like we are.\nHere's the butter robot,"},"1166":{"dur":2,"text":"it's existence is just to pass\nthe butter to its' inventor,"},"1169":{"dur":2,"text":"but the first thing it does when\nit's turned on is look at its'"},"1172":{"dur":4,"text":"hand and say 'Oh, my God!\nWhat is existence for'?"},"1176":{"dur":3,"text":"The argument from just look\naround you, all right? So,"},"1180":{"dur":3,"text":"when we look at where AI is\nactually succeeding, it's not"},"1184":{"dur":3,"text":"in algorithms and these clever\nsort of self-improving ways,"},"1187":{"dur":3,"text":"it's just by throwing massive,\nmassive amounts of data"},"1191":{"dur":4,"text":"into fairly simple models.\nAnd, like, right now Google's"},"1195":{"dur":2,"text":"rolling out GoogleHome where\nit's going to try to pour even"},"1198":{"dur":2,"text":"more data and get like a second\ngeneration of understanding."},"1201":{"dur":2,"text":"This is really effective, but\nthe way it works is not the way"},"1204":{"dur":3,"text":"it's described in these sort of\ndoomsday scenarios, by recursive"},"1208":{"dur":3,"text":"self-improvement, it's just\nmassive training sets on data."},"1211":{"dur":2,"text":"The argument from my roommate\nPeter, the smartest person that"},"1214":{"dur":2,"text":"I've ever met in my life. And\nthe laziest person that I've"},"1217":{"dur":2,"text":"ever met in my life. He was\nincredibly brilliant, and all he"},"1220":{"dur":2,"text":"did was bong rips and just\nlay around on the sofa."},"1223":{"dur":3,"text":"The idea that every intelligent\nsystem is gonna have motivation"},"1226":{"dur":2,"text":"Tony Robbins style to improve\nitself until it can conquer"},"1229":{"dur":3,"text":"the galaxy is decisively\nrefuted by my roommate Peter."},"1233":{"dur":2,"text":"The argument from brain\nsurgery. Okay, so, there's"},"1235":{"dur":2,"text":"always this guy at every party,\nright? Pulls out the guitar in"},"1238":{"dur":2,"text":"the most inappropriate moment,\nwhen we don't want to hear"},"1241":{"dur":3,"text":"Wonderwall. But, my point about\nbrain surgery is I can't go"},"1244":{"dur":2,"text":"operate on my brain and improve\nthe part that does brain"},"1247":{"dur":3,"text":"surgery. It would be neat if I\ncould. I'd become the world's"},"1251":{"dur":2,"text":"greatest brain surgeon by just\nrecursively going in there"},"1254":{"dur":2,"text":"and kind of tweaking neurons.\nBut brains don't work like that."},"1257":{"dur":2,"text":"We have no idea how they work,\nbut they're very interconnected"},"1259":{"dur":2,"text":"and holistic, and there's not\na part that you can point to."},"1262":{"dur":3,"text":"Similarly, the AI can't just go\nin there and fix the part that"},"1266":{"dur":4,"text":"is better at designing AIs.\nThe argument from childhood."},"1271":{"dur":3,"text":"All right, we're born into this\nworld just like little helpless"},"1275":{"dur":4,"text":"messes, and it takes us a long\ntime to, of interacting with the"},"1279":{"dur":3,"text":"world and with other people\nin the world before we can"},"1283":{"dur":3,"text":"start to be intelligent beings.\nA childhood is a long period,"},"1286":{"dur":3,"text":"there's no reason to think that\na superintelligence could upload"},"1289":{"dur":3,"text":"I mean, improve itself thirty\ntimes in the course of a minute,"},"1293":{"dur":2,"text":"and become hyperintelligent,\nand take over the Earth."},"1296":{"dur":2,"text":"It might also have a period,\nin fact, it's likely to, when it"},"1299":{"dur":2,"text":"needs to interact with the\nworld, interact with human"},"1301":{"dur":2,"text":"beings, interact with other\nbaby superintelligences,"},"1304":{"dur":3,"text":"and kind of, basically\nlearn to be what it is."},"1308":{"dur":2,"text":"And then the argument\nfrom Robinson Crusoe."},"1311":{"dur":3,"text":"So many things about our\nintelligence are based on"},"1314":{"dur":3,"text":"us working together, and\nbeing together, collectively."},"1318":{"dur":3,"text":"You know, we all, or most\nof us had a higher university"},"1322":{"dur":3,"text":"education, and that's thousands\nand thousands, and thousands"},"1326":{"dur":3,"text":"of years of accumulated\nknowledge that was kind of"},"1329":{"dur":3,"text":"distilled and beaten into us\nby professors, you know,"},"1333":{"dur":2,"text":"our whole experience as a\nspecies is that intelligence"},"1335":{"dur":3,"text":"is something that you need\na collective group to do."},"1339":{"dur":2,"text":"You can't just have the most\nbrilliant person in the world"},"1342":{"dur":2,"text":"on an island with nothing.\nThey'll make do, and they'll"},"1344":{"dur":2,"text":"be inventive, but they won't be\nanywhere near their full"},"1347":{"dur":2,"text":"potential. So, when we first\ncreate some thinking sort of"},"1349":{"dur":3,"text":"entity it's not going to take\nover the universe. It's gonna be"},"1353":{"dur":4,"text":"lonely and sad, and in need of\nus to kind of shepard it along."},"1358":{"dur":3,"text":"So much for the inside\narguments, I wanna talk about"},"1361":{"dur":3,"text":"outside arguments which was\nthe real reason I wanted to"},"1365":{"dur":4,"text":"give this talk. Basically, what\nkind of person does believing"},"1369":{"dur":4,"text":"this stuff sincerely turn you\ninto? The answer's not pretty."},"1374":{"dur":4,"text":"The outside arguments are these,\nlike, there's a grandiosity that"},"1379":{"dur":4,"text":"is taking over. The grandiosity\nis basically it's all or"},"1384":{"dur":3,"text":"nothing, we are the generation\nthat has to make this happen,"},"1388":{"dur":3,"text":"or we condemn ourselves to\nextinction, or to some sort of"},"1391":{"dur":2,"text":"hell-like existence in the\nmind of the computer."},"1394":{"dur":3,"text":"Let me quote Bostrom again.\nHe's talking about all possible"},"1398":{"dur":3,"text":"future lives and what the stakes\nare. 'If we represent all"},"1402":{"dur":2,"text":"happiness experience during one\nentire life with a tear of joy,"},"1405":{"dur":2,"text":"then the happiness of these\nsouls could fill and refill the"},"1408":{"dur":3,"text":"Earth's oceans every second,\nand keep doing so for 100"},"1411":{"dur":3,"text":"billion billion millennia. It is\nreally important that we make"},"1415":{"dur":3,"text":"sure that these truly are\ntears of joy.' That's some"},"1419":{"dur":2,"text":"heavy shit to lay down on a\ntwenty year old developer,"},"1422":{"dur":3,"text":"you know? That's some pretty\nheavy responsibility to bear"},"1426":{"dur":4,"text":"for these trillions and\ntrillions of beings. And,"},"1430":{"dur":3,"text":"it reminds me of\nsomething that I don't like."},"1434":{"dur":2,"text":"I have a visceral reaction\nto this language because"},"1437":{"dur":2,"text":"I remember it vaguely from\nchildhood living in a Marxist"},"1440":{"dur":3,"text":"society where we were gonna fix\nthe world, and then it was gonna"},"1444":{"dur":3,"text":"eventually kind of trickle down\nto where everyday life might"},"1447":{"dur":3,"text":"change, but the first job was\nto fix the fate of humanity."},"1451":{"dur":2,"text":"My mom used to say that\neverybody under communism"},"1454":{"dur":2,"text":"suffered from a disease where\nwhat your eyes saw, and your"},"1456":{"dur":3,"text":"ears heard was not the same\nthing, and I'm feeling the same"},"1460":{"dur":3,"text":"symptoms. You know, I live\nin California which has the"},"1464":{"dur":3,"text":"highest poverty rate in the US,\neven though it's the home of"},"1467":{"dur":4,"text":"Silicon Valley. I see my rich\nindustry doing nothing to"},"1472":{"dur":2,"text":"improve the day to day life of\npeople, but they are saving"},"1475":{"dur":3,"text":"trillions and trillions of\nbeings in the future."},"1478":{"dur":3,"text":"I don't think so. It ties into\nmegalomania. All right,"},"1482":{"dur":2,"text":"this bondvillain-ness\nwhich is really creepy."},"1485":{"dur":3,"text":"People think that AI is gonna\ntake over the world, so that's"},"1489":{"dur":2,"text":"justification that intelligent\npeople should take over the"},"1491":{"dur":2,"text":"world first, and try to fix it\nbefore AI can break it, make"},"1494":{"dur":3,"text":"sure the AI is healthy. There's\na really wonderful quote from"},"1498":{"dur":4,"text":"Joi Ito who runs the MIT Media\nLab. He says, 'This may upset"},"1503":{"dur":2,"text":"some of my students at MIT, but\none of my concerns is that it's"},"1506":{"dur":2,"text":"been a predominately male gang\nof kids, mostly white, who are"},"1509":{"dur":3,"text":"building the core computer\nscience around AI, and they're"},"1512":{"dur":2,"text":"more comfortable talking to\ncomputers than to human beings."},"1515":{"dur":2,"text":"A lot of them feel that if they\ncould just make that science"},"1518":{"dur":2,"text":"fiction, generalized AI, we\nwouldn't have to worry about"},"1521":{"dur":2,"text":"all the messy stuff like\npolitics and society. They"},"1524":{"dur":2,"text":"think machines will just\nfigure it all out for us.'"},"1526":{"dur":2,"text":"So, having realized that the\nworld is not a programming"},"1529":{"dur":2,"text":"problem, they want to make it\ninto a programming problem"},"1532":{"dur":2,"text":"by kind of designing the thing\nthat will then fix all of our"},"1535":{"dur":3,"text":"problems. This is, this is\nmegalomaniacal, I don't like it."},"1538":{"dur":3,"text":"Transhuman voodoo. So, there's\nthis whole constellation of"},"1542":{"dur":2,"text":"beliefs that falls out as soon\nas you start talking about"},"1545":{"dur":3,"text":"artificial intelligence. If you\nhave a really smart AI,"},"1549":{"dur":2,"text":"the first thing it can make is\nnanotechnology. Nanotechnology"},"1552":{"dur":2,"text":"is magic 'cos it can make\nanything so you have a post,"},"1555":{"dur":3,"text":"kind of this abundance society\nwhere there's no more want."},"1558":{"dur":2,"text":"Of course, nanotechnology can\nalso scan your brain and upload"},"1561":{"dur":3,"text":"it so you no longer die, you're\nimmortal, and it can probably"},"1565":{"dur":3,"text":"even resurrect the dead, you\nknow, I can... These machines"},"1568":{"dur":2,"text":"can go into my brain, and look\ninto my memories of my father"},"1571":{"dur":2,"text":"and kind of create a simulation\nof him that I could interact"},"1574":{"dur":2,"text":"with. I mean, for all intents\nand purposes it could behave"},"1577":{"dur":2,"text":"just like him. So that's, you\nknow, there's a lot of stuff"},"1580":{"dur":3,"text":"packed into this assumption\nof artificial intelligence."},"1583":{"dur":2,"text":"Uploading is another one where\nwe will be able to occupy,"},"1586":{"dur":2,"text":"you know, these kind of\nartificial worlds or bodies"},"1588":{"dur":2,"text":"because our brains can be\ncompletely scanned. And"},"1591":{"dur":2,"text":"galactic expansion for some\nreason always falls out too."},"1594":{"dur":2,"text":"I never really understood\nwhy we immediately have to"},"1597":{"dur":2,"text":"expand to the galaxy, but\nthis seems to be a staple of"},"1600":{"dur":3,"text":"transhumanist thought. What it\ncomes down to is Religion 2.0."},"1604":{"dur":2,"text":"People have called this\nThe Nerd Apocalypse."},"1607":{"dur":3,"text":"It very much is, it's kind of,\nit's a clever hack because"},"1610":{"dur":2,"text":"instead of believing in God\nat the outset, you kind of build"},"1613":{"dur":2,"text":"something that can become\na God-like entity, and then,"},"1616":{"dur":3,"text":"but for all intents and purposes\nit has all the attributes."},"1619":{"dur":3,"text":"It is omnipotent, omniscient,\nand is either benevolent,"},"1623":{"dur":2,"text":"if you got your programming\nright, and didn't introduce any"},"1626":{"dur":3,"text":"bugs, or it is, you know, it is\nthe Devil, and you are at its'"},"1630":{"dur":4,"text":"mercy. And, there's this\nfeeling of urgency. You have to"},"1635":{"dur":3,"text":"act now, everything is on the\nline. There's a very religious"},"1638":{"dur":3,"text":"feeling. Because these arguments\nappeal to religious sentiments"},"1642":{"dur":3,"text":"it gives them these strong roots\nthat they're able to put down"},"1645":{"dur":2,"text":"in people. And while they\nrationalize why they have"},"1648":{"dur":2,"text":"these beliefs at heart\nthese are religious beliefs"},"1651":{"dur":3,"text":"in, kind of, in other clothing.\nAnd they lead to a sort of"},"1654":{"dur":2,"text":"comic book ethics. You know,\nwhere everything is about"},"1657":{"dur":2,"text":"saving the world through\ntechnology and technical"},"1660":{"dur":3,"text":"adeptness. I have a fantasy.\nI wanna see a Batman movie"},"1663":{"dur":3,"text":"where everybody knows that\nBatman is Bruce Wayne"},"1667":{"dur":2,"text":"and they just have to humor\nhim because he's their boss."},"1670":{"dur":2,"text":"So they create, like, fake\nscenarios and crimes for him"},"1673":{"dur":3,"text":"to solve, and he has this\nawkward bat-belt and things."},"1676":{"dur":4,"text":"So, that our coders and\nthought leaders in Silicon"},"1681":{"dur":3,"text":"Valley really see themselves\nas modern day Batman."},"1684":{"dur":4,"text":"Nobody is Robin interestingly...\nAll right, simulation fever."},"1689":{"dur":3,"text":"Anybody here heard of\nthe simulation argument?"},"1693":{"dur":3,"text":"Okay, a couple of people have.\nIf you believe that artificial"},"1697":{"dur":4,"text":"intelligence is possible, and\ncan design really, really"},"1701":{"dur":3,"text":"high performance computers,\nthen there's a simple argument"},"1705":{"dur":3,"text":"you can use to convince yourself\nthat it will, it can simulate"},"1708":{"dur":3,"text":"other worlds, and just by\nmathematics it's far more"},"1711":{"dur":2,"text":"likely that we live in one of\nthese simulations 'cos there's"},"1714":{"dur":2,"text":"many more of them,\nthan in the base reality."},"1716":{"dur":3,"text":"I hope I didn't freak you out.\nPeople believe this shit."},"1720":{"dur":2,"text":"So, Elon Musk, you know,\nactually thinks... he's offered"},"1723":{"dur":3,"text":"billion to one odds on it...\nSomebody, we haven't found him"},"1727":{"dur":2,"text":"yet, but somobody's paid two\ncoders in Silicon Valley to try"},"1729":{"dur":3,"text":"to hack the simulation which\nis so rude. I live in this"},"1733":{"dur":5,"text":"simulation, don't segfault it.\nPlease! I'm using it."},"1741":{"dur":4,"text":"So, simulation fever is really\ndestabilizing to reality because"},"1746":{"dur":3,"text":"if you think, so... Let me\nbacktrack, and explain how it"},"1750":{"dur":3,"text":"works. Say, like, you're in a\npost-singularity world where"},"1753":{"dur":2,"text":"you have these hyper-powerful\ncomputers, and you're a"},"1756":{"dur":2,"text":"historian studying the Second\nWorld War. You wanna ask"},"1759":{"dur":2,"text":"what would happen if Hitler\nhad conquered Moscow"},"1762":{"dur":2,"text":"instead of stopping just short?\nSo you create the scenario,"},"1765":{"dur":3,"text":"you simulate the entire world,\nand the army's rolling, you see"},"1768":{"dur":2,"text":"what happens, you write your\nthesis, but because the"},"1770":{"dur":3,"text":"simulation is so detailed\nthe entities in it are sentient."},"1774":{"dur":4,"text":"You can't just turn it off\n'cos that would be a war crime."},"1778":{"dur":3,"text":"Setting aside the fact that\nyou've recreated genocide"},"1781":{"dur":2,"text":"already as part of the\nhistorical setting. So you"},"1785":{"dur":2,"text":"have to keep it running because,\nyou know, that's what your"},"1787":{"dur":3,"text":"ethical board says you have to\ndo. And this WWII simulation"},"1790":{"dur":2,"text":"will develop its own technology,\nand soon it will discover AI,"},"1793":{"dur":2,"text":"and will begin writing its own\nsimulations. So it's kind of"},"1796":{"dur":2,"text":"simulations all the way down\nuntil you run out of CPU."},"1799":{"dur":2,"text":"That's where this argument\ncomes from. There's many more"},"1802":{"dur":3,"text":"of these simulated worlds\nthan the base realities."},"1806":{"dur":2,"text":"But if you believe this,\nyou believe in magic,"},"1808":{"dur":2,"text":"because if we're in a simulation\nwe know nothing about the"},"1811":{"dur":2,"text":"rules in the level above.\nWe don't even know"},"1814":{"dur":2,"text":"if math works the same. Maybe\ntwo plus two is five, maybe"},"1817":{"dur":3,"text":"two plus two is, you know,\na spiky-tailed monster..."},"1821":{"dur":2,"text":"There's no information\nthat we can have"},"1823":{"dur":3,"text":"by looking at our own situation.\nPeople could easily rise from"},"1827":{"dur":2,"text":"the dead, you know, if you\njust kept the right back-ups"},"1830":{"dur":2,"text":"you can reinstantiate them.\nIf we can communicate with"},"1832":{"dur":2,"text":"whoever runs the simulation,\nthen we have a direct line to"},"1835":{"dur":2,"text":"God. So this is like a\npowerful solvent for sanity."},"1838":{"dur":2,"text":"When you start really getting\ndeep into simulation world,"},"1841":{"dur":4,"text":"you start to go nuts.\nData hunger."},"1846":{"dur":4,"text":"As I mentioned, the way that\nwe found right now that's"},"1851":{"dur":2,"text":"most effective to get\ninteresting behavior out of AIs"},"1854":{"dur":4,"text":"is just to pour data into them,\nand this creates a dynamic that"},"1858":{"dur":2,"text":"is really socially harmful.\nI mean, we're on the point of"},"1861":{"dur":2,"text":"introducing these Orwellian\nmicrophones in everybody's house"},"1864":{"dur":3,"text":"and all that data is gonna be\nused to train neural networks"},"1867":{"dur":3,"text":"that will then get better and\nbetter at listening to what we"},"1871":{"dur":2,"text":"wanna do. But if you think that\nthe road to AI goes through"},"1874":{"dur":2,"text":"this pathway, then you really\nwant to maximize the amount"},"1877":{"dur":2,"text":"of data collected. You\nwant to be working on these"},"1879":{"dur":2,"text":"big projects. So it reinforces\nthis idea that we have to"},"1882":{"dur":3,"text":"collect as much and, do as much\nsurveillance as possible."},"1886":{"dur":4,"text":"Ultimately, I think that AI risk\nis like string theory for"},"1890":{"dur":3,"text":"programmers. You know, it's\nvery, it's fun to think about,"},"1894":{"dur":2,"text":"you kind of build these towers\nof thought, and then you climb"},"1897":{"dur":2,"text":"up into them, and you pull the\nladder up behind you so you're"},"1899":{"dur":2,"text":"disconnected from anything.\nAnd there's no way to put them"},"1902":{"dur":3,"text":"to the test, short of creating\nwhich we have no idea how to do."},"1905":{"dur":5,"text":"Finally, it incentivizes crazy.\nOne of the hallmarks of deep"},"1911":{"dur":4,"text":"thinking about AI risk is, like,\nthe more outlandish your ideas,"},"1916":{"dur":3,"text":"the more, like, credibility\nthat gives you because it shows"},"1920":{"dur":2,"text":"that you're courageous enough\nto follow these trains of"},"1923":{"dur":3,"text":"thought all the way to the last\nstation. So, Ray Kurzweil,"},"1926":{"dur":2,"text":"who believes he will never die,\nhas been a Google employee"},"1929":{"dur":2,"text":"for several years now, and is\npresumably working on that"},"1932":{"dur":2,"text":"problem. If Google hacks death,\nI will be so annoyed because,"},"1935":{"dur":2,"text":"like, imagine you have a thirty\nthousand year browsing history"},"1938":{"dur":3,"text":"and how that's gonna\nfollow you around."},"1941":{"dur":3,"text":"I think the most harmful effect,\nI think is what I wanna call"},"1945":{"dur":4,"text":"AI Cosplay. So, people who\nare really, really persuaded"},"1950":{"dur":5,"text":"that AI is really gonna happen\nstart behaving like their"},"1955":{"dur":3,"text":"fantasy of what the artificial\nintelligence would do."},"1959":{"dur":3,"text":"In his book Nick Bostrom\noutlines these six things that"},"1963":{"dur":3,"text":"an AI would have to do in order\nto be able to successfully take"},"1967":{"dur":5,"text":"over, and accomplish its' goals.\nOn the list is intelligence"},"1972":{"dur":4,"text":"amplification, strategizing,\nsocial manipulation, hacking,"},"1977":{"dur":4,"text":"technology research, and\neconomic productivity."},"1982":{"dur":3,"text":"And if you look at what people\nin Silicon Valley are doing"},"1985":{"dur":4,"text":"is they're trying to behave\nlike their favorite AI heroes."},"1989":{"dur":3,"text":"It's a sociopathic form of\nbehavior, but we see it."},"1993":{"dur":2,"text":"Sam Altman is my favorite\nexample of this. This is the"},"1996":{"dur":2,"text":"guy who runs Y Combinator.\nThere's all sorts of attempts"},"1998":{"dur":2,"text":"of reinventing the cities\nfrom scratch, maximizing"},"2001":{"dur":3,"text":"personal productivity and time.\nDoing behind the scenes stuff"},"2005":{"dur":2,"text":"to influence the US election.\nIt's very skull and dagger,"},"2008":{"dur":2,"text":"and it's gonna provoke a\nbacklash by non-tech people."},"2010":{"dur":3,"text":"Because you can't just, like,\nyou can't push on the levers"},"2014":{"dur":3,"text":"of power indefinitely before\nit's gonna annoy democratic"},"2017":{"dur":4,"text":"society that you're a part of.\nAnd I even have a note here."},"2022":{"dur":3,"text":"I've heard people in the\nso-called rationalist community"},"2026":{"dur":3,"text":"refer to people as\nnon-player characters,"},"2029":{"dur":2,"text":"people who don't affect\nthe world in a meaningful way."},"2033":{"dur":3,"text":"That's horrible, like, so I'm in\nan industry where the"},"2036":{"dur":3,"text":"rationalists are the craziest\nones of all. It's, it's..."},"2040":{"dur":3,"text":"It's getting me down. What I've\ncome to think of these, like,"},"2044":{"dur":3,"text":"these AI Cosplayers is like\nnine year old's who go in the"},"2048":{"dur":3,"text":"back yard and play in the tent,\nyou know? And then they start"},"2052":{"dur":3,"text":"they cast shadows on the wall\nof the tent, and they start"},"2055":{"dur":2,"text":"freaking themselves out.\nBut it's really just an image of"},"2058":{"dur":2,"text":"themselves that they're\nreacting to. There's a feedback"},"2061":{"dur":2,"text":"loop between how you imagine\nthe ultimate intelligence to"},"2063":{"dur":3,"text":"behave, and how you behave as\nsomeone who thinks that they're"},"2067":{"dur":4,"text":"smarter than the rest of the\nworld. It's very, very harmful."},"2071":{"dur":3,"text":"So, what's the answer? What's\nthe fix? We need better Sci-Fi,"},"2075":{"dur":3,"text":"all right? This is Stanislaw Lem\nthe great poet Sci-Fi author."},"2079":{"dur":3,"text":"English language Sci-Fi is\nterrible, it's boring. In the"},"2083":{"dur":3,"text":"Eastern block we had the good\nstuff, and we need to make sure"},"2086":{"dur":2,"text":"that it's exported properly.\nIt's already well translated,"},"2089":{"dur":2,"text":"it just needs to be better\nspread. So Stanislaw Lem and the"},"2092":{"dur":2,"text":"Strugatsky brothers are the ones\nwho come to mind. I hope to hear"},"2095":{"dur":2,"text":"other suggestions from you. What\nsets Eastern European Sci-Fi"},"2098":{"dur":2,"text":"apart is that these are people\nwho grew up in difficult"},"2101":{"dur":2,"text":"circumstances, experienced the\nwar, and then lived in a"},"2104":{"dur":2,"text":"totalitarian society, and had to\nexpress ideas obliquely through"},"2107":{"dur":2,"text":"writing. So there's an actual\nunderstanding of human"},"2110":{"dur":2,"text":"experience, and the limits\nof utopian thinking that is"},"2112":{"dur":3,"text":"completely absent in the West.\nNot to say that it's impossible."},"2116":{"dur":3,"text":"I think Stanley Kubrick was able\nto do it, but, you know, we just"},"2119":{"dur":4,"text":"need to get it back. Finally,\nI wanna put my..."},"2123":{"dur":3,"text":"I wanna put my cards on the\ntable. Like, what do I think"},"2127":{"dur":3,"text":"AI is, and what the\npossibilities of it are."},"2131":{"dur":4,"text":"Since I've been making fun\nof it, it's only fair. I think"},"2135":{"dur":4,"text":"artificial intelligence now is\nin the same position as alchemy"},"2139":{"dur":3,"text":"was in the 17th century.\nAlchemists have a bad rep."},"2143":{"dur":2,"text":"We think of them as being\nmystics, as not doing a lot of"},"2146":{"dur":3,"text":"experimental science, but\nresearch has shown that they"},"2149":{"dur":3,"text":"were actually extremely\ndiligent. They used, in some"},"2153":{"dur":2,"text":"cases, modern scientific\ntechniques, and they had some"},"2155":{"dur":3,"text":"really, really good ideas. They\nwere convinced, for example,"},"2159":{"dur":2,"text":"of the corpuscular theory of\nmatter, right? That everything"},"2162":{"dur":3,"text":"is made of little, tiny bits,\nand that these can be recombined"},"2165":{"dur":2,"text":"to create different substances\nwhich is correct. They had,"},"2168":{"dur":3,"text":"they were on the right track.\nTheir problem was that they"},"2171":{"dur":2,"text":"didn't have precise enough\nequipment to make the"},"2174":{"dur":2,"text":"discoveries they needed to.\nThe big discovery you need to"},"2176":{"dur":2,"text":"make as an alchemist is mass\nbalance. That everything that"},"2179":{"dur":2,"text":"you start with weighs as much as\nwhat you end with, but some"},"2182":{"dur":2,"text":"of those things might be gases,\nsome liquids, and they just"},"2185":{"dur":3,"text":"didn't have the precision. They\nhad to wait until the 18th ct."},"2188":{"dur":2,"text":"And they had some clues that\nweren't helpful. So, mercury is"},"2191":{"dur":4,"text":"a metal that  is liquid at room\ntemperature, you know? Woohoo..."},"2196":{"dur":2,"text":"It's no big deal to us. It's\njust a quirk of the periodic"},"2199":{"dur":3,"text":"table, but to them that seemed\nto be a really significant and"},"2203":{"dur":2,"text":"deep clue. Mercury was at the\nheart of this alchemical system,"},"2206":{"dur":2,"text":"and their search for the\nphilosopher's stone, which was"},"2208":{"dur":2,"text":"gonna be a way to turn\nbase metals into gold."},"2211":{"dur":2,"text":"So I got to thinking about\nwhat if we could send a modern"},"2214":{"dur":3,"text":"chemistry textbook back in time\nto Robert... Richard Starkey,"},"2218":{"dur":3,"text":"or Sir Isaac Newton who did\na lot of alchemical research?"},"2222":{"dur":3,"text":"What would their reaction be?\nI think first they would just"},"2225":{"dur":2,"text":"flip through it to see like,\ndid you find the philosopher's"},"2228":{"dur":3,"text":"stone? The key to their quest.\nAnd our answer is yeah,"},"2232":{"dur":4,"text":"but meh... You, know? It makes\nradioactive gold, so... They'd"},"2236":{"dur":2,"text":"be like, radioactivity, what's\nthat? We'd be like, you know,"},"2239":{"dur":2,"text":"invisible, magic rays that will\nkill you if you stand in the"},"2242":{"dur":2,"text":"same room as them. So, a\nlot of the struggle would be"},"2244":{"dur":2,"text":"to just not to make it sound\nmystical. To us it's scientific,"},"2247":{"dur":3,"text":"to them it's very, very voodoo,\nand spooky. And then,"},"2251":{"dur":2,"text":"further on, we'd say but we do\nuse transubstantiation, your"},"2254":{"dur":2,"text":"philosopher's stone, in order\nto make this metal that is very"},"2257":{"dur":2,"text":"handy 'cos if you take two lumps\nof it, and smack them together,"},"2260":{"dur":2,"text":"you can blow up a city.\nSo that's kind of cool."},"2262":{"dur":3,"text":"And then further on we'd say\nactually the philosopher's stone"},"2266":{"dur":2,"text":"you were looking for, it's up\nin the sky. Every single star"},"2269":{"dur":3,"text":"you see is, you know, a source\nof reactions that change"},"2272":{"dur":2,"text":"elements from one to another,\nand every particle in your body"},"2275":{"dur":2,"text":"was actually once in a star. So\nthink about that for a while,"},"2278":{"dur":4,"text":"and how you feel. And not just\nthat, but, you know, we, we've"},"2282":{"dur":3,"text":"discovered that the forces that\nhold this together are the same"},"2286":{"dur":2,"text":"as the lightning in the sky, and\nthe reason that I can see you"},"2288":{"dur":2,"text":"is the same reason that your\ncat gives off a spark when I"},"2291":{"dur":2,"text":"pet it. And the force that keeps\nme from plummeting through"},"2294":{"dur":3,"text":"the floor is the same thing as\nwell, and that these forces are"},"2298":{"dur":3,"text":"defined by simple mathematical\nlaws that fit on an index card."},"2302":{"dur":3,"text":"I think... I don't think it will\nbe possible to communicate this"},"2306":{"dur":4,"text":"without sounding like, like a\nmystic, and invoking God,"},"2311":{"dur":4,"text":"and things that, you know,\nconcepts that were at the heart"},"2316":{"dur":3,"text":"of their belief system. So, I\nthink we're in the same boat"},"2319":{"dur":4,"text":"as artificial intelligence. I\nthink that we have some clues."},"2324":{"dur":2,"text":"We have some really big clues.\nThere's the mystery of"},"2327":{"dur":4,"text":"consciousness. That this box of\nmeat on my head is self aware,"},"2331":{"dur":3,"text":"and that hopefully, presumably,\nunless it's the simulation,"},"2335":{"dur":3,"text":"you guys also experience\nthis, like, through awareness."},"2339":{"dur":2,"text":"But we don't even know\nhow to ask questions about"},"2341":{"dur":2,"text":"consciousness 'cos it's so,\nyou know, we're kind of..."},"2344":{"dur":2,"text":"We're lost in the dark. We have\nother clues like the fact that"},"2347":{"dur":3,"text":"every smart animal seems to\nneed to sleep, and it seems to"},"2351":{"dur":3,"text":"dream. We know how brains\ndevelop in children, we know"},"2354":{"dur":2,"text":"how important language seems\nto be to cognition... We have"},"2358":{"dur":2,"text":"all these pieces, and we have\npieces from computer science"},"2360":{"dur":2,"text":"as well. We see, we're having\nreal success with identifying"},"2363":{"dur":3,"text":"things in images and sounds\nthe way the brain seems to do."},"2367":{"dur":3,"text":"So, there's a lot coming up,\nbut there's also things that we"},"2370":{"dur":2,"text":"are terribly mistaken about.\nUnfortunately, we just don't"},"2373":{"dur":2,"text":"know what they are. And there's\nthings that we've massively"},"2376":{"dur":2,"text":"underestimated the complexity\nof. Just like the alchemist who"},"2378":{"dur":2,"text":"held the rock in one hand and\na piece of wood in the other,"},"2381":{"dur":2,"text":"and thought they were\nroughly the same substance."},"2384":{"dur":3,"text":"Not understanding that the wood\nwas orders of magnitude more"},"2387":{"dur":3,"text":"complex. We're the same way with\nthe study of minds. And that's"},"2391":{"dur":3,"text":"exciting, we're gonna learn a\nlot, but it's gonna take some"},"2394":{"dur":3,"text":"time. And in the meantime,\nthere's this quote I love..."},"2398":{"dur":2,"text":"'If everybody contemplates the\ninfinite instead of fixing the"},"2401":{"dur":3,"text":"drains, many of us will die\nof cholera.' -John Rich"},"2404":{"dur":2,"text":"In the near future, the kind of\nAI and machine learning that"},"2407":{"dur":3,"text":"we have to face is much\ndifferent, and it has ethics"},"2410":{"dur":3,"text":"problems of its' own. It's like\nif those Alamogordo scientists"},"2414":{"dur":3,"text":"had decided to completely focus\non whether they were gonna blow"},"2418":{"dur":2,"text":"up the atmosphere, and forgot\nthat they were building nuclear"},"2420":{"dur":3,"text":"weapons that also had to be\ndealt with. So, there's ethical"},"2424":{"dur":2,"text":"questions in machine learning,\nand they're not about things"},"2427":{"dur":2,"text":"becoming self-aware,\nand taking over the world,"},"2429":{"dur":2,"text":"they're about how people can\nexploit other people, or through"},"2432":{"dur":4,"text":"lapses of thought introduce,\nkind of, immoral, immoral"},"2436":{"dur":4,"text":"behavior into automated,\nautomated processes"},"2441":{"dur":3,"text":"that get more and more\nimportant in our daily lives."},"2445":{"dur":2,"text":"And, of course, there's the\nquestion of how power"},"2448":{"dur":2,"text":"relationships are affected by\nmachine learning and AI."},"2451":{"dur":2,"text":"We've already seen that\nsurveillance has become"},"2454":{"dur":3,"text":"a de facto part of our lives\nin an unexpected way. We never"},"2457":{"dur":2,"text":"forsaw that it would look like\nthis, but it is here. This is"},"2460":{"dur":2,"text":"the NSA Data Center for those\nwho aren't familiar with it."},"2463":{"dur":2,"text":"We have this world, and at the\ntop of this world, the people"},"2466":{"dur":3,"text":"who are running the show, are\nobsessed with a crazy idea."},"2473":{"dur":5,"text":"So, what I hope I've done today\nis, is shown you that you can"},"2478":{"dur":3,"text":"learn something from Stephen\nHawking's cat. No matter how"},"2482":{"dur":3,"text":"much they tell you to get in the\ncarrier, do your own thing."},"2485":{"dur":3,"text":"I hope I made you just a little\nbit dumber from my talk so that"},"2489":{"dur":3,"text":"you don't get caught on the\nsuperintellingence idea, and,"},"2493":{"dur":4,"text":"hopefully, I can persuade you\nthat in the absence of good"},"2497":{"dur":2,"text":"leadership from the people\nat the top of our industry,"},"2500":{"dur":3,"text":"it's up to us to try to make an\neffort to contribute, and to"},"2503":{"dur":2,"text":"really think through all of the\nethical, and difficult issues"},"2506":{"dur":3,"text":"that AI has created for us.\nMostly, I wanna thank you for"},"2510":{"dur":2,"text":"letting me blather on about this\nweird topic in front of you,"},"2513":{"dur":2,"text":"and for your rapt attention.\nThank you so much."}}